---
title: 算法
date: 2023-07-10 15:37:48
tags:
  - 笔记
  - 算法
declare: true
---
- 要计算**非加权图**中的最短路径，可使用**广度优先搜索**。要计算**加权图**中的最短路径，可使用**狄克斯特拉算法**
- **如果有负权边，就不能使用狄克斯特拉算法.原因在于，已经处理过的结点，可能会由于负权边的原因，更新到它的最近距离**.也就是说，狄克斯特拉算法假设：**对于是处理过的节点，没有前往该节点的更短路径**。<!--more-->
- 在包含负权边的图中，要找出最短路径，可使用另一种算法：**贝尔曼-福德算法（Bellman-Ford algorithm）**
- **要判断问题是不是NP完全问题很难，易于解决的问题和NP完全问题的差别通常很小**。例如最短路径问题可以解决，但如果要找出经由指定几个点的最短路径，就是旅行商问题-----NP完全问题。简言之，不好判断问题是不是NP完全问题，但还是有一些经验的：
  - 元素较少时算法的运行速度非常快，但随着元素数量的增加，速度会变得非常慢。
  - 涉及“所有组合”的问题通常是NP完全问题
  - 不能将问题分成小问题，必须考虑各种可能的情况。这可能是NP完全问题
  - 如果问题涉及序列（如旅行商问题中的城市序列）且难以解决，它可能就是NP完全问题
  - 如果问题涉及集合（如广播台集合）且难以解决，它可能就是NP完全问题
  - 如果问题可转换为集合覆盖问题或旅行商问题，那它肯定是NP完全问题
> 面临NP完全问题时，最佳的做法是使用近似算法，例如贪心算法，易于实现、运行速度快。
- 使用动态规划时，要么考虑拿走整件商品，要么考虑不拿，而**没法判断**该不该拿走商品的一部分。但使用**贪心算法可轻松地处理**这种情况！首先，尽可能多地拿价值最高的商品；如果拿光了，再尽可能多地拿价值次高的商品，以此类推
- 动态规划功能强大，它能够解决子问题并使用这些答案来解决大问题，**但仅当每个子问题都是离散的，即不依赖于其他子问题时，动态规划才管用**
- **计算最终的解时会涉及两个以上的子背包吗？**根据动态规划算法的设计，最多只需合并两个子背包，即根本不会涉及两个以上的子背包。不过这些子背包可能又包含子背包
- **在问题可分解为彼此独立且离散的子问题时，就可使用动态规划来解决**，下面是一些技巧：
  - **每种动态规划解决方案都涉及网格**
  - 单元格中的值通常就是你要优化的值。
  - 每个单元格都是一个子问题，因此应考虑如果将问题分成子问题，这有助于找出网格的坐标轴
  - **没有放之四海而皆准的计算动态规划解决方案的公式**
  - 例如，**动态规划甚至可以解决最长公共子串问题**
    - 两个字符串都包含的最长字串的长度为要优化的值，所以这就是单元格中的值
    - 是要比较字串，而不是比较单词，故而坐标轴应该是两个单词
    - 算法：
      - 如果两个字母不相同，值为 0 
      - 如果两个字母相同，值为左上角邻居的值加 1
    - 需要注意的一点是，**这个问题的最终答案并不在最后一个单元格中，答案为网格中最大的数字**
- `git diff` 是用动态规划实现的

- 费曼算法（Feynman algorithm）
  - (1) 将问题写下来
  - (2) 好好思考
  - (3) 将答案写下来
- 在计算相似度时，我们通常可以使用余弦相似度或距离算相似度，具体使用哪种方法取决于数据的性质和具体问题的需求。
  - 余弦相似度（Cosine Similarity）：余弦相似度是衡量两个向量方向之间的相似性。**当我们关注向量的方向而不是其大小时**，通常使用余弦相似度。
    - 适用情况：
      - 当文本数据表示为向量（如词袋模型、TF-IDF向量）时，可以使用余弦相似度来比较文本之间的相似性。
      - 当我们关注特征的方向而不关心其大小时，如**推荐系统中的用户兴趣向量或文档主题向量**，可以使用余弦相似度。
    - 优点：
      - 对于高维稀疏数据（如文本），余弦相似度能够有效地忽略向量的大小差异，更关注向量的方向，适用于表示稀疏特征的数据。
    - 缺点：
      - 余弦相似度无法捕捉到向量之间的欧几里德距离（大小）信息，可能导致相似度计算不准确。
  - 距离相似度：距离相似度是通过计算向量之间的距离来度量它们的相似性。常见的距离度量包括欧几里德距离（Euclidean Distance）、曼哈顿距离（Manhattan Distance）和闵可夫斯基距离（Minkowski Distance）等。
    - 适用情况：
      - 当我们希望考虑向量的大小信息，或者关注向量之间的距离差异时，可以使用距离相似度。
      - **当特征空间较小且维度较低（非稀疏）时**，距离相似度通常更适用。
    - 优点：
      - 距离相似度可以准确地度量向量之间的距离差异，更适用于表示密集特征的数据。
    - 缺点：
      - **距离相似度在处理高维稀疏数据时可能会受到维度灾难（curse of dimensionality）的影响，计算复杂度较高。**
  - 综上所述，选择使用余弦相似度还是距离相似度取决于数据的特点和具体问题的需求。如果关注特征的方向而不关心其大小，或者处理高维稀疏数据，可以使用余弦相似度。如果需要考虑向量的大小信息，或者处理低维密集数据，可以使用距离相似度。
- **KNN中如果考虑的邻居太少，结果很可能存在偏差。一个不错的经验规则是：如果有N位用户，应考虑sqrt(N)个邻居**
- OCR指的是光学字符识别（optical character recongnition）
- **垃圾邮件过滤器采用的是朴素贝叶斯分类器（Naive Bayes classifier）**
- 在数组中查找时，最快的方式是二分查找，但问题是，每当有新数据插入数组时需要将数组重新排序，**因为二分查找仅在数组有序时才管用。如果能将数据插入到数组的正确位置就好了**，这样就无需在插入后再排序。为此，有人设计了一种名为**二叉查找树（binary search tree）**的数据结构
- 一个散列表，将单词映射到包含它的页面。这种数据结构被称为**反向索引（inverted index）**，常用于创建搜索引擎
- [An Interactive Guide To The Fourier Transform](https://betterexplained.com/articles/an-interactive-guide-to-the-fourier-transform/) 对于傅里叶变换做了一个绝佳的比喻：给它一杯冰沙，它能告诉你其中包含哪些成分。换言之，给定一首歌曲，**傅里叶变换能够将其中的各种频率分离出来**。所以，**傅里叶变换非常适合用于处理信号**，可使用它来压缩音乐。
- 在最佳情况下，排序算法的速度大致为$O(nlogn)$。众所周知，对数组进行排序时，除非使用并行算法，否则运行时间不可能为O(n)
- 并行算法，有一点是确定的，那就是**速度的提升并非线性的**，因此即便你的笔记本电脑**装备了两个而不是一个内核，算法的速度也不可能提高一倍**，其中的原因有两个。
  - **并行性管理开销**
  - **负载均衡**
- 有一种特殊的并行算法正越来越流行，它就是**分布式算法**。可让算法在多台计算机上运行。**MapReduce是一种流行的分布式算法**。分布式算法非常适用于在短时间内完成海量工作，**其中MapReduce基于两个简单的理念：映射（map）函数和归并（reduce）函数**
  - **map就是能够自动将工作分配给计算机，也就是说，映射时将一个数组转换为另一个数组**
  - **归并是将一个数组转换为一个元素**
- 当要索引的东西过多时，散列表就稍显乏力。是因为此时的散列表非常大，需要占用大量的存储空间。面临海量数据，**布隆过滤器**提供了解决之道。**布隆过滤器是一种概率性数据结构**，他提供的答案有可能不对，但很可能是正确的。
- 使用散列表时，答案绝对可靠，而使用布隆过滤器时，答案却是很可能是正确的。
  - **可能出现漏报的情况**，即指出存储了某个数据，但实际上没有存储
  - **不可能出现漏报的情况**，即如果布隆过滤器说没有存储某个数据，就肯定没有存储
  - 布隆过滤器的**优点在于占用的存储空间很少**，非常适用于不要求答案绝对准确的情况
- HyperLogLog是一种类似于布隆过滤器的算法
- 散列函数接受一个字符串，并返回一个索引号。**另一种散列函数是安全散列算法（secure hash algorithm，SHA）函数，给定一个字符串，SHA返回其散列值**.
  - **可以使用SHA来判断两个文件是否相同**，如果两个文件都很大，不需要一一对比，而可计算它们的SHA散列值，再对结果进行比较
  - SHA也可以用来检查密码，可以将密码转换为散列值，但反过来不行。也就是说**SHA是单向的**
- **SHA-0 和 SHA-1 已被发现存在一些缺陷**。如果要使用SHA算法来计算密码的散列值，应使用SHA-2 和SHA-3.当前，**最安全的密码散列函数是bcrypt**，但没有任何东西是万无一失的。
- SHA 还有一个重要特征，那就是**局部不敏感**的。也就是说假设有一个字符串，并计算了其散列值。如果修改其中一个字符，再计算其散列值，结果将截然不同！
- **如果希望散列函数是局部敏感的，可以使用Simhash**，需要检查两项内容的相似程度时，Simhash很有用
- Diffie-Hellman算法，它以优雅的方法解决了一个古老的问题：如何对消息进行加密，以便只有收件人才能看懂。Diffie-Hellman算法解决了如下两个问题：
  - **双发无需知道加密算法**。他们不必会面协商要使用的加密算法
  - **要破解加密的消息比登天还难**
- Diffie-Hellman使用两个密钥：公钥和私钥。Diffie-Hellman算法及其替代者**RSA**依然被广泛使用。
- **线性规划用于在给定约束条件下最大限度地改善指定的指标**。也就是说，最优化问题与线性规划关系密切。所有的图算法都可使用线性规划来实现。线性规划是一个宽泛得多的框架，图问题只是其中的一个子集。**线性规划使用Simplex算法**，很复杂。

> 上述内容来自《算法图解》