---
title: paper
date: 2023-05-14 20:32:31
tags:
declare: true
top : 1
---
#### 1. April 4, 2023(week 1)
Decision tree<!--more-->

|Title|Publication|Year|Authors|Area|Problem|Main Method|Datasets|
| :---:| :---:| :---:| :---:|:---:|:---:|:---:|:---:|
|Popular decision tree algorithms are provably noise|ICML|2022|Guy Blanc|Machine Learning|决策树算法的容忍性|基于杂质的决策树学习算法，包括经典的 ID3、C4.5 和 CART|[UCI 机器学习库中的 Wine 数据集](https://github.com/Heng-W/wine_classification)|
|Fast Provably Robust Decision Trees and Boosting|ICML|2022|Jun-Qi Guo|Machine Learning|稳健的决策树和用于对抗防御|AdaBoost(PRAdaBoost)|[OpenML](https://www.openml.org/) and [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)|

- Popular decision tree algorithms are provably noise tolerant
    - 这篇文章讲了什么？
    这篇论文使用了 boosting 框架，证明了所有基于不纯度的决策树学习算法，包括经典的 ID3、C4.5 和 CART 算法，都具有高度的噪声容忍性。这些保证适用于最强噪声模型，即恶意噪声，并且我们提供了允许的噪声率的近似上下界。此外，论文进一步表明，这些算法在嘈杂的环境中具有可证明的保证，这是现有决策树学习理论文献中现有算法无法匹配的。

- Fast Provably Robust Decision Trees and Boosting
    - 方法
        - 这篇文章使用了可证明鲁棒的AdaBoost(PRAdaBoost)算法，这是一种提高对抗性指数损失上界的提升算法，基本学习器是通过他们的FPRDT进行构建的，稍作修改。作者提出了训练对抗0/1损失的指数收敛分析方法，以验证其方法的有效性，并获得最小的O(nlogn)计算复杂度。
        
        - 文章中还介绍了一种决策树构建方法，即FPRDT。在构建决策树时，作者直接使用0/1损失而不是传统的代理损失，如平方损失和softmax损失，作为决策树构建过程中的分裂标准。这是因为这些代理损失与0/1损失之间在对抗性环境下的一致性不成立。另一个原因是在具有O(1)计算复杂度的情况下，通过分裂节点来进行鲁棒优化，而这些代理损失需要通过梯度下降以O(n)计算复杂度来实现。

        - 文章中还介绍了一种名为PRAdaBoost的提升算法，它使用PRDT作为基本学习器。PRAdaBoost旨在最小化对抗指数损失上界，并且具有指数收敛速度。

        - 文章中还介绍了一种名为Madry et al. (2018)的鲁棒学习方法，该方法旨在寻找一个假设h∈H，使得对于所有(xi,yi)∈S_n，都有maxℓ(h(x′), yi)≤ε，其中x′∈N_ε(xi)，ε是给定的扰动大小。

        - 文章中还介绍了一种名为Goodfellow et al. (2015)的对抗训练方法，在每个步骤中近似地解决内部最大化问题。

    - 提出了一种新的具有对抗鲁棒性的学习算法。 该论文解决了当代机器学习中具有对抗性鲁棒性学习的问题，这一直是一个巨大挑战。 所提出的算法具有高计算复杂性，但提供了可证明的鲁棒性保证。

> 对抗性鲁棒性是指在自然引起的图像损坏或更改的情况下保持模型性能。 换句话说，它是衡量机器学习模型抵抗对抗性攻击能力的指标。 对抗性攻击是恶意输入，旨在导致机器学习模型做出不正确的预测。


- 总结

1. 本文是关于一种快速且可证明稳健的决策树和用于对抗防御的提升算法。
2. 所提出的方法直接优化对抗性 0/1 损失，并实现比现有方法更好的性能和效率。
3. 该文件提供了理论分析、计算复杂性和实证结果来支持这些说法。
4. 该文档还讨论了鲁棒树集成的一些未来方向。

------------------------------------------

#### 2. April 4, 2023(week 2)
Linear Models and Neural Networks

|Title|Publication|Year|Authors|Area|Problem|Main Method|Datasets|
| :---:| :---:| :---:| :---:|:---:|:---:|:---:|:---:|
|[Near-optimal rate of consistency for linear models with missing values](https://proceedings.mlr.press/v162/ayme22a.html)|ICML|2022|Alexis Ayme|Machine Learning|输入值或者特征值缺失|利用缺失数据分布来进行预测，并提出了相应的自适应风险界限，这些界限是最小化的|无数据集，自行生成矩阵|
|[Fair Generalized Linear Models with a Convex Penalty](https://proceedings.mlr.press/v162/do22a.html)|ICML|2022|Hyungrok Do|Machine Learning|数据驱动的预测模型通常可以保留基础数据中存在的系统偏差，并可以将这些不平等传播到预测中|通过一种凸惩罚项来实现广义线性模型（GLM）的公平性|[开源](https://github.com/hyungrok-do/fair-glm-cvx)|
|[Non-Vacuous Generalisation Bounds for Shallow Neural Networks](https://proceedings.mlr.press/v162/biggs22a.html)|ICML|2022|Felix Biggs|Machine Learning|如何理解训练好的神经网络在未知数据上的泛化能力问题|PAC-Bayesian 理论推导出了一种新的泛化界限，并在实践中证明了其非空性。|MNIST and [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist)|

- [Near-optimal rate of consistency for linear models with missing values](https://proceedings.mlr.press/v162/ayme22a.html)
    - 文章发布在ICML
    - 时间为2022年
    - 作者：Alexis Ayme
    - 问题：对于大型模型，在现实生活中，总会出现缺失值这一问题，应该如何训练。
    - 解决方案：利用缺失数据分布来进行预测，并提出了相应的自适应风险界限，这些界限是最小化的
    - 数据集：没有数据集，自行生成了两个矩阵（U和T）。其中U是一个10x10的矩阵，用于计算协方差矩阵的特定块。T是一个Toeplitz矩阵，是用来演示一种特殊类型的矩阵。
    - [代码](https://github.com/AlexisAyme/minimax_linear_na/blob/main/Minimax_linear_na.ipynb)
    - 总结
    文章中提到，缺失值在数据集中越来越普遍，这些缺失值可能由于多个来源而产生，例如传感器故障、拒绝回答调查问题或来自不同来源（具有不同数据收集方法）的数据聚合。文章提出了一种严格的设置来分析最小二乘估计器，并建立了一个关于超额风险的界限，其随着维度呈指数增长。
    在这种情况下，Bayes预测器可以分解为与每个缺失模式相对应的预测器的总和。这最终需要解决许多学习任务，其数量随着输入特征的数量呈指数级增长，这使得当前真实世界数据集的预测变得不可能。作者提出了一种新算法，利用缺失数据分布，并推导出相关的自适应风险界，这些界限是最小化的。数值实验突出了作者方法相对于用于具有缺失值的预测的最先进算法的好处。

---------------------------------

- [Fair Generalized Linear Models with a Convex Penalty](https://proceedings.mlr.press/v162/do22a.html)
    - 文章发布在ICML
    - 时间为2022年
    - 作者：Hyungrok Do
    - 问题：数据驱动的预测模型通常可以保留基础数据中存在的系统偏差，并可以将这些不平等传播到预测中。例如，在与种族相关的犯罪累犯预测、与性别相关的求职者排名、与种族和性别相关的人脸识别，以及与性别、种族和保险状况相关的多种医疗保健应用。
    - 对于fairness（公平性）的理解。是指算法的输出不会因为个人特征（例如性别、种族、年龄等）而产生偏见。举个例子，如果一个机器学习算法用于预测贷款申请人是否会违约，那么算法应该不会因为申请人的种族或性别而产生偏见。
    - 解决方案：在这篇论文中，作者提出了两种基于广义线性模型（GLMs）的公平性标准，分别是通过平衡预期结果或对数似然来实现的。作者证明了对于GLMs，这两个标准都可以通过仅基于GLM的线性组件的凸惩罚项来实现，从而允许高效优化。作者还推导了所得到的公平GLM估计量的理论性能。
    - 附加知识
    广义线性模型（GLM）是一种广泛使用的统计模型，用于建立响应变量Y与一个或多个解释变量X之间的关系。GLM提供了一种自然和系统化的方法来处理各种不同类型的响应变量Y，包括实值、二元、分类、序数和计数结果。更具体地说，GLM可以被视为标准线性回归的推广，其中对Y的条件分布的正态性假设被放松以允许一系列分布形式，包括二项式、多项式和泊松分布。
    相对于其他机器学习模型，GLM有以下优点：
        - GLM具有更简单的功能形式。
        - GLM可以处理各种类型的响应变量。
        - GLM可以通过加入惩罚项来实现公平性。
    一言以蔽之：作者证明了GLM可以为除二元和连续结果之外的一系列响应变量生成公平预测。结合一个仅基于GLM线性分量的凸惩罚项就OK。
    - [代码和数据集](https://github.com/hyungrok-do/fair-glm-cvx)

-------------------------------------

- [Non-Vacuous Generalisation Bounds for Shallow Neural Networks](https://proceedings.mlr.press/v162/biggs22a.html)
    - 文章发布在ICML
    - 时间为2022年
    - 作者：Felix Biggs
    - 问题：如何理解训练好的神经网络在未知数据上的泛化能力问题。
    - 方法：因此，作者使用 PAC-Bayesian 理论推导出了一种新的泛化界限，并在实践中证明了其非空性。作者还研究了一类具有单个隐藏层的浅层神经网络，并通过 PAC-Bayesian 理论推导出了新的泛化界限。这些结果表明，PAC-Bayesian 理论可以用于深度学习中神经网络的泛化性能分析。
    - 文章内容
    这篇文章主要讲了一种特定类型的**浅层神经网络**，即具有 $L_2$ normalised data 和 sigmoid shaped 的高斯误差函数激活或高斯误差线性单元激活的网络。作者们通过**PAC-Bayesian**理论推导出了这些网络的新的泛化界限。与大多数现有的泛化界限不同，它们适用于具有**确定性而不是随机参数**的神经网络。作者们的界限在MNIST、Fashion-MNIST和上述二元分类版本上进行了实证，当网络使用SGD训练时，它们是**非空**的。
        - 浅层神经网络：单个隐藏层
        - PAC-Bayesian 理论是一种概率不等式，它可以用于分析机器学习算法的泛化性能。深度学习 PAC-Bayesian 理论是将 PAC-Bayesian 理论应用于深度学习的一种方法。**PAC-Bayesian 理论的一个重要应用是推导出泛化误差的上界，这个上界可以用于评估模型的泛化性能。**
        - 确定性参数：是指其参数是固定的，而不是随机的。
        - 非空：非空的界限是指它们不是无用的，即它们可以在实践中使用。

    这篇文章还讨论了深度神经网络的泛化性质，以及如何理解训练后的神经网络在哪些情况下可能成功或失败。作者们提出了一种新的方法来利用SGD在数据集上的稳定性，从而获得紧密的边界。
    
    一言以蔽之：这篇论文解决了如何理解训练好的神经网络在未知数据上的泛化能力问题。
    这篇论文还提出了一种新方法来计算深度神经网络的平均输出，该方法可以用于构建更复杂的多数投票。通过这种方法，我们获得了这些确定性预测器的分类界限。

    - 附加内容
    PAC-Bayesian理论是一种理论框架，旨在量化机器学习算法的泛化误差，这是指模型在未见过的数据上的性能。PAC-Bayesian理论是基于概率不等式和贝叶斯方法的结合而来的。

    PAC-Bayesian理论的基本思想是通过衡量假设类（例如，分类器）的复杂度和训练数据的复杂度之间的平衡来解决泛化问题。简而言之，PAC-Bayesian理论提供了一个工具，可以根据学习算法的复杂度和训练数据的复杂度来控制泛化误差的上限。

    具体来说，PAC-Bayesian理论利用了KL散度和Hoeffding不等式等工具来量化泛化误差的上界。通过将模型的先验分布和训练数据的分布结合起来，PAC-Bayesian理论可以提供更加准确的泛化误差上界。
    
    PAC-Bayesian理论在理论计算机科学和机器学习中得到了广泛的应用，并已经成为了许多学习算法的理论基础之一。

---------------------------------------------------

#### 3. April 11, 2023(week 3)
Neural Networks

|Title|Publication|Year|Authors|Area|Problem|Main Method|Datasets|
| :---:| :---:| :---:| :---:|:---:|:---:|:---:|:---:|
|[Neural Fisher Discriminant Analysis: Optimal Neural Network Embeddings in Polynomial Time](https://proceedings.mlr.press/v162/bartan22a.html)|ICML|2022|Burak Bartan|Machine Learning|优化（FLDA）的判别标准|NFDA 利用神经网络来扩展 FLDA，找到最优的两层神经网络。作者使用凸优化工具将最优神经网络嵌入问题转换为凸问题。该方法易于解释和全局最优解。|开源|
|[Certified Neural Network Watermarks with Randomized Smoothing](https://proceedings.mlr.press/v162/bansal22a.html)|ICML|2022|Arpit Bansal|Machine Learning|水印的不安全性导致了版权的不安全性|提出了一种可验证的水印方法，使用随即平滑技术，证明了水印在模型参数改变不超过一定的距离时是无法移除的。|MNIST and [CIFAR-10/100](https://www.cs.toronto.edu/~kriz/cifar.html)|
|[An Initial Alignment between Neural Network and Target is Needed for Gradient Descent to Learn](https://proceedings.mlr.press/v162/abbe22a.html)|ICML|2022|Emmanuel Abbe|Machine Learning|神经网络在初始化时与目标函数之间的初始对齐是否必要|通过数学证明了如果网络和布尔目标函数没有明显的INAL，则具有归一化 $i.i.d.$ 初始化的全连接网络上的噪声梯度下降不会在多项式时间内学习。因此，在架构设计中需要一定量的关于目标的知识（由INAL衡量）。|[CIFAR-10/100](https://www.cs.toronto.edu/~kriz/cifar.html)|
|[Going Deeper into Permutation-Sensitive Graph Neural Networks](https://proceedings.mlr.press/v162/huang22l.html)|ICML|2022|Zhongyu Huang|Machine Learning|传统的置换不变聚合方式可能会忽略邻居节点之间的关系，从而限制了GNN的表达能力。|通过置换群来捕捉邻居节点之间的成对相关性。|开源|
|[Lazy Estimation of Variable Importance for Large Neural Networks](https://proceedings.mlr.press/v162/gao22h.html)|ICML|2022|Yue Gao|Machine Learning|神经网络中变量对于网络的影响程度有多大|采用惰性估计 + Ridge-like penalty（类岭回归惩罚）|自行生成点 + [CESM-LENS](https://www.earthsystemgrid.org/home.html)|
|[NeuralEF: Deconstructing Kernels by Deep Neural Networks](https://proceedings.mlr.press/v162/deng22b.html)|ICML|2022|Zhijie Deng|Machine Learning|难以确定正确的核函数进行近似逼近|通过神经网络来近似核函数的特征值和特征向量|[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)|

------------------------------

- [Neural Fisher Discriminant Analysis: Optimal Neural Network Embeddings in Polynomial Time（神经 Fisher 判别分析：多项式时间内的最优神经网络嵌入）](https://proceedings.mlr.press/v162/bartan22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Burak Bartan and Mert Pilanci (Department of Electrical Engineering, Stanford University, CA, USA.)
  - 问题：优化（FLDA）的判别标准
  - 方法：NFDA 利用神经网络来扩展 FLDA，找到最优的两层神经网络。作者使用凸优化工具将最优神经网络嵌入问题转换为凸问题。该方法易于解释和全局最优解。
  - 先修知识
    - 线性判别分析（LDA）
    线性判别分析（LDA）是一种经典的机器学习方法，它可以用于分类问题。它的目的是通过将数据投影到低维空间中，来最大化类别之间的差异，最小化类别内部的差异。
    具体来说，LDA 将数据投影到一条直线上（对于二分类问题）或者一个低维平面上（对于多分类问题），以最大化类别之间的距离，同时最小化类别内部的方差。这可以通过计算类别之间的协方差矩阵和总体协方差矩阵来实现。
    LDA 最常用于二分类问题，但也可以用于多分类问题。在多分类问题中，LDA 可以将数据投影到一个比样本数少一个的低维空间中，从而获得一个鲁棒性较好的分类器。
    LDA 的优点包括：（1）它可以提高分类准确性；（2）它可以减少数据维度，从而降低计算成本；（3）它可以在数据分布不平衡的情况下获得比其他分类器更好的性能。
    LDA 的缺点包括：**（1）它只能处理线性可分的问题；（2）它对于噪声和离群点敏感；**（3）它需要假设样本的协方差矩阵是相同的，这在一些情况下可能不成立。
    在实践中，LDA 可以与其他分类器（如逻辑回归、支持向量机等）结合使用，以获得更好的性能。
    - Fisher’s Linear Discriminant Analysis（FLDA）
    Fisher’s Linear Discriminant Analysis（FLDA）是线性判别分析（LDA）的一个扩展，也被称为Fisher判别分析。FLDA与LDA非常相似，但是FLDA的目标是在保留最大类别差异的同时最小化类别内部的方差，并且不像LDA，**FLDA不需要假设类别协方差矩阵相同**。与LDA不同的是，FLDA可以用于解决非线性可分的问题。
    FLDA的核心思想是将数据从原始空间投影到一个新的低维空间中，使得在该空间中不同类别之间的距离尽可能大，同一类别之间的距离尽可能小。**FLDA通过计算类别之间的Fisher判别量来实现这个目标。Fisher判别量是类别之间的差异除以类别内部的方差，最大化这个量等价于最小化类别内部的方差，同时最大化类别之间的差异。**
    FLDA可以被用于解决许多分类问题，例如人脸识别、语音识别、手写数字识别等。它在降低数据维度的同时提高了分类精度，因此被广泛应用于数据挖掘、机器学习和模式识别等领域。
    FLDA的主要优点包括：（1）**可以解决非线性可分问题**；（2）可以处理高维数据；（3）可以提高分类准确性。
    FLDA的缺点包括：（1）FLDA在处理高维数据时可能出现过拟合；（2）FLDA需要计算类别之间的协方差矩阵，这可能会带来一定的计算复杂度。
  - 文章内容
  正如本文标题所述，作者介绍了一种叫做 **NFDA** 的东西，NFDA 利用神经网络来扩展 FLDA，找到最优的两层神经网络，以优化相同的判别准则。作者使用凸优化工具将最优神经网络嵌入问题转换为凸问题。该方法易于解释和全局最优解。作者在合成和真实数据集上评估了该方法的性能。具体来讲，作者通过证明匹配下限和上限来表明其算法找到了这个目标的全局最优解。
  - 数据集
    - [Two Spirals Dataset](https://conx.readthedocs.io/en/latest/Two-Spirals.html) 是一个含有两个类的螺旋数据集。
    - MNIST Dataset
    - [The Yale Face dataset](https://www.kaggle.com/datasets/olgabelitskaya/yale-face-database) 含有165张人脸灰度图像，据集包括每个受试者11张图像，每张图像对应不同的配置，如不同的光线、戴眼镜或不戴眼镜、睡意朦胧的面部表情等。
  - 总结
  Neural Fisher Discriminant Analysis (NFDA) 是 Fisher Linear Discriminant Analysis (FLDA) 与神经网络的结合体，旨在通过神经网络的非线性变换提高分类性能。
  NFDA 的核心思想是使用神经网络作为一个特征变换器，将原始数据映射到一个新的特征空间中。在这个新的特征空间中，FLDA 被用来计算 Fisher 判别量，并用于分类。这个过程可以被看作是神经网络的训练过程，其中神经网络的权重被优化以最大化 Fisher 判别量，从而提高分类准确性。
  相比于传统的 FLDA，NFDA 具有以下优势：
    - 对于非线性可分问题，NFDA 可以通过神经网络的非线性变换提高分类性能。
    - 通过神经网络的训练，NFDA 可以自动学习数据的特征表示，从而减少手动特征工程的需求。
    - 在高维数据集上，NFDA 可以利用神经网络的特征选择功能，自动选择与分类相关的特征。
  NFDA 的主要缺点包括：
    - 需要大量的计算资源和时间来训练神经网络。
    - 对于小数据集，NFDA 可能会出现过拟合问题。
    - 对于复杂的神经网络结构，可能难以解释和理解分类器的决策过程。
  总之，NFDA 是一个有前途的分类方法，它通过神经网络的非线性变换提高了传统 FLDA 的分类性能。然而，它也需要在计算资源和时间方面做出妥善的安排，以满足实际应用的需求。

--------------------------------------

- [Certified Neural Network Watermarks with Randomized Smoothing（具有随机平滑的认证神经网络水印）](https://proceedings.mlr.press/v162/bansal22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Arpit Bansal and Ping-yeh Chiang (马里兰大学帕克分校 University of Maryland, College Park)
  - 问题：水印的不安全性导致了版权的不安全性
  - 方法：提出了一种可验证的水印方法，使用随即平滑技术，证明了水印在模型参数改变不超过一定的距离时是无法移除的。
  - 文章内容
  水印是保护创作者对数字图像、视频和音频的权利的常用策略。最近，水印方法已经扩展到深度学习模型。原则上，当对手试图复制模型时，水印应该被保留。
  这篇文章介绍了一种新的神经网络水印技术，可以保护数字图像、视频和音频的版权。作者提出了一种可验证的水印方法，使用随机平滑技术，证明了水印在模型参数改变不超过给定 $L_2$ 阈值时是无法移除的。此外，作者还发现，与以前的水印方法相比，他们的水印在实践中更加稳健。
  - 先修知识
  随机平滑技术（Random Smoothing）是一种用于提高深度神经网络（DNN）鲁棒性的技术，由 Chiang 等人在 2020 年提出。
  在深度学习中，DNN 模型容易受到对抗样本的攻击，即通过对原始样本进行微小的扰动来欺骗模型。这种攻击可能导致模型的误判，从而对机器学习系统的可靠性和安全性造成威胁。为了提高模型的鲁棒性，研究人员提出了一些对抗训练（Adversarial Training）方法，其中包括随机平滑技术。
  随机平滑技术的核心思想是，通过对输入样本进行随机扰动，从而生成多个类似于原始样本的扰动样本，并将这些扰动样本作为训练数据，用于训练模型。具体而言，随机平滑技术将原始样本 x 加上一些随机噪声 r，得到一个扰动样本 $x'=x+r$。随机噪声 r 的大小和方向是随机选择的，这样就可以生成多个扰动样本。然后，模型使用这些扰动样本进行训练，从而使其能够更好地适应不同的输入样本。
  随机平滑技术的优点是它可以增加模型的鲁棒性，从而降低对抗攻击的影响。此外，随机平滑技术还可以作为一种正则化方法，有助于防止模型过拟合。然而，随机平滑技术也存在一些缺点，比如增加了训练时间和内存占用，以及可能会对模型的性能产生一定的负面影响。
  总之，随机平滑技术是一种有效的对抗训练方法，它可以提高深度神经网络的鲁棒性，从而增强机器学习系统的可靠性和安全性。
  - 数据集
    - [CIFAR-10/100](https://www.cs.toronto.edu/~kriz/cifar.html)
    CIFAR-10数据集由10类中的60000 32x32颜色图像组成，每个类别有6000张图像。有50000个培训图像和10000个测试图像
    - MNIST

-----------------------------------------

- [An Initial Alignment between Neural Network and Target is Needed for Gradient Descent to Learn（梯度下降学习需要神经网络和目标之间的初始对齐）](https://proceedings.mlr.press/v162/abbe22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Emmanuel Abbe (洛桑联邦理工学院数学研究所)
  - 问题：神经网络在初始化时与目标函数之间的初始对齐是否必要
  - 方法：通过数学证明了如果网络和布尔目标函数没有明显的INAL，则具有归一化 $i.i.d.$ 初始化的全连接网络上的噪声梯度下降不会在多项式时间内学习。因此，在架构设计中需要一定量的关于目标的知识（由INAL衡量）。
  - 先修知识
    - Initial Alignment (INAL) 即初始对齐
    在深度学习中，神经网络的训练通常是通过对目标函数进行优化来实现的。在进行优化之前，需要对神经网络中的参数进行初始化。这个过程就叫做初始对齐（Initial Alignment, INAL）。
    初始对齐的目标是让神经网络中的参数具有一定的初始值，以便更好地拟合训练数据。这是因为如果将所有的参数都设置为随机值，那么神经网络就会很难在初始阶段就找到一个合适的初始点。**（请类比迁移学习的思想）**
    常见的初始对齐方法包括：
      - 随机初始化：将网络的所有参数都设置为随机值。这种方法简单易行，但很难保证网络能够快速收敛到最优解。
      - 均匀分布初始化：将网络的参数设置为在一定范围内的均匀分布值。这种方法相对随机初始化更加稳定，但需要对每个参数都进行手动调整。
      - 高斯分布初始化：将网络的参数设置为高斯分布的随机值。这种方法比随机初始化更加稳定，但需要对每个参数都进行手动调整。
      - Xavier 初始化：根据网络输入和输出的维度，对网络的参数进行随机初始化。这种方法比均匀分布和高斯分布更加稳定，但需要对每个参数都进行手动调整。
      - He 初始化：根据网络输入和输出的维度，对网络的参数进行高斯分布随机初始化。这种方法比 Xavier 初始化更加稳定，但同样需要对每个参数都进行手动调整。
    **举例**
    如果我们要训练一个用于图像分类的神经网络，那么在进行训练之前，我们需要对神经网络进行初始化，即进行初始对齐。我们可以使用 Xavier 或 He 等初始化方法来设置神经网络中的权重和偏置等参数。这样就可以确保神经网络能够更快地找到最优解，同时提高网络的准确性和泛化能力。
    总的来说，初始对齐是深度学习中一个非常重要的步骤，可以帮助神经网络更快地学习到最优解，提高网络的准确性和泛化能力。不同的初始对齐方法适用于不同的情况，需要根据具体的应用场景选择合适的方法。
  - 数据集
  同上[CIFAR](https://www.cs.toronto.edu/~kriz/cifar.html)
  - 结论
  一言以蔽之，初始对齐十分必要。神经网络和目标函数之间需要有一个**初始对齐（INAL）**，才能在多项式时间内通过噪声梯度下降学习。因此，在架构设计中需要一定量的关于目标的知识（由INAL测量）。

-----------------------
- [Going Deeper into Permutation-Sensitive Graph Neural Networks](https://proceedings.mlr.press/v162/huang22l.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Zhongyu Huang (中科院、清华、微软亚院)
  - 问题：传统的置换不变聚合方式可能会忽略邻居节点之间的关系，从而限制了GNN的表达能力。
  - 方法：通过置换群来捕捉邻居节点之间的成对相关性。
  - 先修知识
    - 置换不变聚合
    图神经网络（Graph Neural Networks, GNNs）是一种针对图结构数据的深度学习模型。在图神经网络中，节点和边都被视为数据，因此需要考虑如何对这些数据进行聚合。
    置换不变聚合是一种常见的聚合方式，它在图神经网络中得到了广泛的应用。这种聚合方式的基本思想是：对于图中的每个节点，将其与其周围的节点进行聚合，生成一个新的节点表示，这个表示应该与其他节点的表示没有任何区别。换句话说，置换不变聚合方式是指，在图中对称的节点应该具有相同的表示。
    常见的置换不变聚合方式包括最大池化（max-pooling）、均值池化（mean-pooling）和逐元素求和（element-wise summation）等。这些方法都是在节点之间进行局部操作，得到一个新的节点表示。
    最大池化和均值池化是比较简单的聚合方式，它们分别将节点的特征向量中的最大值和平均值作为新的节点表示。逐元素求和是将节点特征向量中对应元素相加得到新的节点表示。
    需要注意的是，在置换不变聚合方式中，**不同节点之间的顺序是无关紧要的，因为节点之间的相对位置对于生成节点表示并没有影响。**
    - 2-WL图同构测试
    2-WL图同构测试是一种基于Weisfeiler-Lehman算法的图同构测试方法。Weisfeiler-Lehman算法是一种广泛使用的图分割算法，它可以将每个节点的邻居节点信息聚合到节点本身的标签中，用于判断两个节点是否在同一个局部结构中。
    在2-WL图同构测试中，我们首先将每个节点的标签初始化为其节点ID，并按照Weisfeiler-Lehman算法的方式迭代更新节点标签。在每次迭代中，对于每个节点，我们将其与其一阶邻居的标签按照某种规则（比如排序后拼接）进行拼接，并将拼接后的标签作为节点的新标签。这个过程类似于哈希表，可以将一个图的节点信息哈希为一个字符串。
    最终，我们比较两个图的哈希字符串是否相同来判断它们是否同构。如果哈希字符串相同，则认为两个图同构；否则，认为它们不同构。
    2-WL图同构测试是一种快速而有效的图同构测试方法，可以在多项式时间内完成测试。它在化学、计算机视觉等领域得到了广泛应用。
    **例子**
    假设我们有两个无向图，分别为图G和图H：
```shell
G
1---2
/ \ / \
3---4---5

H
1---2
/ \ / \
3---4---5
```
    这两个图在结构上是相似的，但是它们的节点ID不同。我们可以使用2-WL图同构测试来判断它们是否同构。具体步骤如下：
    1. 首先，我们将每个节点的标签初始化为其节点ID，如下所示：
```shell
G:
1-1, 2-2, 3-3, 4-4, 5-5

H:
1-1, 2-2, 3-3, 4-4, 5-5
```
    2. 然后，我们按照Weisfeiler-Lehman算法的方式迭代更新节点标签。对于每个节点，我们将其与其一阶邻居的标签按照某种规则（比如排序后拼接）进行拼接，并将拼接后的标签作为节点的新标签。具体步骤如下：
```shell
G:
1-1, 2-2, 3-34, 4-1245, 5-345

H:
1-1, 2-2, 3-34, 4-1245, 5-345
```
    3. 我们比较两个图的哈希字符串是否相同。由于它们的哈希字符串相同，因此我们认为这两个图同构。
    因此，通过2-WL图同构测试，我们可以判断这两个图是同构的。
    - 3-WL图同构测试
    3-WL图同构测试是一种基于Weisfeiler-Lehman算法的图同构测试方法，与2-WL图同构测试类似，但在更新节点标签时使用了更多的邻居信息。
    在3-WL图同构测试中，我们首先将每个节点的标签初始化为其节点ID，并按照Weisfeiler-Lehman算法的方式迭代更新节点标签。在每次迭代中，对于每个节点，我们将其与其一阶和二阶邻居的标签按照某种规则（比如排序后拼接）进行拼接，并将拼接后的标签作为节点的新标签。这个过程将更多的邻居信息合并到了节点标签中，提高了判断两个节点是否在同一个局部结构中的准确性。
    与2-WL图同构测试类似，最终我们比较两个图的哈希字符串是否相同来判断它们是否同构。如果哈希字符串相同，则认为两个图同构；否则，认为它们不同构。
    3-WL图同构测试比2-WL图同构测试更准确，但也更耗时，需要进行更多的迭代和比较操作。在实际应用中，可以根据具体情况选择合适的图同构测试方法。
    - 2-WL 与 3-WL之间的对比
    2-WL图同构测试和3-WL图同构测试都是基于Weisfeiler-Lehman算法的图同构测试方法。两者最主要的区别在于节点标签的更新方式。
    在2-WL图同构测试中，节点的标签仅包含节点ID和一阶邻居的标签，而在3-WL图同构测试中，节点的标签还包含了二阶邻居的标签。因此，3-WL图同构测试比2-WL图同构测试使用了更多的邻居信息，可以提高判断两个节点是否在同一个局部结构中的准确性。

    然而，这种提高准确性的代价是计算复杂度的增加。在每次迭代中，3-WL图同构测试需要考虑更多的邻居标签，因此比2-WL图同构测试更耗时。具体而言，3-WL图同构测试的时间复杂度为 $O(dnlogn)$ ，其中d是图的最大度数，n是节点数。相比之下，2-WL图同构测试的时间复杂度为 $O(nlogn)$。
    因此，在实际应用中，我们需要根据具体情况选择合适的图同构测试方法。如果需要更高的准确性并且可以承受更高的计算复杂度，则可以选择3-WL图同构测试；如果计算效率更为关键，则可以选择2-WL图同构测试。
  - 文章内容
  邻接矩阵排列的不变性，即图同构，是图神经网络 (GNN) 的首要要求。按照惯例，这个先决条件可以通过聚合消息时对节点排列的不变操作来满足。然而，这种不变的方式可能会忽略相邻节点之间的关系，从而阻碍 GNN 的表达能力。
  作者提出了一种高效的置换敏感聚合机制，通过置换群来捕捉邻居节点之间的成对相关性。能够在保证表达能力的同时显着降低计算复杂度。据我们所知，到目前为止，我们的方法在 2-WL 测试之外的所有 GNN 中实现了最低的时间和空间复杂度。作者证明了他们的方法比2-WL图同构测试更强大，不比3-WL测试差，并且实现了线性采样复杂度。作者在多个合成和真实数据集上进行了全面的实验，证明了他们模型的优越性。
  - 数据集
  作者在实验部分中提到了他们使用了多个合成和真实数据集来评估他们的模型。其中包括Cora、Citeseer、Pubmed、PPI、Reddit等数据集。
  - 附加内容
  置换敏感聚合机制是一种在图神经网络中用于节点特征聚合的方法，它可以保证节点特征在考虑不同邻居时保持不变，从而增强了模型对于置换对称性的处理能力。
  在传统的图神经网络中，节点的特征聚合通常是基于加权平均或者池化操作实现的，这样的聚合方式是对置换对称性不敏感的。也就是说，如果将图中的节点进行任意置换，这样的聚合方式得到的结果不会发生改变，导致模型无法处理置换对称性。
  置换敏感聚合机制通过引入一组置换矩阵来解决这个问题。 具体来说，**对于一个节点，我们将它的特征向量和它的每一个邻居节点的特征向量分别拼接成一个新的向量，然后再将这个新向量与置换矩阵相乘得到一个新的聚合向量。** 这样，通过将置换矩阵作用于节点特征，我们可以保证在考虑不同邻居时节点特征保持不变，从而增强了模型对置换对称性的处理能力。
  需要注意的是，不同的置换矩阵可以用来捕捉不同的置换对称性，因此，在实践中，我们可以使用多个不同的置换矩阵来进行特征聚合，并将它们拼接起来作为最终的聚合结果，以增强模型对置换对称性的处理能力。

----------------------

- [Lazy Estimation of Variable Importance for Large Neural Networks（大型神经网络变量重要性的惰性估计）](https://proceedings.mlr.press/v162/gao22h.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Yue Gao （威斯康星大学）
  - 问题：神经网络中变量对于网络的影响程度有多大
  - 方法：采用惰性估计 + Ridge-like penalty（类岭回归惩罚）
  - 先修知识
    - 神经网络中变量的重要性
    在神经网络中，每个变量（如权重、偏置等）都对网络的输出有一定的影响。变量的重要性是指对于神经网络的输出，某个变量对输出的影响程度有多大。在机器学习中，评估变量的重要性对于理解和优化神经网络非常重要。通过评估变量的重要性，**可以找出对网络输出影响较大的变量**，从而进行针对性的优化，提高网络的性能和准确性。**（类比舒宁师姐讲的Influence Patterns for Explaining Information Flow in BERT这篇文章）**
    - 惰性估计
    在机器学习中，通常需要对模型中的变量进行评估和选择，以**确定哪些变量对于模型的性能影响最大**。其中一种常用的方法是计算每个变量的**重要性得分**，然后根据得分对变量进行排序和选择。
    惰性估计是一种计算变量重要性得分的方法，它可以减少计算量和内存消耗。**惰性估计的基本思想是，对于每个变量，记录它在模型中的使用次数和对输出的影响程度，然后根据这些记录计算变量的重要性得分。**与其他计算变量重要性得分的方法不同，惰性估计只需要在需要时对变量的使用情况进行记录，而不需要在每次迭代中都重新计算得分。这样可以大大减少计算量和内存消耗，特别是在大型神经网络中。
    - Ridge-like penalty（类岭回归惩罚）
    在神经网络中，Ridge-like penalty（类岭回归惩罚）通常是指在损失函数中加入一个正则化项，以防止模型过度拟合训练数据。
    具体来说，Ridge-like penalty是指对模型中的**权重矩阵进行正则化**，通常采用 $L_2$ 范数对权重矩阵进行惩罚。$L_2$ 正则化可以通过对每个权重的平方和乘以一个正则化参数来实现。这个正则化参数控制了正则化项的强度，可以通过交叉验证等方法来确定。
    加入Ridge-like penalty可以使得权重矩阵中的元素不会过大，从而避免过度拟合，提高模型的泛化能力。Ridge-like penalty常常与其他的正则化方法，如Dropout一起使用，以进一步提高模型的性能。
  - 文章内容
  随着不透明的预测模型越来越多地影响现代生活的许多领域，人们对量化给定输入变量的重要性以进行特定预测的兴趣与日俱增。
  面对量刑、医疗保健和教育等方面的算法决策，黑盒机器学习方法是不够的，而致力于开发更具可解释性的方法变得越来越重要。**也就是说，必须要说明是哪些因素导致它做出了这个决策。（类比西瓜）**
  **本文关键思想**是在转换后的训练数据上训练一个新模型，类似于再训练，但是在以从原始（未减少的）训练数据中学习的模型参数为中心的模型的线性化版本上。作者在梯度特征空间中对这个线性化模型执行岭回归，**这意味着作者的惰性再训练过程可以非常快速地计算。**
  总之，本文的主要贡献是一种新的、计算高效的估计方法，在使用大型神经网络时在模型不可知和无分布的设置中具有统计性​​能保证。
  - 一言以蔽之，网络很深，梯度爆炸，采用最重要节点＋最优路径。而权重和偏置可以采用惰性估计来进行评估重要性，进行针对性学习。本文中的理论为提高神经网络的可解释性计算效率迈出了重要一步。
  - 数据集
    - 随即生成一些点，进行分类
    - [CESM-LENS](https://www.earthsystemgrid.org/home.html)
    CESM-LENS是美国国家大气研究中心（NCAR）开发的一个全球气候模式集合，由一个全球气候模式（CESM）的多个版本构成，每个版本都使用不同的随机数种子生成不同的初值来模拟未来的气候变化情况。LENS是”Large Ensemble”的缩写，表示该集合包含了许多模拟实验。
    由于CESM-LENS的数据集体积庞大，需要大量的存储空间和计算资源进行处理和分析，因此通常需要使用高性能计算机和专业的数据处理工具来处理和分析这些数据。
    **下载CESM-LENS数据集需要注册成为该网站的用户，并且需要获得特定的许可证。在使用数据集时，也需要遵守相关的使用条款和规定。**

-------------------

- [NeuralEF: Deconstructing Kernels by Deep Neural Networks（而且可以用于处理复杂高维数据）](https://proceedings.mlr.press/v162/deng22b.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Zhijie Deng （清华）
  - 问题：难以确定正确的核函数进行近似逼近
  - 方法：通过神经网络来近似核函数的特征值和特征向量
  - 从论文标题 **NeuralEF: Deconstructing Kernels by Deep Neural Networks** 可以提炼出以下信息
    - 论文的主题是 “NeuralEF”，即神经网络对核函数的解构。
    - 该论文通过深度神经网络实现了对核函数的解构。
    - 论文探讨了神经网络解构核函数的优点和应用。
    - 论文的作者可能是关注于机器学习、神经网络以及核函数等领域的专家。
  - 先修知识
    - 神经网络对核函数的解构
    在机器学习领域中，核函数通常用于将输入数据从低维空间映射到高维空间，从而提高模型的分类性能。然而，这些核函数通常是经过人工设计的，并且在使用中可能存在一些缺陷，例如选择不合适的核函数可能导致模型欠拟合或过拟合等问题。
    神经网络对核函数的解构是指使用深度神经网络来学习核函数的组成部分，例如基函数或权重，从而更好地理解和优化核函数的性能。这种方法可以减少对人工设计核函数的依赖，并且在某些情况下可以提高模型的泛化性能。因此，神经网络对核函数的解构是一种有前途的研究方向，可以帮助改进机器学习中的核方法。
  - 代码和数据集
    - [代码](https://github.com/thudzj/neuraleigenfunction)
    - 数据集：[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)
  - 文章内容
  这篇论文提出了一种新的方法，通过神经网络来近似核函数的特征值和特征向量。这种方法可以在大数据集上进行训练，而且可以用于多种核函数，包括多项式核函数、径向基核函数、神经网络高斯过程核函数和神经切向核函数。这种方法可以用于无监督学习和监督学习，可以用于**特征提取和分类**等任务。而且可以用于处理复杂高维数据。

---------------------
#### 4. April 18, 2023(week 4)
Neural Networks

|Title|Publication|Year|Authors|Area|Problem|Main Method|Datasets|
| :---:| :---:| :---:| :---:|:---:|:---:|:---:|:---:|
|[SE(3) Equivariant Graph Neural Networks with Complete Local Frames](https://proceedings.mlr.press/v162/du22e.html)|ICML|2022|Weitao Du|Machine Learning|对于GNN的信息构建，如何权衡表达能力和计算效率？|引入等变局部完整框架来构建等变图神经网络。|开源|
|[DepthShrinker: A New Compression Paradigm Towards Boosting Real-Hardware Efficiency of Compact Neural Networks](https://proceedings.mlr.press/v162/fu22c.html)|ICML|2022|Yonggan Fu|Machine Learning|模型的硬件利用率偏低|提出了一种新的压缩范式，并提出 DepthShrinker 通过将不规则块合并到密集操作中来开发硬件高效的紧凑型 DNN 提高实际硬件效率|[MobileNetV2](https://www.kaggle.com/code/mgiraygokirmak/mobilenetv2)|
|[p-Laplacian Based Graph Neural Networks](https://proceedings.mlr.press/v162/fu22e.html)|ICML|2022|Guoji Fu|Machine Learning|大多数gnn隐含地假设图中节点及其邻居的标签是相同或一致的，这在异质图中不成立，在异质图中，链接节点的标签可能不同。|我们提出了一种新的基于p-拉普拉斯的GNN模型，称为pGNN，其消息传递机制来源于一个离散正则化框架，理论上可以解释为定义在p-拉普拉斯谱域上的多项式图滤波器的近似。|开源|
|[Inducing Causal Structure for Interpretable Neural Networks](https://proceedings.mlr.press/v162/geiger22a.html)|ICML|2022|Atticus Geiger|Machine Learning|神经网络的可解释性|将因果关系结构引入模型中|Open Source|
|[GNNRank: Learning Global Rankings from Pairwise Comparisons via Directed Graph Neural Networks](https://proceedings.mlr.press/v162/he22b.html)|ICML|2022|Yixuan He|Machine Learning|做排序|两两比较做排序，天然适合用图神经网络来建模。一个基于有向图嵌入的可训练gnn框架，将神经网络引入到排序恢复问题中|开源|

------------------------------

- [SE(3) Equivariant Graph Neural Networks with Complete Local Frames（具有完整局部坐标系的SE(3)等变图神经网络）](https://proceedings.mlr.press/v162/du22e.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Weitao (中科院)
  - **本篇文章物理和化学的知识过多**
  - 问题：纯黑盒的GNN模型有着泛化的局限性（由于SE(3)的限制），开发通用等变 GNN 模型要解决的主要挑战是如何以无参考的方式表达张量和进行非线性运算。**为了表示和操纵任意阶的等变张量，一些方法**求助于等变函数空间或者将空间提到高维空间。由于这些方法没有对张量的阶数进行限制，因此保证了这些模型具有足够的表达能力。不幸的是，将多体系统转换到那些高维空间或计算等变函数（例如不可约表示和张量乘积分解）通常会带来过多的计算成本和优化难度，这在某些现实世界场景中是不可接受的。当然，也有等变神经网络直接在原始空间中实现等变操作，提供了一种有效的方法来保持等方差而不复杂的等变嵌入。然而，这些模型中的大多数仅使用径向方向作为不完整的框架以及标量特征的嵌入，并放弃了高阶张量输入。因此，它们面临方向退化（direction degeneration）问题，不足以表达更复杂的几何量。**（一言以蔽之，对于GNN的信息构建，如何权衡表达能力和计算效率？）**
  - 方法：引入等变局部完整框架来构建等变图神经网络。

  - 从论文题目可以了解到什么信息？
    - title: SE(3) Equivariant Graph Neural Networks with Complete Local Frames,译成中文为“具有完整局部坐标系的SE(3)等变图神经网络”。
    - 论文使用的方法：图神经网络。
    - 论文使用的技术：SE(3)等变性，完整局部坐标系。
    - 该论文可能与计算机科学、机器学习、人工智能、图像处理等领域相关。
    - 什么是SE(3)等变性？
      - SE(3)等变性指的是空间欧几里得群（SE(3)）对称性在变换前后不变的性质。简单来说，当对于一个三维空间中的对象进行旋转、平移、缩放等变换时，如果这些变换不改变该对象的性质（如形状、大小、方向等），那么这个对象就具有SE(3)等变性。在机器学习和计算机视觉领域中，使用SE(3)等变性可以提高模型的稳定性。
    - 什么是完整局部坐标系？
      - 完整局部坐标系是指在一个局部区域内，用一组完整的坐标系来描述该区域中的物体或对象。这个坐标系通常由一个基向量集合构成，基向量集合中的每个基向量都是相互独立的，并且能够覆盖该区域内所有可能的方向和位置。使用完整局部坐标系可以方便地描述和分析局部区域内的物体或对象，这在计算机视觉、机器人学和三维重建等领域中特别有用。在SE(3)等变图神经网络中，完整局部坐标系被用来描述节点在三维空间中的位置和方向，并且帮助保持节点特征的旋转和平移等变性质。
    - 什么是方向退化（direction degeneration）？
      - 方向退化（direction degeneration）指的是在一些计算机视觉和机器学习任务中，由于数据中的对称性和平移不变性，导致模型无法区分不同方向上的特征。具体来说，当一些任务中的数据集中包含有对称性的物体或场景，例如球体、立方体、周期性图像等，这些物体或场景在不同的方向上看起来非常相似，这使得模型难以分辨不同方向上的特征。这种方向退化现象不仅会影响模型的精度，还会导致模型无法泛化到新的、未见过的方向。为了解决方向退化问题，研究者们提出了一些方法，如利用SE(3)等变性来提高模型的稳定性、使用完整局部坐标系来描述数据中的方向信息、采用数据增强方法来增加数据集中的方向差异等。

  - 文章内容
  这篇文章是关于SE(3)等变图神经网络的。文章提出了一种构建SE(3)等变图神经网络的框架，该框架可以有效地近似几何量。**作者通过引入等变局部完整框架来构建等变图神经网络，**从而可以将给定阶数的张量信息投影到框架上。局部框架被构造为正交基，**避免了方向退化并确保完整性。**由于框架仅由叉积运算构建，因此该方法**具有计算效率**。作者在两个任务上评估了他们的方法：牛顿力学建模和平衡分子构象生成。广泛的实验结果表明，他们的模型在两种类型的数据集中均取得了最佳或竞争性能。
  - 数据集
    - [ES(5)、ES(20)、G+ES(20)、L+ES(20)](https://ej2.syncfusion.com/javascript/documentation/listview/data-binding/)
    - [QM9](https://paperswithcode.com/dataset/qm9)
    - [Grom-Drugs](https://twitter.com/BenBlaiszik/status/1557098597677776904)
    - [ISO17](https://paperswithcode.com/dataset/iso17)

-------------------------------------

- [DepthShrinker: A New Compression Paradigm Towards Boosting Real-Hardware Efficiency of Compact Neural Networks（DepthShrinker：一种新的压缩范式，旨在提高紧凑型神经网络的实际硬件效率）](https://proceedings.mlr.press/v162/fu22c.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Yonggan Fu (Department of Electrical and Computer Engineering, Rice University 莱斯大学电气与计算机工程系)
  - 问题：模型的硬件利用率偏低
  - 方法：提出了一种新的压缩范式，并提出 DepthShrinker 通过将不规则块合并到密集操作中来开发硬件高效的紧凑型 DNN 提高实际硬件效率
  - 从这个论文题目可以了解到以下信息：
    - 论文提出了一种名为DepthShrinker的新的神经网络压缩范式。
    - DepthShrinker旨在提高紧凑神经网络的实际硬件效率，使其在具有限制的硬件资源的设备上运行更加高效。
    - 该研究可能涉及到神经网络压缩、硬件加速等相关领域的技术。

  - 什么是神经网络压缩
  神经网络压缩是指对神经网络模型进行优化，以减少模型的计算复杂度和存储空间占用，从而提高模型的效率和可用性。常见的神经网络压缩技术包括以下几种：
    - 参数剪枝：在神经网络的参数中去除冗余或低权重的参数，从而减少模型的参数量和计算复杂度。
    - 量化：将神经网络的参数从浮点数转化为低精度的整数或定点数，以减少模型的存储空间和计算量。
    - 分组卷积：将卷积层的输入通道分组，使得一组内的通道共享卷积核，减少卷积的计算量。
    - 知识蒸馏：利用一个较大的神经网络作为**教师**网络，将其知识传输到一个较小的神经网络（**学生**网络）中，以达到减小模型大小和提高效率的目的。
    - 网络结构搜索：通过自动化的搜索算法，找到一组最优的网络结构，达到减小模型大小和提高精度的目的。
  神经网络压缩技术在实际应用中具有广泛的应用，能够提高模型的效率，减少计算资源的使用，降低了硬件成本，使得神经网络在移动设备、嵌入式设备等资源受限的环境下得到广泛应用。

  - 文章内容
    - 这篇论文提出了一种新的压缩神经网络的方法，名为 DepthShrinker。DepthShrinker 通过将现有高效 DNN 的基本构建块中具有不规则计算模式的层缩小为具有更好硬件利用率的密集层，从而开发出硬件友好的紧凑网络。DepthShrinker 的框架提供了比最先进的高效 DNN 和压缩技术更好的硬件友好紧凑网络，例如在 Tesla V100 上比 SOTA 通道智能修剪方法 MetaPruning 的精度高出 3.06％，吞吐量高出 1.53 倍。
  - 数据集
    - [MobileNetV2](https://www.kaggle.com/code/mgiraygokirmak/mobilenetv2)
    - [EfficientNetLite](https://pypi.org/project/efficientnet-lite-pytorch/)：一个轻量的神经网络。

--------------------------------------

- [p-Laplacian Based Graph Neural Networks（基于 p-Laplacian 的图神经网络）](https://proceedings.mlr.press/v162/fu22e.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Guoji Fu （腾讯人工智能实验室）
  - 问题：大多数gnn隐含地假设图中节点及其邻居的标签是相同或一致的，这在异质图中不成立，在异质图中，链接节点的标签可能不同。
  - 方法：我们提出了一种新的基于p-拉普拉斯的GNN模型，称为pGNN，其消息传递机制来源于一个离散正则化框架，理论上可以解释为定义在p-拉普拉斯谱域上的多项式图滤波器的近似。
  - 从这个论文题目可以了解到以下信息：
    - 这是一篇与图神经网络（Graph Neural Networks）相关的论文。
    - 论文中的方法是基于 p-Laplacian 的。
    - p-Laplacian 是一个与 Laplacian 矩阵相关的数学工具，**用于描述图的特征和性质**。
    - 该论文提出的方法可能会利用 p-Laplacian 建立起一种更加有效的图神经网络模型。
  - 先修知识
    - p-Laplacian是什么？
      - p-Laplacian 是一个与 Laplacian 矩阵相关的数学工具，常用于描述图的特征和性质。在数学中，Laplacian 矩阵是一个对称矩阵，用于描述图中节点之间的连接关系。p-Laplacian 是将 Laplacian 矩阵中的二次项改为了 p 次幂的一般化形式。
      - 在图论中，p-Laplacian 常用于解决图信号处理、图像分割、社交网络分析等问题。与 Laplacian 矩阵类似，p-Laplacian 矩阵可以用于计算图的特征向量和特征值，进而推断出图的结构信息和节点之间的相似度。在图神经网络中，p-Laplacian 也可以用于构建更加精确的图嵌入（graph embedding）模型，从而提高图神经网络的性能和效率。
  - 这篇文章讲了什么内容？
    - 这篇文章是关于p-Laplacian Based Graph Neural Networks的。作者提出了一种新的p-Laplacian based GNN模型，称为pGNN，其消息传递机制源自离散正则化框架，并且可以在p-Laplacians的频谱域上定义的多项式图滤波器的近似。该模型可以适应性地学习聚合权重，并且对噪声边具有鲁棒性。实证研究表明，pGNN在异质图上表现出色，而在同质图上表现出竞争性的性能。
    - 文章指出，大多数现有的GNN架构都是在同质性假设下工作的，即图中节点及其邻居的标签相同或一致。然而，最近的研究表明，与其在同质图上的成功相比，大多数GNN在异质图上无法很好地工作，其中链接节点更有可能具有不同的标签。此外，当拓扑对标签预测没有信息时，传统GNN可能会比仅在每个节点上应用多层感知器（MLPs）更差。
  - 这篇文章解决了什么问题？用的什么方法？
    - 这篇论文是关于图神经网络的，提出了一种新的基于p-Laplacian的图神经网络模型，称为pGNN。它的信息传递机制源自于离散正则化框架，并且可以在p-Laplacians的频谱域上被理论上解释为多项式图滤波器的近似。pGNNs在同构和异构图上都很有效，因为它们的信息传递机制作为低通和高通滤波器工作。此外，pGNNs可以自适应地学习聚合权重，并且对噪声边缘具有鲁棒性。这篇论文还通过真实世界和合成数据集的实证研究验证了这些发现，并表明pGNNs在异构基准测试中显著优于几种最先进的GNN体系结构，同时在同构基准测试中实现了竞争性能。
    - 这篇论文提出了一种新的基于p-Laplacian的图神经网络模型，称为pGNN。它的信息传递机制源自于离散正则化框架，并且可以在p-Laplacians的频谱域上被理论上解释为多项式图滤波器的近似。
  - 这篇论文有哪些创新点？
    - 这篇论文的创新点在于提出了一种新的基于p-Laplacian的GNN模型，称为pGNN。它的信息传递机制源自于离散正则化框架，并且可以在p-Laplacian的谱域上被理论上解释为多项式图滤波器的近似。pGNN的谱分析表明，新的信息传递机制作为低通和高通滤波器，因此使得pGNN在同构和异构图上都非常有效。此外，pGNN可以自适应地学习聚合权重，并且对噪声边缘具有鲁棒性。
  - 数据集
    - [Cora](https://paperswithcode.com/dataset/cora)
    - [CiteSeer](https://paperswithcode.com/dataset/citeseer)
    - PubMed
    - Amazon Computers
    - Amazon Photo
    - Coauthor CS
    - Coauthor Physics
    - Chameleon
    - Squirrel
    - Actor cooccurrence graph
    - Webpage graph Wisconsin
    - Webpage graph Texas
    - Webpage graph Cornell

--------------------------------

- [Inducing Causal Structure for Interpretable Neural Networks（可解释性神经网络的诱导因果结构）](https://proceedings.mlr.press/v162/geiger22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Atticus Geiger （斯坦福大学）
  - 问题：神经网络的可解释性
  - 方法：将因果关系结构引入模型中
  - 从论文题目（Inducing Causal Structure for Interpretable Neural Networks）可以了解到什么信息？
    - 论文的研究方向涉及神经网络的可解释性。
    - 论文的重点是关于诱导因果结构的研究，这可能与因果推理和因果关系分析有关。
    - 论文可能提供一些方法来改进神经网络的可解释性，从而使得神经网络的决策过程更加透明和可靠。
  - 诱导因果结构
    - 诱导因果结构是指从数据中推断出潜在的因果关系结构的过程。在这个过程中，我们从数据中推断出一些变量之间的因果关系，构建出一个因果结构图谱。这个过程通常基于一些因果假设和概率模型，并且需要对数据进行统计分析和推断。诱导因果结构是因果推理和因果关系分析的重要领域，其应用包括因果推断、预测和决策等多个方面。在神经网络领域中，诱导因果结构可以帮助提高神经网络的可解释性，并且使得神经网络的决策过程更加透明和可靠。
  - interchange intervention training (IIT) 互动性干预训练(IIT)
    - Interchange Intervention Training (IIT) 是一种因果推断的训练方法，用于改进神经网络的因果推理能力和可解释性。IIT 的核心思想是在训练过程中，对输入数据进行交换干预（Interchange Intervention），来帮助神经网络识别变量之间的因果关系，并学习到更具有因果解释性的表示。具体来说，IIT 在训练过程中，会对每一对输入变量进行交换，即在一些样本中交换它们的取值，并用交换后的样本重新训练神经网络。这样一来，神经网络可以比较交换前后的预测结果，从而识别出那些对预测结果具有因果影响的变量，并对它们进行更好的建模。通过 IIT 训练，神经网络可以更好地理解输入数据之间的因果关系，从而提高其可解释性和泛化能力。
  
  - 文章讲了什么内容？
  这篇论文是关于如何将因果结构引入神经网络中，以使得神经网络的输出更容易被解释。论文提出了一种新的方法，可以将因果结构嵌入到神经网络中，从而使得神经网络的输出更容易被解释，并且可以在训练过程中进行优化。这种算法可以用于各种类型的神经网络，包括卷积神经网络和循环神经网络等。
  - 三次实验评估
    - ResNet在视觉任务上训练（MNIST-PVR）
    - CNN-LSTM模型在给定自然语言命令的网格世界中训练生成动作序列(ReaSCAN)
    - 预训练BERT模型微调标记两个句子之间的语义关系(MQNLI)

--------------------------------------
- [GNNRank: Learning Global Rankings from Pairwise Comparisons via Directed Graph Neural Networks（GNNRank:通过有向图神经网络从两两比较中学习全球排名）](https://proceedings.mlr.press/v162/he22b.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Yixuan He （牛津大学）
  - 问题：做排序
  - 方法：两两比较做排序，天然适合用图神经网络来建模。一个基于有向图嵌入的可训练gnn框架，将神经网络引入到排序恢复问题中
  - 从论文题目（GNNRank: Learning Global Rankings from Pairwise Comparisons via Directed Graph Neural Networks）可以了解到什么信息？
    - 该论文讨论了一种名为 "GNNRank" 的方法，该方法使用有向图神经网络从成对比较中学习全局排序。
    - 该论文是关于从成对比较学习全球排名的一种方法。
    - 该论文可能集中讨论机器学习，并具体开发一种新的基于成对比较的项目排序方法。
    - 使用有向图神经网络的方法表明，该方法可能涉及建立项目之间关系的有向图结构。
  - 先修知识
    - 成对比较
      - 成对比较是一种比较两个项目之间相对优劣的方法。
    - 学习全局排序
      - 学习全局排序则是在一个项目集合中确定每个项目相对优劣的排序，以便能够对它们进行排序和推荐。
    - 成对比较中学习全局排序的方法是一种机器学习技术，它通过学习从成对比较到全局排序的映射来构建一个排序模型。
    - 在成对比较中学习全局排序的任务中，模型需要从已知成对比较中学习每个项目的隐含特征，并使用这些特征来预测全局排序。为了实现这一点，一些机器学习方法使用图形模型来表示项目之间的相关性，而有向图神经网络是一种图形模型，它可以在有向图上执行神经网络操作以学习节点的表示和关系。
    - 因此，GNNRank使用有向图神经网络从成对比较中学习项目之间的关系，并从中学习全局排序。
  - 这篇文章讲了什么内容？
  这篇论文是关于GNNRank的，它是一种通过有向图神经网络学习全局排名的方法。在比赛中，对应于比赛中的匹配的两两比较可以自然地被构造为有向图（digraph）中的边，其节点表示具有未知排名或技能强度的竞争者。GNNRank是一种建模框架，与任何能够学习digraph嵌入的GNN兼容，并设计了可训练的目标来编码排名失误/违规。
  - 一言以蔽之
    - 作者提出所谓的GNNRank，一个基于有向图嵌入的可训练gnn框架，将神经网络引入到排序问题中。该框架包括一个排名分数估计方法，并通过展开由可学习相似矩阵构建的图的费德勒向量计算来增加归纳偏差。
  - 创新点
    - 无监督下，从两两比较，恢复全集排序的第一篇文章。
    - 提出了一种新的可微的损失
    - 为了联合解决全局排序和GNN训练问题，我们设计并引入了一种归纳偏置，作为编码潜在排序的有效方法，这种偏置是通过神经网络的近端梯度步骤实现的，从费德勒向量计算中展开
    - 理论上必然收敛
  - 数据集
    - 开源

-----------------------------------------
#### 5. May 15, 2023(week 5)
Neural Networks

|Title|Publication|Year|Authors|Area|Problem|Main Method|Datasets|
| :---:| :---:| :---:| :---:|:---:|:---:|:---:|:---:|
|[Neuron Dependency Graphs: A Causal Abstraction of Neural Networks](https://proceedings.mlr.press/v162/hu22b.html)|ICML|2022|Yaojie Hu|Machine Learning|神经网络的可解释性|因果抽象，Neuron Dependency Graphs|open source|
|[Representation Topology Divergence: A Method for Comparing Neural Network Representations.](https://proceedings.mlr.press/v162/barannikov22a.html)|ICML|2022|Serguei Barannikov|Machine Learning|神经网络的表示|提出了一种新的度量方法，称为RTD，它可以比较神经网络表示之间的拓扑差异。|open source|
|[How to Train Your Wide Neural Network Without Backprop: An Input-Weight Alignment Perspective](https://proceedings.mlr.press/v162/boopathy22a.html)|ICML|2022|Akhilan Boopathy|Machine Learning|在不使用反向传播的情况下，训练宽神经网络|输入权重对齐|open source|
|[State Transition of Dendritic Spines Improves Learning of Sparse Spiking Neural Networks](https://proceedings.mlr.press/v162/chen22ac.html)|ICML|2022|Yanqi Chen|Machine Learning|提高SNN的性能|通过控制树突棘的状态转移|open source|
|[A Context-Integrated Transformer-Based Neural Network for Auction Design](https://proceedings.mlr.press/v162/duan22a.html)|ICML|2022|Zhijian Duan|Machine Learning|拍卖设计|基于 transformer 提出一种新的模型，用于处理拍卖中的上下文信息。|<table><tr><td bgcolor=#D1EEEE>open source</td></tr></table>|
|[C*-algebra Net: A New Approach Generalizing Neural Network Parameters to C*-algebra](https://proceedings.mlr.press/v162/hashimoto22a.html)|ICML|2022|Yuka Hashimoto|Machine Learning|传统的神经网络模型中，神经元的参数通常是实数或复数。这种表示方式无法更好地描述神经网络的非线性特性和复杂性。也不好处理一些传统神经网络不易处理的问题，例如处理量子信息、非交换随机过程等。|引入C*-algebra，将神经网络的参数推广到C*-algebra，进而设计出一种C*-algebra Net.|closed source|

----------------------------------------

- [Neuron Dependency Graphs: A Causal Abstraction of Neural Networks（神经元依赖图：神经网络的因果抽象）](https://proceedings.mlr.press/v162/hu22b.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Yaojie Hu （美国爱荷华州立大学计算机科学系）
  - 问题：神经网络的可解释性
  - 方法：因果抽象，Neuron Dependency Graphs
  - 本文在[Inducing Causal Structure for Interpretable Neural Networks（可解释性神经网络的诱导因果结构）](https://proceedings.mlr.press/v162/geiger22a.html)的基础上再做研究。
  - 从论文题目中可以获取到什么信息？
    - 论文涉及神经网络，是一个与机器学习/人工智能相关的主题。
    - 论文中介绍了一种叫做“Neuron Dependency Graphs”的概念，这可能是一种新的方法或技术，用于对神经网络进行建模和理解。
    - 论文可能会讨论神经网络中神经元之间的因果关系，即哪些神经元对于其他神经元的激活起到决定性的作用，这可能有助于进一步解释神经网络的行为和决策过程。
  - 先修知识
    - 因果干预理论
      - 因果干预理论（causal intervention theory）是指在影响因果关系的两个变量中，通过对其中一个变量进行干预（例如改变该变量的值），来判断该变量对另一个变量的影响。因果干预理论基于因果图和概率计算，可以用来评估干预措施的效果，例如药物治疗、政策制定等。
    - 因果抽象理论
      - 因果抽象理论（causal abstraction theory）则是指通过对因果图进行简化和抽象，来发现变量之间的因果关系。因果抽象理论可以帮助我们理解复杂系统中的因果关系，并发现其中的重要变量和机制。因果抽象理论的核心思想是对变量进行抽象，将其分为因果变量和非因果变量，并通过因果图中的箭头表示因果关系。

  - 这篇文章讲了什么？
    - 这篇文章是关于神经网络的，它提出了神经网络中的逻辑依赖关系，并介绍了神经元依赖图（NDG），将其提取并呈现为有向图。
    - 在NDG中，每个节点对应于神经元的布尔激活值，每个边从一个节点到另一个节点建立了一个近似的逻辑蕴含关系。
    - 作者发现从训练数据集中提取的逻辑依赖关系可以很好地推广到测试集。除了为神经网络的内部结构提供符号解释外，NDG还可以表示结构因果模型。
    - **通过检查逻辑结构，作者发现一个新的普遍现象，即对于训练模型，近似逻辑依赖关系通常存在于各种神经网络体系结构、数据集和选择层之间，甚至在两个独立训练的模型之间。**
    - 作为一种后期解释方法，**NDGs不需要对所解释的神经网络进行任何架构更改。该图是从数据中发现的，并且不需要先验专家建模。**
    - **因果抽象的关键是识别将两个因果过程联系起来的函数映射，该函数映射以变量值和干预结果为基础将两者联系在一起。**
    - 作者通过实验证明，NDG 是相应神经网络的因果抽象，**使用 Geiger 等人（2021a）的理论在因果干预下“展开”相同。**
  - 一言以蔽之
    - 通过构建神经依赖图，以及因果抽象理论，在不需要先验专家建模且不需要对模型架构进行更改的情况下，作者完成了一种后期解释，其效果不弱于**Geiger的因果干预**
  - 数据集
![20230515133529](https://cdn.jsdelivr.net/gh/Corner430/Picture/images/20230515133529.png)

----------------------------------------------------------
- [Representation Topology Divergence: A Method for Comparing Neural Network Representations.（表示拓扑发散：一种比较神经网络表示的方法）](https://proceedings.mlr.press/v162/barannikov22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Serguei Barannikov （Skolkovo 科学技术研究所，莫斯科，俄罗斯）
  - 问题：神经网络的表示
  - 方法：提出了一种新的度量方法，称为RTD，它可以比较神经网络表示之间的拓扑差异。
  - 从这个论文的题目可以提炼出以下信息：
    - 该论文的主题是神经网络表示比较方法。
    - 该论文提出了一种名为“Representation Topology Divergence”的方法。
    - 这种方法旨在比较神经网络的表示。
    - 该方法的核心思想是计算表示拓扑的分歧度量。
    - 通过使用这种方法，可以比较不同神经网络的表示，从而得出它们之间的相似性或差异性。
  - 先修知识
    - 比较神经网络的表示
      - 比较神经网络的表示是指在神经网络中比较不同层或不同网络之间的特征表示。神经网络的表示是指神经网络中不同层的特征向量或特征图，这些特征向量或特征图被用于对输入进行分类、预测或生成。
      - 比较神经网络的表示可以帮助我们理解神经网络中不同层或不同网络之间的特征提取能力和特征表示能力，从而发现其中的优缺点、改进空间和设计原则。常用的比较方式包括可视化、相似性度量、特征分析和可解释性分析等。
      - 比较神经网络的表示是神经网络领域中的一个重要研究方向，它可以帮助我们更好地理解神经网络的工作原理和内部机制，从而进一步提高神经网络的性能和应用范围。
    - 表示拓扑的分歧度量
      - 表示拓扑的分歧度量是一种用于比较神经网络表示之间相似性或差异性的度量方法。在该方法中，首先将神经网络的表示转换为拓扑结构，然后计算不同拓扑结构之间的分歧度量。这种度量方法基于图论和拓扑学的概念，可以用于比较不同神经网络之间的表示差异、分析神经网络的表达能力和理解神经网络的内部工作原理。
      - 表示拓扑的分歧度量可以用于比较神经网络中不同层或不同网络之间的表示差异，以及分析神经网络的特征提取能力和特征表示能力。该方法可以帮助研究人员更好地理解神经网络的内部机制和优缺点，从而进一步提高神经网络的性能和应用范围。
  - 这篇文章讲了什么内容？
    - 这篇文章是关于神经网络表示拓扑差异的一种比较方法。**作者提出了一种新的度量方法，称为RTD**，它可以比较神经网络表示之间的拓扑差异。
    - RTD还可以检测到神经网络表示之间的聚类结构，而其他度量方法则无法检测到这些结构。
  - 数据集
    - [CIFAR-10/100](https://www.cs.toronto.edu/~kriz/cifar.html)
    CIFAR-10数据集由10类中的60000 32x32颜色图像组成，每个类别有6000张图像。有50000个培训图像和10000个测试图像
    - MNIST


  
----------------------------------------------------------
- [How to Train Your Wide Neural Network Without Backprop: An Input-Weight Alignment Perspective（如何在没有反向传播的情况下训练宽神经网络：输入权重对齐的观点）](https://proceedings.mlr.press/v162/boopathy22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Akhilan Boopathy （MIT）
  - 问题：在不使用反向传播的情况下，训练宽神经网络
  - 方法：输入权重对齐
  - 从这个论文的题目可以提炼出以下信息：
    - 该论文的主题是训练宽神经网络的方法。
    - 在神经网络中，宽度是指隐藏层中神经元的数量。
    - 该论文提出了一种不使用反向传播算法的宽神经网络训练方法。
    - 这种方法基于输入权重对齐的思想，即通过对齐输入和权重来训练神经网络。
    - **该方法可能有助于提高神经网络的训练效率和准确性，并且可以避免反向传播算法中存在的一些问题。**
  - 先修知识
    - 宽神经网络（Wide Neural Network）
      - 宽神经网络（Wide Neural Network）是一种神经网络结构，**其隐藏层中包含大量的神经元。**与传统的神经网络相比，宽神经网络具有更多的参数和更强的表达能力，能够更好地处理高维数据和复杂的非线性关系。
      - 通常情况下，**宽神经网络中隐藏层的神经元数量要远大于输入层和输出层中的神经元数量。**这种结构可以使神经网络学习到更多的特征，从而提高其分类、预测或生成的准确性和泛化能力。
      - 宽神经网络在图像识别、自然语言处理、语音识别、推荐系统等领域中得到广泛应用。但是，宽神经网络的训练和优化也面临一些挑战，**例如过拟合、梯度稀疏性等问题。**因此，近年来研究人员也提出了许多新的方法和技术来解决这些问题，以进一步提高宽神经网络的性能和应用范围。
    - 输入权重对齐（input-weight alignment）
      - 输入权重对齐（input-weight alignment）是一种用于训练神经网络的方法。该方法的核心思想是通过调整神经网络的输入和权重，使它们在相似的方向上对齐，从而提高神经网络的训练效率和准确性。
      - 在输入权重对齐方法中，首先将神经网络的输入向量和权重向量映射到一个高维空间中，并计算它们之间的余弦相似度。然后根据余弦相似度的大小，调整输入和权重的方向，使它们朝着相似的方向对齐。最后，使用对齐后的输入和权重进行神经网络的训练。
      - 通过输入权重对齐方法，可以使神经网络的输入和权重更好地匹配，从而提高神经网络的训练效率和准确性。**该方法可以避免神经网络中存在的一些问题，例如梯度消失和梯度爆炸等，同时也可以提高神经网络对噪声和扰动的鲁棒性。**

  - 这篇文章讲了什么内容？
    - 这篇文章是关于神经网络的，它提出了一种新的训练方法，称为“输入权重对齐”（Input-Weight Alignment）。这种方法可以训练宽神经网络，而无需使用反向传播算法。文章中提到，这种方法可以在不牺牲准确性的情况下，大大减少训练时间和计算成本。文章还提供了一些实验结果来支持这种方法的有效性。

  - 数据集
    - [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)是一个包含10个类别的图像分类数据集，每个类别有6000张32x32的彩色图像。
    - [KMNIST](https://pytorch.org/vision/main/generated/torchvision.datasets.KMNIST.html)是一个包含10个类别的手写数字分类数据集，每个类别有7000张28x28的灰度图像。

----------------------------------------------------------
- [State Transition of Dendritic Spines Improves Learning of Sparse Spiking Neural Networks（树突棘的状态转移提高了稀疏尖峰神经网络的学习）](https://proceedings.mlr.press/v162/chen22ac.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Yanqi Chen （北京大学计算机学院视觉技术国家工程研究中心）
  - 问题：提高SNN的性能
  - 方法：通过控制树突棘的状态转移
  - 先修知识
    - 稀疏脉冲神经网络
      - 稀疏脉冲神经网络（Sparse Spiking Neural Network）是一种**生物启发式**的神经网络模型，其工作方式类似于大脑中的神经元。与传统的神经网络不同，稀疏脉冲神经网络的神经元输出是**离散的脉冲信号，而不是连续的实数值。**
      - 在稀疏脉冲神经网络中，一组输入信号会被映射到神经元的膜电位上，当膜电位超过某个阈值时，神经元会发出一个脉冲信号，**同时膜电位会被重置为基础值。**这种脉冲信号的输出方式**可以降低神经网络的计算复杂度和能耗**，同时也可以更好地模拟大脑中神经元的工作方式。
      - 稀疏脉冲神经网络在处理稀疏数据、模式识别、控制系统等领域中具有广泛的应用。然而，稀疏脉冲神经网络的设计和训练也面临着许多挑战，例如时序数据处理、学习算法设计等问题。因此，近年来研究人员提出了许多新的方法和技术，以进一步提高稀疏脉冲神经网络的性能和应用范围。
    - 树突棘的状态转换
      - 树突棘（dendritic spine）是神经元的突起，可以接收其他神经元的信号。树突棘的形态和状态对神经元之间的信息传递和学习起着重要的作用。
      - 树突棘的状态转换（spine state transition）指的是树突棘形态和状态的变化。树突棘的形态和状态可以受到神经元内部和外部环境的影响，例如神经递质的浓度、神经元发放的脉冲频率等。当树突棘的状态发生变化时，其形态和功能也会发生相应的变化，从而影响神经元之间的信息传递和学习。
      - 树突棘的状态转换在神经元的信息处理和学习中具有重要的作用。近年来，研究人员对树突棘的状态转换机制进行了深入研究，并提出了一些新的理论和方法，以进一步理解神经元之间的信息传递和学习过程。
  - 从这个论文的题目可以提炼出以下信息：
    - 该论文的主题是稀疏脉冲神经网络的学习。
    - 该论文探讨了**树突棘的状态转换如何影响稀疏脉冲神经网络的学习。**
    - 树突棘是神经元的突起，可以接收其他神经元的信号。
    - 该论文认为，**通过控制树突棘的状态转换，可以提高稀疏脉冲神经网络的学习效率。**
    - 该研究可能**有助于改进神经网络的设计，提高其在处理稀疏数据时的性能。**

  - 这篇文章讲了什么内容？
    - 这篇文章是关于稀疏尖峰神经网络的学习的，它介绍了树突棘的状态转换如何改善稀疏尖峰神经网络的学习。文章中提到，稀疏尖峰神经网络是一种新型的神经网络，它模拟了人类大脑中神经元之间的通信方式。文章介绍了一种新的方法，通过树突棘状态转换来改善稀疏尖峰神经网络的学习效果。文章还介绍了一些实验结果，证明了这种方法的有效性。**文章中提到，这种方法可以使神经网络的学习效果更好，同时减少神经元之间的通信量。**文章还介绍了一些实验结果，证明了这种方法的有效性。
  - 一言以蔽之
    - 在部署在节能神经形态硬件上时，尖峰神经网络 (SNN) 被认为是人工神经网络 (ANN) 为其事件驱动计算范式的一种有前途的替代方案。通过动态剪枝，可以在大规模数据集上产生了稀疏的深度网络，同时保持了最先进的低性能损失。

  - 数据集
    - 文章中提到了一些实验结果，证明了这种方法的有效性。这些实验结果包括在ImageNet数据集上的剪枝算法性能比较、在CIFAR-10数据集上的剪枝算法性能比较以及MNIST等。





----------------------------------------------------------
- [A Context-Integrated Transformer-Based Neural Network for Auction Design（用于拍卖设计的基于上下文集成 transformer 的神经网络）](https://proceedings.mlr.press/v162/duan22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Zhijian Duan （北大和谷歌研究院）
  - 问题：拍卖设计
  - 方法：基于 transformer 提出一种新的模型，用于处理拍卖中的上下文信息。
  - 从这个论文的题目可以提炼出以下信息：
    - 该论文的主题是拍卖设计。
    - 该论文提出了一种基于Transformer的神经网络模型。
    - 该模型将上下文信息整合到拍卖设计中，以提高拍卖的效率和准确性。
    - Transformer是一种广泛用于自然语言处理的神经网络结构，可以处理序列数据。
    - 这种基于Transformer的神经网络模型可能有助于改进拍卖设计，并提高其在实际应用中的效果。

  - 这篇文章讲了什么内容？
    - 这篇文章是关于拍卖设计的，**它提出了一种基于Transformer的神经网络模型，称为CITransNet**，用于处理拍卖中的上下文信息。文章介绍了拍卖设计的背景和相关工作，然后详细介绍了CITransNet的模型架构和训练过程。最后，作者通过实验验证了CITransNet在不同设置下的性能，并与其他模型进行了比较。
    - 文章提到，**CITransNet将出价概要、竞标人上下文和物品上下文作为输入，并采用Transformer交互层来建模不同竞标人和物品之间的相互作用。最后，通过最终输出层计算分配和付款结果。**
    - 此外，CITransNet还可以在不同设置下进行泛化，这表明它具有很好的可扩展性。
  - 一言以蔽之
    - 这个论文中所说的拍卖设计指的是在拍卖机制中设计出合理的拍卖规则和策略，以实现某些特定的目标，例如提高拍卖效率、增加拍卖收益、平衡拍卖参与者的利益等。拍卖设计可以涉及拍卖机制的各个方面，例如出价规则、竞价方式、信息披露、竞拍者的资质和数量等。
    - 在该论文中，研究人员使用了一种基于Transformer的神经网络，将上下文信息与拍卖机制进行整合，以实现更好的拍卖设计。具体来说，他们使用了一种称为Context-Integrated Transformer的神经网络模型，该模型可以将拍卖机制的设计目标、拍卖参与者的信息和市场环境等因素进行整合，并基于这些信息进行拍卖设计。该论文中的拍卖设计旨在提高拍卖的效率和公平性，同时最大化卖方的收益和买方的福利。

  - 数据集
    - 这篇文章中使用的数据集是作者自己构建的。作者在文章中提到，他们使用了两个数据集，一个是用于评估模型性能的数据集，另一个是用于泛化实验的数据集。作者还提到，他们在构建数据集时采用了一些技巧来增加数据集的多样性和难度。
    - [代码](https://github.com/zjduan/CITransNet)




----------------------------------------------------------
- [C*-algebra Net: A New Approach Generalizing Neural Network Parameters to C*-algebra（C*-algebra Net：一种将神经网络参数推广到 C*-algebra 的新方法）](https://proceedings.mlr.press/v162/hashimoto22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Yuka Hashimoto （NTT网络服务系统实验室，NTT公司，东京，日本）
  - 问题：传统的神经网络模型中，神经元的参数通常是实数或复数。这种表示方式无法更好地描述神经网络的非线性特性和复杂性。也不好处理一些传统神经网络不易处理的问题，例如处理量子信息、非交换随机过程等。
  - 方法：引入C*-algebra，将神经网络的参数推广到C*-algebra，进而设计出一种C*-algebra Net.
  - 先修知识
    - C*-代数（C*-algebra）
      - C*-代数（C*-algebra）是一种数学结构，它是一个包含一个或多个元素的代数系统，同时还满足一些特定的性质。C*-代数在数学、物理学和工程学等领域中有广泛的应用，尤其在量子力学、函数分析和偏微分方程等领域中有重要的地位。
      - C*-代数的名称中的`"C*"表示共轭代数（conjugate algebra），也就是代数中的复共轭运算`。C*-代数的定义要求它是一个Banach代数，也就是一个具有范数的代数。同时，C*-代数还具有一些特定的性质，例如范数的完备性、范数满足三角不等式、元素的共轭具有范数等于自身的性质等。
      - C*-代数在数学中的应用非常广泛，例如在函数分析、拓扑学、算子理论等领域中都有应用。在物理学中，C*-代数也是量子力学和统计力学中重要的数学工具，它被用于描述量子物理系统的代数结构和对称性。在工程学中，C*-代数也被广泛应用于信号处理、控制系统、机器学习等领域中的数学建模和分析。
  - 从这个论文的题目可以提炼出以下信息：
    - 该论文的主题是一种名为C*-algebra Net的新型神经网络。
    - C*-代数是一种数学结构，它在量子力学、函数分析和数学物理学等领域中得到广泛应用。
    - 该论文提出了一种将神经网络参数推广到C*-代数的新方法。
    - **这种方法可以将神经网络的参数表示为C*-代数中的元素，从而扩展了传统神经网络的表达能力。**
    - C*-algebra Net可能有助于解决一些现有神经网络中存在的问题，并在量子计算等领域中发挥作用。

  - 这篇文章讲了什么内容？
    - 这篇文章是关于 C∗-代数网络的，它是一种新的方法，将神经网络参数推广到 C∗-代数。**文章提出了一种新的密度估计方法，称为归一化流，它可以将任务转换为模型参数。**文章还介绍了一些应用程序，并比较了现有方法和作者提出的方法之间的差异。
  - 一言以蔽之
    - 这篇文章提出了一种基于C*-代数的神经网络模型，称为C*-algebra Net。该模型可以将神经网络的参数表示为C*-代数，从而在一定程度上扩展了传统神经网络的能力。
    - **传统的神经网络模型中，神经元的参数通常是实数或复数。而在C*-algebra Net中，神经元的参数被表示为C*-代数，这种表示方式可以更好地描述神经网络的非线性特性和复杂性。**同时，C*-algebra Net还能够处理一些传统神经网络不易处理的问题，例如处理量子信息、非交换随机过程等。
    - C*-algebra Net的提出对于推动神经网络模型的发展和应用具有重要的意义。它不仅为神经网络模型提供了新的表示方式，也为神经网络在量子计算、量子信息处理等领域的应用带来了新的思路和方法。
    - 举例
      - 在量子计算中，传统的神经网络模型难以处理量子态的非线性变换。而C*-algebra Net则可以将这些非线性变换表示为C*-代数，从而更好地描述和处理量子态的非线性变换。例如，C*-algebra Net可以用于量子态的分类、量子纠缠的检测等任务中，在这些任务中，C*-algebra Net的表现可能会更好，因为它能够更好地描述和处理非线性变换。
      - 在处理非交换随机过程的任务中，C*-algebra Net也具有一定的优势。非交换随机过程是一类广泛存在于自然界中的物理和生物系统的随机过程，例如蛋白质分子的折叠过程、量子自旋系统的演化过程等。C*-algebra Net可以将这些非交换随机过程表示为C*-代数，从而更好地描述和处理这些随机过程。

  - 数据集
    - 自己生成，代码不开源
![20230515143612](https://cdn.jsdelivr.net/gh/Corner430/Picture/images/20230515143612.png)

-----------------------------------------
#### 6. May 21, 2023(week 6)
Neural Networks

|Title|Publication|Year|Authors|Area|Problem|Main Method|Datasets|
| :---:| :---:| :---:| :---:|:---:|:---:|:---:|:---:|
|[Wide Bayesian neural networks have a simple weight posterior: theory and accelerated sampling](https://proceedings.mlr.press/v162/hron22a.html)|ICML|2022|Jiri Hron|Machine Learning|宽贝叶斯的权重计算复杂度过高，加速采样|提出一种马尔可夫链蒙特卡罗（MCMC）后验采样算法|open source|
|[The Dual Form of Neural Networks Revisited: Connecting Test Time Predictions to Training Patterns via Spotlights of Attention](https://proceedings.mlr.press/v162/irie22a.html)|ICML|2022|Kazuki Irie|Machine Learning|如何更好地理解神经网络中训练数据点与测试时间预测之间的关系？|通过注意力聚焦将测试时的预测和训练模式相关联|open source|
|[A deep convolutional neural network that is invariant to time rescaling](https://proceedings.mlr.press/v162/jacques22a.html)|ICML|2022|Brandon G. Jacques|Machine Learning|当语音呈现倍速播放时，于人而言不成问题，于模型而言却是天差地别。|受神经科学的启发，提出一种不受时间缩放影响的深度卷积神经网络，用以解决这类和**时间序列**相关的问题|open source|
|[Training Your Sparse Neural Network Better with Any Mask](https://proceedings.mlr.press/v162/jaiswal22a.html)|ICML|2022|Ajay Jaiswal|Machine Learning|目前的研究工作侧重于越来越复杂的剪枝方法。|从头开始训练稀疏子网络，改进修剪子网络的训练技术，即稀疏训练。|open source|
|[Robust Fine-Tuning of Deep Neural Networks with Hessian-based Generalization Guarantees](https://proceedings.mlr.press/v162/ju22a.html)|ICML|2022|Haotian Ju|Machine Learning|迁移学习容易过拟合，带上噪声更麻烦|基于Hessian对模型的泛化误差上界做评估|open source|
|[Matching Learned Causal Effects of Neural Networks with Domain Priors](https://proceedings.mlr.press/v162/kancheti22a.html)|ICML|2022|Sai Srinivas Kancheti|Machine Learning|一方面，如果训练数据包含因果关系和相关关系，优化预测精度的模型**不一定学习输入和输出变量之间的真实因果关系**（胖子未必跑不动）。另一方面，专家用户通常了解某些输入变量与领域知识输出之间的因果关系。|提出了一种正则化方法，该方法将神经网络的学习因果效应与域先验对齐，包括直接效应和总因果效应。|open source|
|[Composing Partial Differential Equations with Physics-Aware Neural Networks](https://proceedings.mlr.press/v162/karlbauer22a.html)|ICML|2022|Matthias Karlbauer|Machine Learning|<table><tr><td bgcolor=#D1EEEE>方向不符</td></tr></table>|<table><tr><td bgcolor=#D1EEEE>方向不符</td></tr></table>|open source|
|[Neural Network Poisson Models for Behavioural and Neural Spike Train Data](https://proceedings.mlr.press/v162/khajehnejad22a.html)|ICML|2022|Moein Khajehnejad|Machine Learning|对于监测神经元和行为之间关系的模型乏力。任务计算约束的简单反射往往不足以捕获分布在不同大脑区域的感觉输入和动作的复杂神经表示，无法解释试验之间的行为和神经记录的时间不规则性。总之所有的方式都有缺陷。|提出了一种新颖的神经网络泊松过程模型|open source|
|[DSTAGNN: Dynamic Spatial-Temporal Aware Graph Neural Network for Traffic Flow Forecasting](https://proceedings.mlr.press/v162/lan22a.html)|ICML|2022|Shiyong Lan|Machine Learning|由于路网中存在复杂的动态时空依赖关系，实现高精度的交通流预测是一项具有挑战性的任务|提出一种新的动态时空感知图神经网络(DSTAGNN)来建模路网中复杂的时空交互|open source|
|[Neural Tangent Kernel Analysis of Deep Narrow Neural Networks](https://proceedings.mlr.press/v162/lee22a.html)|ICML|2022|Jongmin Lee|Machine Learning|受宽神经网络启发。本篇文章是窄神经网络，但可以无限深。|神经切向核分析（Neural Tangent Kernel Analysis，NTK）|open source|
|[Low-Complexity Deep Convolutional Neural Networks on Fully Homomorphic Encryption Using Multiplexed Parallel Convolutions](https://proceedings.mlr.press/v162/lee22e.html)|ICML|2022|Eunsang Lee|Machine Learning|联邦学习就是为了解决隐私保护问题，本篇文章也是|全同态加密|open source|

----------------------------------------

- [Wide Bayesian neural networks have a simple weight posterior: theory and accelerated sampling（宽贝叶斯神经网络具有简单的权重后验：理论和加速采样）](https://proceedings.mlr.press/v162/hron22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Jiri Hron （美国谷歌研究中心，英国剑桥大学通信）
  - 问题：宽贝叶斯的权重计算复杂度过高，加速采样
  - 方法：提出一种马尔可夫链蒙特卡罗（MCMC）后验采样算法
  - 从这个论文的题目可以得到以下信息：
    - 论文的主题是关于宽Bayesian神经网络的，研究的内容包括其权重后验的理论和加速采样方法。
    - 文章的作者可能会介绍一个新的方法来简化宽Bayesian神经网络的权重后验，从而提高采样的效率。
    - 该论文可能会介绍一些理论结果，以支持作者的方法，并可能会涉及到神经网络的概率建模技术。
  - 先修知识
    - 宽Bayesian神经网络（Wide Bayesian neural networks）
      - 宽Bayesian神经网络（Wide Bayesian neural networks）是一种用于深度学习任务的神经网络模型，它在传统的深度学习模型中引入了贝叶斯方法。
      - 在传统的深度学习模型中，网络参数通常是确定性的，即每个参数都有一个唯一的确定值。**但在宽Bayesian神经网络中，网络参数被看作是随机变量，其取值可以由一个概率分布来描述。**这个概率分布可以用贝叶斯推断来估计，因此这种模型被称为贝叶斯神经网络。
      - 与传统的深度学习模型相比，宽Bayesian神经网络具有以下优点：
        - 它们可以**提供参数估计的不确定性**，这对于一些应用非常有用，如强化学习和控制等。
        - 它们可以更好地处理数据集中的**噪声和不确定性**，因为它们可以自适应地调整参数的不确定性。
        - 它们可以更好地处理**小数据集**，因为它们可以使用先验知识来缓解过拟合问题。
        - 宽Bayesian神经网络**通常使用马尔可夫蒙特卡罗（Markov Chain Monte Carlo，MCMC）方法进行贝叶斯推断**，但这种方法在计算上非常昂贵。因此，近年来出现了一些更有效的方法，如**变分推断和随机权重平均**等。
      **总之，宽Bayesian神经网络是一种强大的深度学习模型，它可以提供参数估计的不确定性，更好地处理数据集中的噪声和不确定性，并缓解过拟合问题。**
    - 权重后验
      - 在贝叶斯统计学中，**权重后验（posterior distribution）是指在给定模型和数据的情况下，权重的概率分布**。权重后验反映了我们对权重的不确定性，即对权重取值的可能性的估计。在神经网络中，**权重后验分布通常是一个高维的复杂分布，它反映了模型对数据的适应度和先验对权重的偏好。**
    - 采样（sampling）
      - 采样（sampling）是从一个给定的概率分布中获取样本的过程。在贝叶斯神经网络中，**可以使用采样方法来获得权重的随机样本**，用于进行模型预测和不确定性估计。通常，采样方法采用马尔科夫链蒙特卡罗（Markov Chain Monte Carlo, MCMC）方法，以从权重后验分布中获取样本。这种方法可以有效地探索权重空间，从而获取更准确的权重分布估计。另外，还有一些更快速的采样方法，例如重参数化技巧（reparameterization trick）和自适应重参数化技巧（adaptive reparameterization trick），它们可以加速采样过程并提高采样效率。
  - 这篇文章都讲了什么内容
    - 这篇论文是关于贝叶斯神经网络的。**论文提出了一种新的数据依赖性重参数化方法**，称为“repriorisation”，它将贝叶斯神经网络（BNN）后验分布转换为一种分布，其KL散度与BNN先验随着层宽的增加而消失。通过利用这种重参数化方法，论文提出了一种马尔可夫链蒙特卡罗（MCMC）后验采样算法，**该算法在BNN越宽时混合得越快。**
    - 相比而言，马尔可夫链蒙特卡罗（MCMC）在高维度上通常表现不佳，二者形成鲜明对比。
  - 数据集
    - LMC sampler 采样器
    - [cifar-10](https://www.cs.toronto.edu/~kriz/cifar.html)
    - [代码](https://github.com/google/wide_bnn_sampling)


----------------------------------------

- [The Dual Form of Neural Networks Revisited: Connecting Test Time Predictions to Training Patterns via Spotlights of Attention（重新审视神经网络的双重形式：通过注意力聚焦将测试时的预测和训练模式相连接）](https://proceedings.mlr.press/v162/irie22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Kazuki Irie（瑞士 AI 实验室）
  - 问题：如何更好地理解神经网络中训练数据点与测试时间预测之间的关系？
  - 方法：通过注意力聚焦将测试时的预测和训练模式相关联
  - 从这个论文的题目可以得到以下信息：
    - 该论文的主题是关于神经网络的，研究的内容是关于神经网络的双重形式（dual form）的重新审视，以及**通过注意力聚焦（spotlights of attention）来将测试时的预测与训练模式（training patterns）相连接。**
    - 文章的作者可能会介绍一种新的方法来解释神经网络中的双重形式，以及如何使用注意力聚焦来帮助理解神经网络的行为和提高其性能。
    - 该论文可能会涉及到神经网络的结构和设计，以及深度学习中的注意力机制。
  - 先修知识
    - 测试时的预测（Test Time Predictions）
      - 在机器学习中，模型通常在训练过程中学习如何从输入数据映射到输出数据。在测试时，模型将新的输入数据输入到模型中，并生成输出数据。这个过程被称为预测或推理，因为模型通过学习从训练数据中推断出的规律来预测新的未知数据的输出。
      - 在论文标题中，**"Test Time Predictions"指的是模型在测试时生成的输出数据**。这些预测通常是基于模型在训练数据上学习到的模式和规律。因此，**论文的主要目标是探讨如何将测试时的预测结果与训练数据中的模式和规律联系起来，以提高模型的性能和解释性。**
    - 训练模式（Training Patterns）
      - **在机器学习中，"Training Patterns"通常指的是模型在训练数据集上学习到的模式和规律**。训练数据集是由一组已知输入和对应的输出组成的，模型通过学习这些输入和输出之间的关系来建立一个映射函数，使得在未知数据上的预测能够尽可能准确。
      - 在这篇论文中，"Training Patterns"指的是模型在训练数据集上学习到的一些关键特征和模式。论文的主要目标是探讨如何将模型在训练数据集上学习到的这些特征和模式与测试时的预测结果联系起来，以提高模型的性能和解释性。**通过这种方式，论文提出了一种新的方法，即通过关注训练数据中的重要特征来指导模型生成测试时的预测结果，以提高模型的准确性和稳健性。**
  - 这篇文章讲了什么？
    - 这篇论文是关于神经网络的双重形式的。作者提出了一种新的方法，**将神经网络的训练数据点与测试时的预测相连接，以更好地理解神经网络中训练数据点与测试时间预测之间的关系**。这种双重形式表达了通过梯度下降（GD）训练的神经网络中任何线性层的前向操作，作为一个键/值/查询注意操作，其中键和值是训练数据点，查询是从测试输入生成的。这允许直接将测试时间预测与训练数据点相连接。
  - 数据集
    - 实验基于图像分类和语言建模中的小规模模型和数据集
    - 图像分类
      - [MNIST](https://www.kaggle.com/datasets/hojjatk/mnist-dataset)
      - [Fashion-MNIST](https://www.kaggle.com/datasets/zalando-research/fashionmnist)
    - NLP领域
      - [a small public domain book](Hochreiter & Schmidhuber, 1997)
      - [WikiText-2](https://paperswithcode.com/dataset/wikitext-2)

----------------------------------------

- [A deep convolutional neural network that is invariant to time rescaling（一种不受时间缩放影响的深度卷积神经网络）](https://proceedings.mlr.press/v162/jacques22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Brandon G. Jacques 1 Zoran Tiganj 2 Aakash Sarkar 3 Marc W. Howard 3 Per B. Sederberg 1（1弗吉尼亚大学**心理学系**，Charlottesville，VA，美国2印第安纳大学计算机科学系，布鲁明顿，美国3波士顿大学**心理与大脑科学系**，波士顿，MA，美国）
  - 问题：当语音呈现倍速播放时，于人而言不成问题，于模型而言却是天差地别。
  - 方法：受神经科学的启发，提出一种不受时间缩放影响的深度卷积神经网络，用以解决这类和**时间序列**相关的问题
  - 从这个论文的题目可以得到以下信息：
    - 该论文的主题是关于深度卷积神经网络（deep convolutional neural network）的，研究的目标是实现对时间重缩放（time rescaling）的不变性。
    - 时间重缩放是指对时间轴上的信号进行拉伸或压缩，**这可能会导致传统的神经网络对数据的处理能力下降。**
    - 该论文可能会介绍一种新的神经网络结构，该结构可以在保持高性能的同时，对时间重缩放具有不变性。这种不变性可能会通过卷积层和池化层的设计来实现，也可能会涉及到其他的技术和方法。
  - 先修知识
    - 时间重缩放（time rescaling）
      - 在信号处理和时间序列分析中，"time rescaling"（时间重缩放）是指对时间轴上的信号进行拉伸或压缩，**以改变其时间尺度或速度，而不改变其形状或特征**。例如，将一个音频信号加快或减慢播放速度，可以看作是对时间轴进行重缩放。
      - 这篇论文的主要贡献之一是提出了一种新的深度学习方法，可以在处理时间序列数据时具有更强的鲁棒性和泛化能力，能够处理不同时间尺度的信号并保持其不变性，从而有助于改善时间序列分析和信号处理等应用领域的性能。
  - 这篇文章讲了什么？
    - 这篇论文是关于一种深度卷积神经网络的，它对时间缩放不变。这个网络被称为“Scale-Invariant Temporal History Convolution network (SITHCon)”。它的一个特点是，它可以在对时间进行缩放的情况下，对输入数据进行分类，而不会影响其性能。
    - SITHCon是一种鲁棒性强的神经网络，它使用了一种对数分布的时间记忆，通过对数分布的时间记忆进行最大池化，可以实现时间上的尺度不变性。
  - RNN不行吗？
    - 需要注意的是，一般的 RNN 非常适合此目的。可以在方程式中编写一组线性过滤器。 1 和 4 作为循环网络（Liu &amp; Howard，2006）——从而产生尺度不变 RNN。然而，在不引入与 SMITH 非常相似的约束的情况下，如何确保 RNN 在训练中达到该状态并不明显。此外，即使 RNN 生成了一组时间基函数，也不清楚如何访问时间基函数的索引，以使内存尺度不变。
  - 数据集
    - Morse Decoder
    - Morse Addition
    - [AudioMNIST](https://www.kaggle.com/datasets/sripaadsrinivasan/audio-mnist)



----------------------------------------

- [Training Your Sparse Neural Network Better with Any Mask（用任何掩码更好地训练您的稀疏神经网络）](https://proceedings.mlr.press/v162/jaiswal22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Ajay Jaiswal（德克萨斯大学奥斯汀）
  - 问题：目前的研究工作侧重于越来越复杂的剪枝方法。
  - 方法：从头开始训练稀疏子网络，改进修剪子网络的训练技术，即稀疏训练。
  - 从这个论文的题目可以得到以下信息：
    - 该论文的主题是关于稀疏神经网络（sparse neural network）的，研究的内容是如何更好地训练这种类型的神经网络，而不受稀疏掩码（sparse mask）的限制。
    - 稀疏神经网络是指在神经网络中使用了稀疏掩码，即一种掩膜（mask）技术，可以将一部分神经元的输出设置为零，从而减少模型的计算量和参数数量。
    - 该论文可能会介绍一种新的训练方法，该方法可以更好地处理稀疏掩码，并提高稀疏神经网络的性能。这种方法可能会涉及到优化算法和正则化技术等方面的知识。
    - 该论文可能会对深度学习中的稀疏神经网络的设计和训练方法进行探讨，并提出了一些新的思路和方法。
  - 先修知识
    - 掩码（mask）
      - "Mask"指的是用于稀疏化神经网络的二元掩码，它可以将神经元的输出设置为0或非0的值。这个掩码可以通过训练过程中的某些规则来生成，也可以通过手动设计。
    - 稀疏神经网络（Sparse Neural Network）
      - "稀疏神经网络"是指具有很少活跃神经元的神经网络。本文中的稀疏神经网络采用了二元掩码来实现，每个掩码的元素值为0或1，表示相应的神经元是否处于活跃状态。因此，这种稀疏神经网络的输出仅依赖于少数几个活跃的神经元，从而使得网络的计算效率显著提高。
    - 一言以蔽之，**稀疏掩码即剪掉不必要的枝**
  - 这篇文章讲了什么？
    - 这篇论文是关于如何更好地训练稀疏神经网络的。后期剪枝不如前期早做准备。作者提供了一个稀疏再训练技术 (TOST) 工具包，并证明，仅通过将作者们的技术引入现有流行修剪算法识别的稀疏掩码的训练中，作者们的方法大大减少了训练不稳定性，并提高了训练的性能和泛化子网络。
    - 通常认为**掩码的质量对于稀疏再训练最重要**，作者认为**改进修剪掩码的训练技术**更重要。
    - 提出了一个策划且易于适应的训练工具包，用于从头开始训练任何稀疏掩码，而无需任何额外的开销。
  - 数据集
    我们展示了各种流行数据集（CIFAR-10、CIFAR-100、TinyImageNet）、架构（ResNet-18/32/104、Vgg16、MobileNet）和稀疏掩码选项（彩票、SNIP/GRASP、SynFlow 甚至随机修剪）的显着性能提升，尤其是在高稀疏级别。
  - [代码](https://github.com/VITA-Group/ToST)



----------------------------------------

- [Robust Fine-Tuning of Deep Neural Networks with Hessian-based Generalization Guarantees（基于Hessian的泛化保证的深度神经网络的鲁棒微调）](https://proceedings.mlr.press/v162/ju22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Haotian Ju （美国马萨诸塞州波士顿东北大学）
  - 问题：迁移学习容易过拟合，带上噪声更麻烦
  - 方法：基于Hessian对模型的泛化误差上界做评估
  - 从这个论文的题目可以得到以下信息：
    - 该论文的主题是关于深度神经网络（deep neural network）的，研究的内容是如何通过基于Hessian矩阵的泛化保证（generalization guarantees）来实现深度神经网络的稳健微调（robust fine-tuning）。
    - 神经网络的微调是**指在一个预先训练好的模型的基础上，继续进行训练以适应新的数据集或任务**。稳健微调的目标是在保持模型性能的同时，提高模型的鲁棒性和泛化能力。
    - 该论文可能会介绍一种新的微调方法，该方法可以使用Hessian矩阵来估计模型在微调过程中的性能和泛化能力，并通过对微调过程中的梯度进行调整，实现模型的稳健微调。这种方法可能会涉及到优化算法、泛化理论和微调技术等方面的知识。
    - 该论文可能会对深度学习中的微调方法和泛化理论进行探讨，并提出了一些新的思路和方法，以提高深度神经网络的鲁棒性和泛化能力。

  - 先修知识
    - Hessian 矩阵
      - Hessian矩阵是一个二阶偏导数组成的方阵，**它描述了一个函数的局部曲率和形状**。在机器学习中，特别是在深度学习中，Hessian矩阵常常用来衡量损失函数的二阶导数，从而提供了有关模型参数的更丰富的信息。
      - 在优化问题中，**Hessian矩阵可以帮助确定一个函数的局部最小值或最大值**。在深度学习中，通过计算损失函数的Hessian矩阵，可以提供更多有关模型参数的信息，例如确定模型参数的更新方向和步长，并且可以帮助优化算法更快地收敛到最佳值。
      - 然而，计算Hessian矩阵需要计算二阶导数，**这通常比计算一阶导数更为困难和耗时，因此在实际应用中很少使用Hessian矩阵**。一种常见的替代方法是使用自适应优化算法（例如Adam和Adagrad）**来估计Hessian矩阵的逆矩阵**，从而可以在不需要显式计算Hessian矩阵的情况下获得类似的信息。此外，还有一些其他方法，例如牛顿共轭梯度法和BFGS算法，可以用来计算Hessian矩阵的**逆矩阵**。
    - PAC-Bayesian
      - PAC-Bayesian（PAC是Probable Approximations with Confidence的缩写，意为带有置信度的概率近似）是一种用于评估机器学习模型泛化性能的理论框架。
      - PAC-Bayesian理论基于贝叶斯推断，提供了一种方法来估计模型在新数据上的泛化误差的上限，并且可以提供置信度的度量。
      - 具体来说，PAC-Bayesian理论基于一个假设：如果一个模型在训练集上表现良好，那么它也应该在未曾见过的新数据上表现良好。在这个假设的基础上，PAC-Bayesian理论**提供了一些数学上的界限，这些界限可以告诉我们，一个模型的泛化误差上限是多少**，并且可以提供泛化误差上限的置信度。这些界限通常采用KL散度的形式，即衡量两个概率分布之间的距离。
    - **初始化的距离**指的是模型参数初始值与最终微调得到的参数值之间的距离。

  - 这篇文章讲了什么？
    - 这篇论文是关于深度神经网络的鲁棒性和泛化性能的。作者使用了PAC-Bayesian分析，发现除了与初始化的距离之外，Hessian还通过深度神经网络对噪声注入的噪声稳定性影响泛化。作者基于这一观察结果，为广泛的微调方法开发了基于Hessian距离的泛化界限。
    - 一言以蔽之，**迁移学习容易过拟合。作者使用 PAC-贝叶斯方法分析了微调深度模型的泛化误差。提出了一种基于Hessian矩阵的泛化界限方法，以提高模型的稳定性和泛化能力。该方法可以用于广泛的微调方法，并且考虑了模型初始值和噪声注入的影响，从而提供更加准确的模型泛化上界。**
  - 数据集
    - [CIFAR-10/100](https://www.cs.toronto.edu/~kriz/cifar.html)，采用的ResNet-18和ResNet-50两种架构.
    - [DomainNet](https://paperswithcode.com/dataset/domainnet)，采用的 ResNet-18 和 ResNet-101
      - DomainNet是一个大规模的多域图像数据集，包含六个不同的领域：sketch（素描）、painting（绘画）、quickdraw（速绘）、infograph（信息图）、clipart（剪贴画）和real（真实图片）。该数据集由微软亚洲研究院于2018年发布，包含超过50万张图像，用于推动计算机视觉领域中的跨域学习和迁移学习研究。DomainNet数据集中的图像涵盖了众多不同的类别，例如动物、建筑、食物、家具、人物、自然景观等等。
    - [MRPC](https://paperswithcode.com/dataset/mrpc)，采用的RoBERTa-Base
      - MRPC（Microsoft Research Paraphrase Corpus）是一个由微软研究院发布的用于自然语言处理（NLP）任务的数据集，其中包含5,801对句子，每一对句子都被标注为是“相似的”（paraphrase）或“不相似的”（not paraphrase）。这个数据集最初被用于评估句子相似度任务，即给定两个句子，判断它们是否具有相同的语义含义。这个数据集已经成为了许多NLP任务的基准数据集之一，例如文本匹配、句子相似度计算、语言模型等等。


----------------------------------------

- [Matching Learned Causal Effects of Neural Networks with Domain Priors（匹配神经网络与域先验的学习因果效应）](https://proceedings.mlr.press/v162/kancheti22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Sai Srinivas Kancheti（印度海德巴理工学院 微软研究院）
  - 问题：一方面，如果训练数据包含因果关系和相关关系，优化预测精度的模型**不一定学习输入和输出变量之间的真实因果关系**（胖子未必跑不动）。另一方面，专家用户通常了解某些输入变量与领域知识输出之间的因果关系。
  - 方法：提出了一种正则化方法，该方法将神经网络的学习因果效应与域先验对齐，包括直接效应和总因果效应。
  - 从这个论文的题目可以得到以下信息：
    - 该论文的主题是关于神经网络的，研究的内容是**如何通过匹配神经网络的学习因果效应（causal effects）和领域先验（domain priors）来提高模型的泛化能力。**
    - 在机器学习中，因果推断（causal inference）是指通过观察变量之间的因果关系，来推断出一些变量对其他变量的影响。神经网络可以用于因果推断，但是在领域迁移（domain transfer）和泛化能力方面仍然存在一些挑战。
    - 该论文可能会介绍一种新的方法，**该方法可以使用领域先验来指导神经网络的因果推断**，并通过匹配学习的因果效应和先验知识来实现模型的泛化。这种方法可能会涉及到因果推断、领域迁移和神经网络的设计等方面的知识。
    - 该论文可能会对深度学习中的因果推断和领域迁移等问题进行探讨，并提出了一些新的思路和方法，以提高神经网络的泛化能力。
  - 先修知识
    - Domain Priors（领域先验）
      - 在机器学习中，"domain"通常指的是数据集的特征和属性。"Domain priors"指的是先验知识，即我们在进行机器学习任务之前已经知道的关于数据集的一些基本假设或规律
      - 在本文中，指的是来自因果推断领域的先验知识。因果推断是一种研究因果关系的方法，在机器学习中被广泛应用于处理因果关系和干扰问题。具体来说，该论文中的"domain priors"是指我们对于因果关系的先验知识，例如我们已经知道某些变量之间存在因果关系，或者我们已经知道某些变量是干扰变量，可能会影响因果关系的推断。在这个论文中，作者使用这些"domain priors"来帮助神经网络模型推断因果关系，并提高模型的泛化能力。
  - 这篇文章讲了什么？
    - 这篇论文是关于如何将神经网络的学习因果效应与领域先验相匹配的。作者提出了一种新的算法，称为CREDO，它可以将神经网络的学习因果效应与领域先验相匹配，并且训练的模型是稳健的，并且在噪声输入上提高了准确性。
    - 一言以蔽之，目前的研究重点都在因果效应方面的决策事后解释，使用反事实进行解释或增强。这些努力都没有考虑到专家人类用户在实践中与 NN 模型交互的可能性，可能事先了解输入和输出变量之间的关系，甚至是因果变量，从领域理解。
    - 该方法可以与任何可微先验一起工作，表示对域的完整或部分理解。
    - 区分了**直接效应和总因果效应**，并展示了如何在 CREDO 中考虑两者。
  - 数据集和先验，作者使用两种数据集：
    - 来自 BNLearn 存储库 (Scutari & Denis, 2014) 的基准合成数据集，其中因果图是已知的，所有效果都可以计算
    - 八个真实世界的数据集，没有真正的因果图的知识，其中只能计算 ¢
    

----------------------------------------

- [Composing Partial Differential Equations with Physics-Aware Neural Networks（用物理感知神经网络组合偏微分方程）](https://proceedings.mlr.press/v162/karlbauer22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Matthias Karlbauer（图宾根大学，图宾根，德国）
  - 问题：<table><tr><td bgcolor=#D1EEEE>方向不符</td></tr></table>
  - 方法：<table><tr><td bgcolor=#D1EEEE>方向不符</td></tr></table>
  - 从这个论文的题目可以得到以下信息：
    - 该论文的主题是关于物理感知神经网络（physics-aware neural network）的，研究的内容是如何将偏微分方程（partial differential equations）和神经网络结合起来，以实现物理模型的建模和求解。
    - 偏微分方程是数学中一类描述自然界中物理和工程问题的方程。在物理建模中，常常需要求解偏微分方程，而神经网络则可以用于函数拟合和数据驱动建模。
    - 该论文可能会介绍一种新的方法，该方法可以使用神经网络来建模偏微分方程，并将其与物理模型相结合，从而实现对物理系统的建模和预测。这种方法可能会涉及到神经网络、偏微分方程和物理建模等方面的知识。
    - 该论文可能会对深度学习中的物理感知神经网络进行探讨，并提出了一些新的思路和方法，以提高神经网络在物理建模中的应用能力。
  - 先修知识
  - 这篇文章讲了什么？
    - 这篇论文是关于物理感知神经网络（Physics-Aware Neural Networks）如何组合偏微分方程（Partial Differential Equations）的学习能力和数值模拟中的物理和结构知识，以组合方式对偏微分方程的组成部分进行建模。

  - 这篇文章的创新点是什么？
    - 这篇论文的创新点是将物理和结构知识与人工神经网络的学习能力相结合，通过组合方式对偏微分方程的组成部分进行建模，从而实现了对偏微分方程的学习。这种方法被称为物理感知神经网络（Physics-Aware Neural Networks）

----------------------------------------

- [Neural Network Poisson Models for Behavioural and Neural Spike Train Data（行为和神经脉冲序列数据的神经网络泊松模型）](https://proceedings.mlr.press/v162/khajehnejad22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Moein Khajehnejad（澳大利亚墨尔本大学信息技术学院数据科学与人工智能系）
  - 问题：对于监测神经元和行为之间关系的模型乏力。任务计算约束的简单反射往往不足以捕获分布在不同大脑区域的感觉输入和动作的复杂神经表示，无法解释试验之间的行为和神经记录的时间不规则性。总之所有的方式都有缺陷。
  - 方法：提出了一种新颖的神经网络泊松过程模型：（i）灵活地学习环境刺激和神经表示之间的联系，以及神经表示和行为反应； (ii) 联合拟合行为和神经数据； (iii) 处理不同试验的反应时间之间的差异
  - 从这个论文的题目可以得到以下信息：
    - 该论文的主题是关于神经网络的，研究的内容是如何使用神经网络模型来处理**行为和神经脉冲序列数据**（behavioural and neural spike train data）。
    - 神经脉冲序列数据是指神经元在时间上的离散脉冲序列，通常用于研究神经系统的活动和行为。
    - 该论文可能会介绍一种新的神经网络模型，该模型可以用于建模和预测**行为和神经脉冲序列数据**。这种模型可能会采用泊松分布（Poisson distribution）来描述神经脉冲序列的统计特征，并将神经网络与泊松分布相结合，从而实现对数据的建模和预测。这种方法可能会涉及到神经网络、泊松分布和时间序列分析等方面的知识。
    - 该论文可能会对深度学习在神经科学中的应用进行探讨，并提出了一些新的思路和方法，以提高神经网络在处理**行为和神经脉冲序列数据**方面的能力。

  - 先修知识
    - 行为和神经脉冲序列数据（behavioural and neural spike train data）
      - **行为和神经脉冲序列数据是指在神经科学中记录和分析动物行为和神经脉冲（spike）的时间序列数据**。动物的行为可以通过各种传感器和设备进行记录，例如运动跟踪器、摄像机、力传感器等等。**神经脉冲序列数据则是通过在动物大脑中植入电极或光学探针等设备来记录神经元的活动**。
      - 行为和神经脉冲序列数据可以用来研究神经系统和行为之间的关系，例如如何感知和响应环境刺激、如何学习和记忆、如何协调运动和行为等等。对于神经科学研究来说，行为和神经脉冲序列数据是非常重要的，因为它们可以提供神经系统活动的高分辨率时间信息，从而揭示神经信息的动态特性和复杂性。
      - 分析和建立数学模型是对行为和神经脉冲序列数据进行研究的重要手段。例如，可以使用统计方法对行为和神经脉冲序列数据进行分析，例如计算神经脉冲的频率、相关性和时序结构等等。此外，还可以使用机器学习和深度学习方法对行为和神经脉冲序列数据进行建模和预测，例如基于神经网络的行为识别和运动控制等应用。
      - 行为和神经脉冲序列数据在神经科学和计算神经科学等领域具有广泛的应用前景。例如，可以使用这些数据来研究神经系统的发育和退化、认知和行为障碍的机制、神经可塑性和学习等等问题。同时，这些数据也可以应用于神经工程学和脑机接口等领域的研究，例如开发控制假肢和神经调控技术等。
    - 泊松分布（Poisson distribution）
      - 泊松分布（Poisson distribution）是一种概率分布，用于描述在给定时间或者空间内某个事件在平均上发生的次数。泊松分布通常用来处理稀疏事件的计数问题，例如在某个时间段内电话的呼叫次数、某个地区的交通事故数、某个网站的访问量等等。
      - 泊松分布的概率质量函数为：
      $$P(X=k) = (\lambda^k * e^{-\lambda}) / k!$$
      - 其中，$\lambda$表示单位时间或单位空间内事件的平均发生率，k表示在单位时间或单位空间内事件发生的次数。泊松分布的特点是，它的均值和方差都等于$\lambda$，即 $E(X) = Var(X) = \lambda$。
      - 泊松分布在实际应用中具有广泛的应用，例如在保险精算、信用风险评估、电信网络分析等领域都有应用。在机器学习和深度学习中，泊松分布也常用于模型的损失函数，例如用于图像去噪、稀疏编码和自编码等任务中。
  - 这篇文章讲了什么？
    - 这篇论文提出了一种新的神经网络泊松过程模型，该模型可以灵活地学习刺激与神经、神经与行为反应之间的联系，同时拟合行为和神经数据，并从所选时间间隔中分离出脉冲计数统计信息。
    - 该框架允许对模型进行有效训练，**而无需假设输入刺激与神经和行为过程之间关系的功能形式**。
  - 数据集
    - 视觉识别：来自老鼠的神经像素探针（Steinmetz dataset）
    - 具有相互连接的感官和集成电路的分层网络输出，它们模拟了基于运动的任务的行为

----------------------------------------

- [DSTAGNN: Dynamic Spatial-Temporal Aware Graph Neural Network for Traffic Flow Forecasting（DSTAGNN：用于流量预测的动态时空感知图神经网络）](https://proceedings.mlr.press/v162/lan22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Shiyong Lan（ 中国四川大学计算机科学专业）
  - 问题：由于路网中存在复杂的动态时空依赖关系，实现高精度的交通流预测是一项具有挑战性的任务
  - 方法：提出一种新的动态时空感知图神经网络(DSTAGNN)来建模路网中复杂的时空交互
  - 从这个论文的题目可以得到以下信息：
    - 该论文的主题是关于图神经网络（graph neural network）的，研究的内容是如何使用动态空间-时间感知图神经网络（dynamic spatial-temporal aware GNN）来进行交通流量预测（traffic flow forecasting）。
    - **交通流量预测是指预测未来某个时间点的交通流量情况**，是交通运输规划和交通控制领域中的一个重要问题。
    - 该论文可能会介绍一种新的动态空间-时间感知图神经网络，该神经网络可以有效地处理交通网络中的动态空间-时间信息，并用于交通流量预测。这种方法可能会涉及到图神经网络、空间-时间建模和交通流量预测等方面的知识。
    - 该论文可能会对深度学习在交通领域中的应用进行探讨，并提出了一些新的思路和方法，以提高神经网络在交通流量预测方面的能力。

  - 先修知识
    - 动态空间-时间感知图神经网络（Dynamic Spatial-Temporal Aware Graph Neural Network，DSANet）
      - 动态空间-时间感知图神经网络（Dynamic Spatial-Temporal Aware Graph Neural Network，DSANet）是一种用于处理**时空数据**的图神经网络。DSANet最初是由中国科学技术大学提出的，用于解决**视频分割、行为识别和动作检测**等任务。
      - DSANet的主要特点是，**可以同时考虑时空维度的特征，从而对时空数据进行建模和分析**。DSANet将时空数据看作是一个图结构，**其中节点表示空间位置，边表示时间维度上的关系**。DSANet利用图神经网络对时空图进行**特征提取和学习**，从而实现对时空数据的建模和分析。
      - DSANet的另一个特点是，**它可以自适应地处理不同尺度的时空数据**。DSANet使用自适应卷积和自适应池化等技术，可以在不同时间和空间尺度上对数据进行建模和分析。此外，DSANet还使用了多尺度注意力机制，可以自适应地对不同尺度的特征进行加权和融合，从而提高网络的性能和鲁棒性。
      - 总的来说，DSANet是一种非常有前景的时空数据处理方法，可以广泛应用于视频分割、行为识别、动作检测、交通流量预测等领域。


  - 这篇文章讲了什么？
    - DSTAGNN是一种新型的动态空间-时间感知图神经网络，用于交通流量预测。它可以捕捉道路网络的空间-时间相关性，并具有动态图学习模块，以针对交通网络的动态特征学习。
    - 考虑到历史数据携带有关道路网络的空间结构的内在动态信息
    - 其次，我们设计了一种新的时空注意模块，改进了多头注意力机制以捕获节点之间的动态时间依赖性，使用空间注意力模块来改进ChebyNet图卷积操作，以捕获节点之间的动态空间依赖性。
    - 在STAD生成的时空感知图(STAG)上运行的图卷积可以**减少对路网先验信息的依赖**。结合我们的时空注意模块和多感受野门控卷积，我们的 DSTAGNN 进一步提高了对时间序列数据中动态时空依赖性的认识
  - 数据集
    - [PeMS](https://github.com/SANDAG/PeMS-Datasets)
    - 来自加州、PEMS03、PEMS04、PEMS07 和 PMS08 的四个真实道路交通数据集进行了比较实验，这些数据集由 (Song et al., 2019) 发布。

----------------------------------------

- [Neural Tangent Kernel Analysis of Deep Narrow Neural Networks（深度窄神经网络的神经切线核分析）](https://proceedings.mlr.press/v162/lee22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Jongmin Lee（韩国首尔国立大学数学科学部）
  - 问题：受宽神经网络启发。本篇文章是窄神经网络，但可以无限深。
  - 方法：神经切向核分析（Neural Tangent Kernel Analysis，NTK）
  - 从这个论文的题目可以得到以下信息：
    - 该论文的主题是关于神经网络的，研究的内容是如何使用神经切向核分析（neural tangent kernel analysis）来研究深度窄神经网络（deep narrow neural networks）。
    - 神经切向核是指神经网络在训练过程中的切向空间上的核函数，可以用于研究神经网络的训练和性能。
    - **深度窄神经网络是指神经网络中层数较少、每层神经元数量较少的一种网络结构，可以用于处理一些低维数据和小规模任务。**
    - 该论文可能会介绍一种新的方法，该方法可以使用神经切向核分析来研究深度窄神经网络的训练和泛化性能，并探讨其与深度宽神经网络的差异。这种方法可能会涉及到神经网络、核方法、泛化理论和数学分析等方面的知识。
    - 该论文可能会对深度学习中神经网络的设计和训练方法进行探讨，并提出了一些新的思路和方法，以提高神经网络的性能和泛化能力。

  - 先修知识
    - 神经切向核分析（Neural Tangent Kernel Analysis，NTK）
      - 神经切向核分析（Neural Tangent Kernel Analysis，NTK）是一种用于理解神经网络学习行为的分析框架。NTK的核心思想是，将神经网络看作是一组非线性核函数的组合，这些核函数可以用来描述神经网络的学习过程。**NTK分析的重点是研究神经网络在训练过程中权重的演化，以及权重对输出的影响**。
      - NTK分析可以帮助我们理解神经网络的学习行为，**例如为什么深层神经网络可以有效地拟合高维数据、为什么梯度下降等优化算法可以收敛到全局最优解、以及神经网络的泛化性能等问题。**此外，NTK分析还可以指导神经网络的设计和优化，例如通过设计合适的非线性核函数来提高神经网络的性能。
      - NTK分析在近年来受到了广泛的关注，并且已经被应用于许多机器学习问题的研究，例如图像分类、语音识别、自然语言处理等领域。
  - 这篇文章讲了什么？
    - 宽神经网络，本篇文章是窄神经网络，但可以无限深。
    - 与宽神经网络相比，作者的结果并不表明使用深度神经网络有任何好处。
    - 仅仅提供了一个启发性的方向。
  - 数据集
    - [MNIST](https://www.kaggle.com/datasets/hojjatk/mnist-dataset)，采用的Very deep MLP和Very deep CNN
 



----------------------------------------

- [Low-Complexity Deep Convolutional Neural Networks on Fully Homomorphic Encryption Using Multiplexed Parallel Convolutions（基于多倍并行卷积的全同态加密低复杂度深度卷积神经网络）](https://proceedings.mlr.press/v162/lee22e.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Eunsang Lee（首尔国立大学电气与计算机工程系）
  - 问题：联邦学习就是为了解决隐私保护问题，本篇文章也是
  - 方法：全同态加密
  - 从这个论文的题目可以得到以下信息：
    - 该论文的主题是关于全同态加密（fully homomorphic encryption）和深度卷积神经网络（deep convolutional neural network）的，研究的内容是如何在全同态加密环境下使用多路复用并行卷积（multiplexed parallel convolutions）实现低复杂度的深度卷积神经网络。
    - 全同态加密是指一种加密技术，可以在不暴露明文的情况下，对密文进行计算和处理，具有广泛的应用前景。
    - **深度卷积神经网络是一种用于图像处理和分析的深度学习模型**，通常需要大量的计算资源和存储空间。
    - 该论文可能会介绍一种新的方法，该方法可以使用**多路复用并行卷积**来实现在全同态加密环境下的低复杂度深度卷积神经网络。这种方法可能会涉及到加密技术、神经网络、多路复用并行卷积和计算优化等方面的知识。
    - 该论文可能会对全同态加密在深度学习中的应用进行探讨，并提出了一些新的思路和方法，以提高深度学习在安全计算和隐私保护方面的能力。

  - 先修知识
    - 全同态加密
      - 全同态加密（Fully Homomorphic Encryption，FHE）是一种加密技术，可以使得密文在不暴露明文的情况下，仍然可以进行加法和乘法等数学运算。具体来说，全同态加密使得数据可以在加密状态下进行计算，得到的结果也是加密的，而不需要解密。这种加密技术可以保护数据隐私，使得计算可以在加密数据上进行，从而避免了数据泄露的风险。
      - 全同态加密是一个非常强大的加密技术，因为它可以用于许多实际应用，例如云计算、隐私保护和数据分析等。但是，全同态加密的计算效率较低，而且实现起来比较困难。目前，全同态加密已经成为了加密领域的研究热点之一，许多研究机构和公司都在开展相关的研究和应用。
  - 这篇文章讲了什么？
    - 客户端不愿意将他们的敏感私有数据发送到服务器。为了保护客户的隐私，已经研究了隐私保护机器学习 (PPML) 以直接对加密数据进行推理。
    - 以前的大多数PPMLs采用非标准卷积神经网络(CNNs)，**减少了层数或用低阶多项式替换激活函数**。这种方法需要新设计的 CNN 的训练阶段。然而，由于训练是一个昂贵的过程，甚至访问训练数据集通常由于数据隐私问题而受到限制，因此在许多实际应用中，训练请求是服务器的负担。此外，为大型数据集设计非标准 CNN **并不容易**。
    - 当网络很复杂，浅层SCNN显得乏力。因此，本文为 VDSCNN 实施实用的 PPPML。针对ResNet
    这篇论文是关于使用多路并行卷积的全同态加密上的低复杂度深度卷积神经网络的。这种方法可以任意增加可用级别的消耗。最近，使用引导程序首次实现了加密CIFAR-10图像的SCNN，准确率很高。
    - 这篇论文的创新点是成功地在全同态加密（FHE）上实现了标准CNN模型，这是第一次使用多路并行卷积实现加密CIFAR-10图像的SCNN，准确率很高。 为了提高性能，作者首先使用多路并行卷积来最小化总引导运行时间，紧凑地收集多个通道的稀疏输出数据。 他们还提出了虚数去除引导来防止深度神经网络在近似ReLU操作期间发生灾难性分歧。
  - 数据集
    - [CIFAR-10/100](https://www.cs.toronto.edu/~kriz/cifar.html)
    - [代码](https://github.com/snu-ccl/FHE-MP-CNN)



-----------------------------------------
#### 7. May 27, 2023(week 7)

|Title|Publication|Year|Authors|Area|Problem|Main Method|Datasets|
| :---:| :---:| :---:| :---:|:---:|:---:|:---:|:---:|
|[Sharp-MAML: Sharpness-Aware Model-Agnostic Meta Learning](https://proceedings.mlr.press/v162/abbas22b.html)|ICML|2022|Momin Abbas|Machine Learning|MAML由于固有的双层问题结构，导致其难以优化。具体来说，MAML的损失情况比经验风险最小化方法更复杂，鞍点可能更多，局部最小化器可能更大|利用最近发明的锐度感知最小化，开发了一种锐度感知的MAML方法，作者称之为Sharp-MAML。|open source|
|[Active Sampling for Min-Max Fairness](https://proceedings.mlr.press/v162/abernethy22a.html)|ICML|2022|Jacob D Abernethy|Machine Learning|资源分配的公平性问题，通常采用的模型在训练时忽视了某些代表性不足的群体，而直接降低其他组的权重又是一种“降级”的表现，这可能导致不必要的降低整体表现。|通过主动采样和重加权策略，**选取最差的节点来更新权重**，这种“升级”的方式，如果提高了最差组的性能，也仅仅只会降低一个组的性能。|open source|
|[Meaningfully debugging model mistakes using conceptual counterfactual explanations](https://proceedings.mlr.press/v162/abid22a.html)|ICML|2022|Abubakar Abid|Machine Learning|如何理解和解释训练模型所犯的错误？为什么会将斑马分类为狗？了解这一点是非常重要的，可以提高鲁棒性、解决概念漂移和减轻偏差。通常所采用的方式是动查看模型在许多测试样本上的错误并猜测这些错误预测的潜在原因。|本文中提出了一种系统方法，即概念反事实解释 (CCE)，它解释了为什么分类器根据人类可理解的概念在特定测试样本上出错。|open source|
|[Learning of Cluster-based Feature Importance for Electronic Health Record Time-series](https://proceedings.mlr.press/v162/aguiar22a.html)|ICML|2022|Henrique Aguiar|Machine Learning|电子病历的数据是稀疏的、异构的、多维的和多模态的时间序列，怎么从中学习模型，进行病人疾病发展倾向进行预测。|采用时间序列，注意力机制，聚类的方法，提出了一个有监督的深度学习模型来对 EHR 数据进行聚类|open source|
|[Minimum Cost Intervention Design for Causal Effect Identification](https://proceedings.mlr.press/v162/aguiar22a.html)|ICML|2022|Sina Akbari|Machine Learning|确定因果关系的成本过高|贪心算法 + 多项式时间启发式算法 或者 对数因子近似算法|open source|
|[Deploying Convolutional Networks on Untrusted Platforms Using 2D Holographic Reduced Representations](https://proceedings.mlr.press/v162/alam22a.html)|ICML|2022|Mohammad Mahmudul Alam|Machine Learning|如何在不信任的平台上部署CNN？|使用二维全息简化表示法|open source|









---------------------------------------------------
- [Sharp-MAML: Sharpness-Aware Model-Agnostic Meta Learning（Sharp-MAML：锐度感知模型不可知元学习）](https://proceedings.mlr.press/v162/abbas22b.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Momin Abbas（Renselaer 理工学院，Troy）
  - 问题：MAML由于固有的双层问题结构，导致其难以优化。具体来说，MAML的损失情况比经验风险最小化方法更复杂，鞍点可能更多，局部最小化器可能更大
  - 方法：利用最近发明的锐度感知最小化，开发了一种锐度感知的MAML方法，作者称之为Sharp-MAML。
  - 先修知识
    - 模型不可知元学习(MAML)
      - 模型不可知元学习（Model-Agnostic Meta-Learning，MAML）是一种元学习算法，旨在通过在一组相关任务上**快速调整模型参数，使得该模型在新任务上能够快速适应。**
      - 具体来说，MAML算法**包含两个嵌套循环**的过程。外循环用于迭代更新模型的初始参数，内循环用于在每个任务上进行快速调整。在内循环中，模型通过少量的梯度下降步骤来适应当前任务，以获得一个良好的初始化状态。在外循环中，模型的初始参数被更新为在所有任务中表现最好的参数，以便在新任务上获得更好的性能。
      - MAML的一个重要优点是，它在不同的任务之间共享模型参数，因此可以在只有少量标记数据的情况下进行元学习。此外，由于它是**模型不可知**的，因此可以与各种不同类型的模型和损失函数一起使用，从而具有广泛的适用性。
      - MAML已经在各种领域得到了广泛的应用，包括计算机视觉、自然语言处理、机器人学习等领域。
    - 元学习（Meta-Learning）
      - **元学习（Meta-Learning）是指学习如何学习的过程，也称为“学习到学习”（Learning to Learn）**。元学习的**目标是**设计一个能够自动学习适应新任务的学习算法，而不是手动为每个新任务设计一个新算法。
      - 在元学习中，算法需要**从多个相关任务中获取经验**，学习如何快速适应新任务。通常，元学习算法会学习一个**模型或策略**，该模型或策略可以在新任务上进行快速调整，以适应该任务的特定特征和要求。元学习算法通常使用一些指标来衡量模型在新任务上的适应能力，例如泛化误差、收敛速度等。
      - 元学习已经在许多应用领域得到了广泛的应用，例如计算机视觉、自然语言处理、机器人学习等。**元学习的优点之一是它可以减少对大量标记数据的依赖，**因为它可以使用先前学习的经验来快速适应新任务。另外，**元学习还可以提高模型的泛化能力，**使其在未见过的数据上表现更好。
    - 锐度感知（Sharpness-Aware）
      - Sharpness-Aware是指在模型不可知元学习（MAML）中考虑模型的锐度（sharpness）。Sharpness通常是指模型的**局部梯度范数的大小**，用来反映模型的平滑度和泛化能力。**Sharpness较低的模型通常具有更好的泛化能力，因为它们更容易避免过拟合。**
      - 在Sharp-MAML中，为了更好地控制模型的泛化能力，**算法通过最大化每个任务的训练损失和验证损失之间的差异，来推动模型的锐度较低**。具体来说，Sharp-MAML使用一种称为“sharpness-aware gradient”的梯度计算方式，这种方式可以精确地计算模型参数的梯度，并考虑到参数的锐度。通过调整梯度计算方式，Sharp-MAML可以使得模型在元学习过程中**更加注重锐度，从而提高模型的泛化能力。**
      - 实验证明，Sharp-MAML在某些情况下可以显著提高模型的泛化能力和元学习性能，尤其是在使用少量训练数据时。**然而，也有一些研究表明，在某些情况下，Sharp-MAML并不能带来明显的性能提升，甚至可能会导致性能下降。**因此，使用Sharp-MAML需要根据具体情况进行调整和优化，才能发挥其最大的优势。
    - 鞍点（Saddle point）
      - 鞍点（Saddle point）是指在高维空间中的某个点，该点的梯度为0，但是它既不是局部最小值也不是局部最大值。在这样的点上，函数在某些方向上是上升的，而在另一些方向上是下降的。因此，鞍点可能会导致优化算法停留在局部极值附近，而不能找到全局最优解。
      - 在机器学习中，优化问题通常是在高维空间中进行的，因此鞍点是一个普遍存在的问题。特别是在深度神经网络中，由于网络的非线性结构和大量的参数，鞍点会更加常见。
    - 局部最小化器（Local Minimizer）
      - 局部最小化器（Local Minimizer）是指在优化问题中，找到局部最小值的算法。在机器学习中，常用的局部最小化器包括梯度下降、牛顿法、共轭梯度等。
      - 然而，局部最小化器通常会受到鞍点的影响，因为它们可能会停留在鞍点处，而无法找到全局最优解。因此，为了避免被鞍点困扰，通常需要使用更高级的优化算法，如随机梯度下降、动量优化、自适应学习率等。此外，还可以通过调整模型结构、初始化方式等方法来减少鞍点的影响，从而提高优化算法的收敛速度和稳定性。
  - 本文内容
    - 人类倾向于仅使用少数样本轻松学习新概念。相比之下，现代深度神经网络需要数千个样本来训练一个可以很好地泛化到看不见的数据的模型。元学习是对这样一个问题的补救措施，即可以使用有限数量的样本来学习新概念。元学习提供了对未见任务的快速适应。
    - 特别是，**与模型无关的元学习 (MAML)** 是最流行的基于优化的元学习框架之一，用于小样本学习。
    - **MAML旨在学习初始化**，以便在对初始化应用少量梯度下降更新后，适应的特定于任务的模型可以在验证数据集上实现所需的性能
    - 问题在于，这个初始化的模型怎么学习？**通常的MAML需要两层循环，导致很多优化上的问题。**例如，由于二阶导数，MAML 会产生很高的计算成本，需要搜索多个超参数，并且对神经网络架构很敏感。进而导致其鞍点和局部最小化器可能过多，其中许多没有良好的泛化性能。
    - 本文就是解决了这么一个问题，利用最近发明的锐度感知最小化，并开发了一种锐度感知的MAML方法，**其收敛速度和泛化界限均有提高。**
    - 这是第一个在双层学习的背景下对锐度感知最小化的实证研究。
    - 这样训练出来的初始化模型很有实际意义，**例如chatgpt-3**
  - [代码](https://github.com/mominabbass/Sharp-MAML)
  - 数据集
    - [CIFAR-10/100](https://www.cs.toronto.edu/~kriz/cifar.html)
  - 一言以蔽之
    - Sharp-MAML 避免了 MAML 损失函数的尖锐局部最小值，实现了更好的泛化性能。
    - 收敛速度和样本复杂度与训练单级ERM模型的复杂度相匹配。
  

---------------------------------------------------
- [Active Sampling for Min-Max Fairness（最小-最大公平性的主动采样）](https://proceedings.mlr.press/v162/abernethy22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Jacob Abernethy（美国佐治亚理工学院）
  - 问题：资源分配的公平性问题，通常采用的模型在训练时忽视了某些代表性不足的群体，而直接降低其他组的权重又是一种“降级”的表现，这可能导致不必要的降低整体表现。
  - 方法：通过主动采样和重加权策略，**选取最差的节点来更新权重**，这种“升级”的方式，如果提高了最差组的性能，也仅仅只会降低一个组的性能。
  - 先修知识：
    - 主动抽样和重加权策略
      - **主动抽样和重加权策略是一种在机器学习中用于处理不平衡数据集的方法。**
      - 在不平衡数据集中，**不同类别的样本数量存在显著差异，这可能会导致模型对数量较少的类别的学习不足**。为了解决这个问题，可以使用主动抽样和重加权策略来平衡不同类别之间的样本数量。
      - **主动抽样是通过随机丢弃一部分数量过多的样本**，来达到类别平衡的目的。这种方法可**能会导致有用的信息丢失**，因为丢弃的样本可能包含一些重要的信息。
      - **重加权策略则是通过为数量较少的类别赋予更高的权重来平衡类别之间的样本数量。**这种方法不会丢失任何信息，因为所有的样本都被使用了，但是需要注意的是，在对数据集进行重加权之后，**模型的评估指标可能需要进行相应的调整，以反映不同类别之间的平衡。**
      - 另外，重加权策略还可以通过使用不同的重加权方法来进一步优化模型性能。例如，可以使用基于样本难度的重加权方法，对数量较少的类别中更具挑战性的样本赋予更高的权重，以帮助模型更好地学习这些样本。
      - 总之，主动抽样和重加权策略是处理不平衡数据集的有效方法，具体使用哪种方法需要根据具体情况进行选择和调整。
    - 最小-最大公平性（min-max fairness）
      - 最小-最大公平性（min-max fairness）是一种公平性准则，**旨在确保不同个体之间的最小福利水平最大化。**在一个多个体的系统中，最小-最大公平性的**目标是通过最小化最劣势群体的损失来实现公平分配。**这个准则的**核心思想是，系统中的最劣势群体应该得到最大的保障，**即使这意味着其他群体需要做出一些妥协或牺牲。
      - 最小-最大公平性常常被应用于资源分配问题，例如公共服务、教育、就业机会和政府福利等领域。在这些领域中，最小-最大公平性的目标是确保最劣势群体的福利最大化，例如贫困人口、少数族裔、残疾人士和其他弱势群体。**在实践中，实现最小-最大公平性可能需要政策制定者进行适当的权衡和资源分配，以确保最劣势群体的权益得到保障，同时避免其他群体的不公平损失。**
  - 这篇文章讲了什么？
    - 在包含多个人口统计组的数据集上训练的模型通常在不同组之间具有不相等的错误率（**例如我在基于白人数据集上调查的个人诉求可能并不适用于黑人**），这要么是因为某些组在训练数据中代表性不足，要么是因为潜在的学习任务对特定组来说本质上更困难。作者说许多现有的公平概念旨在平衡不同人口群体的表现，**这可能导致故意降低较富裕群体的表现，不必要地降低整体表现。**这种表现的退化可能对应于失去获得相关服务的机会，这在法律和道德上被称为“降级”，它受到了大量批评。
    - 相比之下，最小-最大公平概念提供了另一种方法。**这些概念“升级”，**通过采用一个优化的观点，优先将改进模型性能的重点放在性能最差的组上。这种优化如果能提高最差组的性能，也只会降低一个组的性能。
    - 作者方法背后的关键思想是**自适应地对最差群体的数据进行抽样或重新加权**，具体来说，在每个时间步中**使用来自当前模型下最糟糕的组的一个数据点来更新模型**
    - 重要的是，作者表明，对于凸学习问题，这种方法确实可以证明最小化**每组的**最大损失。
    - 作者提供了一个细粒度的分析，证明收敛到最小-最大公平解决方案的速度。
    - 作者提供了三种更新权重的方式，应对不同的场景。
  - 数据集
    - [Drug Consumption（毒品消费预测）](https://www.kaggle.com/code/obeykhadija/drug-consumption-prediction)
    - [COMPAS Recidivism Racial Bias（比较累犯和种族偏见）](https://www.kaggle.com/datasets/danofer/compass)
  - 缺陷
    - 损人利己
    - 种族偏见的执法实践使停车和逮捕率无法很好地替代犯罪活动;招聘数据基于有偏见的历史实践;或者使用现有诊断来训练皮肤癌检测;最小-最大公平以及其他基于错误的公平概念可能会产生模仿数据中存在的偏见的分类器，**如果用于对个人做出实质性决策，可能会使不平等永永化**。



---------------------------------------------------
- [Meaningfully debugging model mistakes using conceptual counterfactual explanations（使用概念反事实解释有意义地调试模型错误）](https://proceedings.mlr.press/v162/abid22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Abubakar Abid（斯坦福大学）
  - 问题：如何理解和解释训练模型所犯的错误？为什么会将斑马分类为狗？了解这一点是非常重要的，可以提高鲁棒性、解决概念漂移和减轻偏差。通常所采用的方式是动查看模型在许多测试样本上的错误并猜测这些错误预测的潜在原因。
  - 方法：本文中提出了一种系统方法，即概念反事实解释 (CCE)，它解释了为什么分类器根据人类可理解的概念在特定测试样本上出错。
  - 文章讲了什么？
    - **本文所说的反事实解释的方式就是添加扰动。**
    - 为什么经过训练的模型会犯特定的错？例如猫被分类成了狗，常规上认为可能是猫在训练分布中的**代表性不足；预训练没做好，偏差**等。
    - **预训练没做好的例子：**病理学家下载了一个预训练模型来对病理图像进行分类。尽管报告的准确性很高，但他发现该模型在他的图像上表现不佳。他调查了为什么会这样，发现他图像中的色调与原始训练数据不同。意识到这个问题，他能够通过一些预处理转换自己的图像，匹配训练分布并提高模型的性能。
    - 但是这在训练和测试之间发生了域转移，这降低了模型的性能。
    - **偏差例子**：皮肤科医生训练一个机器学习分类器，从她的医院患者的皮肤图像中对皮肤疾病进行分类。她与不同医院的同事分享她的训练模型，他们报告说该模型与他自己的患者犯很多错误。她调查了模型出错的原因，意识到她的同事医院的患者有不同的皮肤颜色和年龄。
    - 但是手动降低偏差（例如去除不正确的数据）也会降低模型的性能。
    - 那么要怎样去解释这些错误呢？作者提出了一种反事实概念解释（CCE），**解释上面中的三条来给出正确的解释。**
    - CCE只需要满足下面三个要求：
      - **没有训练数据或重新训练：**CCE 不需要访问训练数据或模型再训练。
      - **只需要模型：**CCE 只需要对模型进行白盒访问。用户可以使用任何数据集来学习所需的概念。
      - **高级解释：**CCE 使用用户易于理解的概念为模型错误提供高级解释。
  - 数据集
    - ISIC dataset
      - ISIC数据集是一个**医学图像数据集**，包含超过23000张皮肤病诊断图像，用于机器学习和计算机视觉应用的训练和评估。这个数据集包括各种类型的皮肤病，例如黑色素瘤、基底细胞癌、鳞状细胞癌等。这个数据集可以用于训练深度学习模型，以帮助医生在早期发现皮肤病，提高诊断准确性。ISIC数据集是开源的，可以在官网上免费下载和使用。
    - Fitzpatrick17k dataset
      - Fitzpatrick17k数据集是一个**肤色分类数据集**，包含17000张人脸图像，用于肤色分类问题的训练和评估。这个数据集基于Fitzpatrick肤色分类系统，将人类肤色分为六个不同的类型。这个数据集可以用于训练机器学习模型，以帮助计算机自动识别人类肤色，例如在人脸识别、美颜软件和虚拟试衣间等应用中。Fitzpatrick17k数据集是开源的，可以在官网上免费下载和使用。
    - NIH dataset
      - NIH数据集是一个医学图像数据集，由美国国立卫生研究院（NIH）提供，包括超过100,000张二维X射线、CT和MRI图像，用于机器学习和计算机视觉应用的训练和评估。这个数据集包括各种疾病和异常，例如肺炎、结核病、肺气肿、肝脏病变等。这个数据集可以用于训练深度学习模型，以帮助医生在早期发现疾病，提高诊断准确性。NIH数据集是开源的，可以在NIH官网上免费下载和使用。需要注意的是，这个数据集包含的是医学图像，访问和使用数据集需要遵守相关的数据使用规定和法律法规。
    - SHREC14LSSTB dateset
      - 这个数据集是一个用于大规模3D物体识别和检索的数据集，包含来自55个类别的1200个3D模型。这些模型由不同的来源生成，包括CAD软件、3D扫描和互联网上的3D模型库。这个数据集的目的是为了帮助开发基于3D形状特征的物体识别和检索算法，并促进在计算机视觉领域的相关研究。SHREC14LSSTB数据集是公开可用的，可以在其官方网站上免费下载和使用。
  - [代码](https://github.com/mertyg/debug-mistakes-cce)


---------------------------------------------------------
- [Learning of Cluster-based Feature Importance for Electronic Health Record Time-series（基于聚类的电子病历时间序列特征重要性学习）](https://proceedings.mlr.press/v162/aguiar22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Henrique Aguiar（英国牛津大学工程科学系）
  - 问题：电子病历的数据是**稀疏的、异构的、多维的和多模态的时间序列**，怎么从中学习模型，进行**病人疾病发展倾向**进行预测。
  - 方法：采用时间序列，注意力机制，聚类的方法，提出了一个无监督的深度学习模型来对 EHR 数据进行聚类
  - 先修知识
    - 电子病历
      - 电子病历是指医疗机构电子化的病历记录，包括患者的诊断、病史、药物治疗和检查结果等信息。这些信息通常**以时间序列的形式进行存储**，因此，**对电子病历数据进行分析和建模可以帮助医生更好地理解疾病的发展和预测患者的病情**。
    - 自组织映射（Self-Organizing Map，SOM）
      - 自组织映射（Self-Organizing Map，SOM）是一种无监督学习的神经网络模型，由芬兰学者 Teuvo Kohonen 在1980年代提出。**SOM 模型可以将高维数据映射到一个低维空间中，同时保留数据间的拓扑结构，即相似的数据在 SOM 映射中也会保持相邻的关系**。SOM 模型的输出层结构呈现出网格状，每个网格被称为节点或神经元，每个节点与输入空间中的向量之间存在一定的拓扑关系。
      - **SOM 模型的训练过程分为两个阶段**。第一阶段是竞争过程，每个输入向量与 SOM 网格中的节点进行竞争，最终每个输入向量都会被映射到最相似的节点上。第二阶段是合作过程，SOM 网格中的节点会相互调整，使得相邻的节点在输入空间中也应该相似，从而形成拓扑结构。SOM 模型的输出层可以用于数据聚类、数据可视化、降维等任务，也可以作为其他机器学习模型的特征提取器。

  - 文章讲了什么？
    - 最近电子健康记录 (EHR) 的可用性允许开发预测患者恶化和轨迹演变风险的算法。然而，使用 EHR 预测疾病进展具有挑战性，**因为这些数据是稀疏的、异构的、多维的和多模态的时间序列。**
    - 例如：首先，EHR 数据包含人口统计或静态变量（例如年龄和性别）和多维时间序列（例如心率、HR 和实验室测量，例如血液测试）的混合。其次，EHR时间序列是多模态的，因为不同的特征是从不同的设备收集的，代表相关性的不同临床属性。类似地，时间序列特征被不同时间采样，并且具有较低的和不同的采样率，以及不同的缺失值属性。此外，每个特征都与不同的噪声和进化模式相关联。
    - 通过引入基于集群的特征时间注意机制来改进通过 EHR 数据对患者结果的预测。我们的方法还利用表型信息来帮助临床可解释性，不仅利用人口和生命体征信息，而且还利用相关的实验室测量（均存在于 EHR 中）来提供更完整的患者生理状态。
    - **作者采用时间序列，注意力机制，聚类的方法，提出了一个有监督的深度学习模型来对 EHR 数据进行聚类，该模型基于识别临床可理解的表型，关于结果预测和患者轨迹。**
  - 一言以蔽之：
    - 在电子病历数据的背景下，**聚类可用于识别在临床特征方面相似的患者组**。然后，这些信息可以用来改进对患者结果的预测。
    - 文中使用的具体聚类算法称为自组织映射(SOM)。SOMS是一种神经网络，可用于表示低维空间中的数据。这使得可视化数据和识别模式变得更容易。
    - 研究表明，SOM模型可以有效地对EHR数据进行聚类。作者还表明，**由SOM确定的集群可以用于改善对患者结果的预测**。
  - 数据集
    - HAVEN dataset
    - MIMIC-IV ED dateset

------------------------------------------------------
- [Minimum Cost Intervention Design for Causal Effect Identification（因果关系识别的最小成本干预设计）](https://proceedings.mlr.press/v162/aguiar22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Sina Akbari（EPFL 技术管理学院）
  - 问题：确定因果关系的成本过高
  - 方法：贪心算法 + 多项式时间启发式算法 或者 对数因子近似算法
  - 先修知识
    - 对数因子近似算法
      - 在计算机科学中，对数因子近似是一种近似算法，它产生的答案在最优解的log(N)因子内，其中n是输入的大小。对数因子近似算法通常用于NP困难的问题，这意味着没有已知的多项式时间算法来寻找最优解。
      - 对数因子近似算法的一个例子是最大覆盖问题的贪婪算法。最大复盖率问题是找到一组元素，尽可能多地覆盖给定的一组项目。贪婪算法的工作原理是将覆盖最多未覆盖项目的元素重复添加到集合中。贪婪算法是一种对数因子近似算法，这意味着它产生一个至少覆盖(1-1/e)项的集合，其中e是自然对数的底。
      - 对数因子近似算法并不总是解决NP-Hard问题的最佳选择。在某些情况下，可能会找到一种更好的近似算法，该算法产生的答案在最优答案的较小因子内。然而，当问题是NP难的并且没有已知的更好的近似算法时，对数因子近似算法通常是一个很好的选择。
      - 以下是对数因子近似算法的一些优势：
        - 它们通常很容易实现。
        - **它们可用于解决NP-Hard问题。**
        - 它们可以在合理的时间内产生良好的近似值。
      - 以下是对数因子近似算法的一些缺点：
        - 它们可能不会产生最佳答案。
        - 它们可能不如其他近似算法那么高效。
      - 总体而言，对数因子近似算法是解决NP-Hard问题的有力工具。它们易于实现，并且可以在合理的时间内产生良好的近似值。然而，它们可能不会产生最优解，并且可能不如其他近似算法那么有效。
    - 最小碰集问题
      - **最小碰集问题（Minimum Hit Set Problem）是一个组合优化问题，通常用于在给定一组集合和一组元素的情况下，找到尽可能小的集合子集，使得这些子集的并集包含所有的元素。**
      - 具体来说，假设有一个包含n个元素的集合U，以及一个包含m个子集的集合S，每个子集都包含U中的一些元素。问题的目标是找到尽可能小的子集T，使得T中的所有子集的并集包含了U中的所有元素。换句话说，T中的子集必须覆盖U中的所有元素，且T的大小应该最小化。
      - 最小碰集问题可以应用于许多实际场景，如测试用例设计、组合优化、数据挖掘、生物信息学等领域。例如，在测试用例设计中，可以将测试用例看作集合中的元素，将测试用例的覆盖情况看作子集的覆盖情况，然后通过解决最小碰集问题来设计最少的测试用例集，以覆盖所有的代码路径或功能。
      - **最小碰集问题是一个NP完全问题**，因此在一般情况下，不存在多项式时间的算法来解决该问题。通常采用启发式算法和近似算法来求解。其中，贪心算法是一种常用的启发式算法，它通过选择覆盖元素最多的子集来逐步构建最小碰集。近似算法则是通过牺牲一定的精度来加速求解，从而在多项式时间内得到一个次优解。
      - 最小碰集问题在实际应用中有着广泛的应用，因此也是组合优化领域的一个重要研究方向。
  - **这篇文章讲了什么内容？**
    - 本文考虑的问题是设计一套干预措施，以最大限度地减少确定因果关系的成本。
    - 作者首先证明了该问题是NP-难的。然后，他们提出了一种算法，可以找到问题的最优解，**或**对其进行对数因子近似。**该算法基于最小成本干预问题和最小碰集问题之间的联系。**
    - 作者还提出了几种多项式时间**启发式算法来解决该问题的计算复杂性**。启发式算法基于最小值的概念。最低限度的对冲是一套足以识别因果关系的干预措施，其规模不可能在不失去识别因果关系的能力的情况下减少。
    - 作者在一个合成数据集上评估了他们的算法的性能。结果表明，该算法能够在合理的时间内找到问题的最优解**或最优解的良好近似值**。
  - 本文对因果推理领域做出了几点贡献。
    - 首先，证明了最小成本干预设计问题是NP难的。这意味着没有多项式时间算法可以找到问题的最优解。
    - 其次，本文提出了一种算法，可以找到问题的最优解，或者说是问题的对数因子近似解。
    - 第三，针对该问题的计算复杂性，提出了几种多项式时间启发式算法。
  - 本文提出的算法可用于识别各种环境中的因果效应，包括医学研究、社会科学研究和商业。
  - **一言以蔽之**：<font color="#dd0000">本文提出了一种方法，首先列出所有可能的干预措施。然后，它使用贪婪算法找到最能改变系统结果的干预措施，同时也是成本最低的。结果表明，该方法能在合理的时间内找到最优解。</font><br />
  - 数据集
    - 合成数据集
      - 该数据集由100个节点和100条边组成。节点表示系统中的变量，边表示变量之间的因果关系。因果关系用半马尔可夫图表示。数据集是使用随机图形生成器生成的。

------------------------------------------------
- [Deploying Convolutional Networks on Untrusted Platforms Using 2D Holographic Reduced Representations（使用2D全息简化表示在不可信平台上部署卷积网络）](https://proceedings.mlr.press/v162/alam22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Mohammad Mahmudul Alam（马里兰大学计算机科学与电气工程系）
  - 问题：如何在不信任的平台上部署CNN？
  - 方法：使用二维全息简化表示法
  - 先修知识
    - 二维全息简化表示法
      - **二维全息简化表示法是一种将卷积神经网络压缩成二维图像的表示方法。**它是通过将卷积神经网络的权重和特征图转换为一种更加简化的形式来实现的。简单来说，这种方法会将卷积神经网络的每个卷积层转换为一个二维图像，其中每个像素值表示该层的一个卷积核或特征图的一个元素。
      - 具体来说，二维全息简化表示法是通过以下步骤实现的：
        - 将卷积神经网络中的每个卷积层的权重和特征图展开成一个一维向量。
        - 将这些一维向量分组，每组包含多个向量，并对每个向量组进行哈希操作，得到一个哈希值。
        - 将这些哈希值组合成一个二维图像，其中每个像素值表示一个哈希值。
      - **通过这种压缩方式，卷积神经网络的大小可以大大减小，从而可以更容易地在资源受限的环境中进行部署和处理。另外，由于哈希函数的性质，这种表示法还具有较强的容错性和安全性，能够抵御一定程度的数据篡改和攻击。**因此，二维全息简化表示法被广泛应用于在不受信任的计算平台上安全地部署卷积神经网络。
  - 这篇文章讲了什么？
    - 随着卷积神经网络 (CNN) 变得越来越流行，因此人们对部署的担忧。
    - 已经采用了许多技巧，如低精度浮点数、权重修剪和经典软件工程和性能调整，以降低这些计算成本。
    - 尽管如此，出于多种原因，**通常需要在第三方计算硬件或云环境中部署模型**（例如，客户的延迟较低、计算资源缺乏以及计算需求弹性）
    - **如果第三方不完全可信，则希望混淆输入和输出的性质，以便第三方不容易确定正在执行哪些特定任务。**
    - 作者探索了一种不同的**快速启发式安全策略**，我们称之为**连接主义符号伪秘密**。通过利用 **全息简化表示 (HRR)**，我们创建了一个具有伪加密风格防御的神经网络，该防御在经验上显示出对攻击的鲁棒性，即使在不现实地支持对手的威胁模型下。
  - 一言以蔽之
    - 本文利用二维全息简化表示法在不受信任的平台上部署卷积神经网络。
    - **这种表示法能够将卷积神经网络的权重和特征图压缩成一个二维图像**，并且具有一定的容错性和安全性。
  - 数据集
    - [MNIST](https://www.kaggle.com/datasets/hojjatk/mnist-dataset)：手写数字的数据集。
    - [CIFAR-10/100](https://www.cs.toronto.edu/~kriz/cifar.html)：自然图像的数据集。
    - [ImageNet](https://www.image-net.org/)：包含100多万张图片的数据集。
    - 除了上面列出的数据集，作者还使用了一个名为“全息简化表示(HRR)数据集”的**合成数据集**。通过使用HRR来表示一组自然图像来生成HRR数据集。作者使用HRR数据集来评估CSP在不是专门为机器学习设计的数据集上的性能。
  - 具体而言
    - 本文提出了一种**在不可信平台上部署卷积神经网络(CNN)的方法**。这种方法被称为**连接主义符号伪秘密(CSP)**，使用一种名为全息简化表示(HRR)的技术来混淆CNN的输入和输出，从而使对手难以推断CNN正在执行的潜在任务。
    - CSPS方法的工作原理是**首先将CNN的输入和输出转换为HRR表示**。HRR表示是一种可用于表示组成结构的分布式表示。具体地，HRR表示可用于表示图像的不同部分之间的关系。
    - 一旦CNN的输入和输出被转换成HRR表示，然后使用密钥对其进行加密。然后，加密的表示被发送到不可信平台。然后，不受信任的平台可以对加密的表示执行推断，但如果没有密钥，它就不能解密它们。
    - 密钥永远不会被发送到不受信任的平台。相反，它存储在受信任的设备上。当不可信平台需要执行推理时，它向可信设备发送请求。然后，可信设备对加密的表示进行解密，并将解密的表示发送回不可信平台。
    - 与在不受信任的平台上部署CNN的其他方法相比，CSPs方法具有几个优点。首先，它非常高效。加密和解密操作非常快，并且它们不会给推理过程增加显著的开销。其次，CSPs方法非常安全。加密的表示在没有密钥的情况下很难解密。第三，CSPs方法非常灵活。它可用于在各种不受信任的平台上部署CNN。
    - CSPS方法已经在各种任务上进行了评估，包括图像分类和目标检测。结果表明，在非可信平台上部署CNN时，CSPs方法可以达到与其他方法相当的精度。
    - CSPs方法是在不可信平台上部署CNN的一种很有前途的新方法。它高效、安全、灵活。CSPS方法是保护敏感数据隐私的宝贵工具。


-----------------------------------------
#### 8. June 6, 2023(week 8)

|Title|Publication|Year|Authors|Area|Problem|Main Method|Datasets|
| :---:| :---:| :---:| :---:|:---:|:---:|:---:|:---:|
|[XAI for Transformers: Better Explanations through Conservative Propagation](https://proceedings.mlr.press/v162/ali22a.html)|ICML|2022|Ameen Ali|Machine Learning|Transformer模型的可解释性，<font color="#dd000">常规的XAI方法无法解决注意力头和 LayerNorm 的问题</font><br />|将XAI方法应用的Transformer模型。具体而言，作者提出一种叫做保守传播（Conservative Propagation，CP）的方法来解释Transformer模型的预测。CP方法基于层级相关传播（Layer-wise Relevance Propagation，LRP）框架。|open source|
|[Neuro-Symbolic Language Modeling with Automaton-augmented Retrieval](https://proceedings.mlr.press/v162/alon22a.html)|ICML|2022|Momin Abbas|Machine Learning|基于检索的语言模型 (R-LM) 通过将标准语言模型 (LM) 与在测试时从外部数据存储中检索的示例相结合来对自然语言文本的概率进行建模。虽然有效，但在实践中使用这些模型的一个主要瓶颈是**计算成本高的数据存储搜索**。|作者提出了 RetoMaton，RetoMaton是一种基于检索的语言模型，使用自动机来近似数据存储的搜索。|open source|
|[Minimax Classification under Concept Drift with Multidimensional Adaptation and Performance Guarantees](https://proceedings.mlr.press/v162/alvarez22a.html)|ICML|2022|Ver ́onica  ́Alvarez|Machine Learning|**传统的分类算法不适用于处理概念漂移**，因为它们通常假设数据的基本分布随时间保持不变。这个假设在现实世界的应用中经常被违反，因为数据的分布可能因环境变化或用户行为变化而改变|在常见的情况下，时间变化是多维的，即不同的统计特征通常会以不同的方式变化。本文提出了自适应极小极大风险分类器（AMRCs），通过对时变基础分布进行多元和高阶跟踪，考虑多维的时间变化|open source|
|[Public Data-Assisted Mirror Descent for Private Model Training](https://proceedings.mlr.press/v162/amid22a.html)|ICML|2022|Ehsan Amid|Machine Learning|当DP-SGD用于训练大型深度学习模型时，与非私有对应模型相比，准确率显著下降。|使用公共数据生成的损失函数作为镜像映射，私有数据上 DP 梯度作为线性项。简而言之，更好的综合私有数据和公共数据，设计了DP变体。**其效果至少要优于原来的DP-SGD**。|open source|
|[Online Algorithms with Multiple Predictions](https://proceedings.mlr.press/v162/anand22a.html)|ICML|2022|Keerti Anand|Machine Learning|在线算法是一种在不了解未来情况下做出决策的算法类型。这使得它们非常适用于环境不断变化的问题，比如股市或交通路由等领域。而传统的在线算法通常使用单个预测来做出决策。然而，在许多情况下，我们可以从不同的来源获取多个预测，比如机器学习模型或人工专家。|该论文研究了如何利用多个预测来提高在线算法的性能。作者们提出了一种名为"多重预测在线算法"（Multiple Prediction Online Algorithm，简称MPOA）的新算法。MPOA算法利用这些预测的组合来做出决策。简言之，**为具有多个预测的在线覆盖问题提供了一个通用的算法框架**|无<font color="#dd000">纯数学理论，无实验</font><br />|
|[Learning to Hash Robustly, Guaranteed](https://proceedings.mlr.press/v162/andoni22a.html)|ICML|2022|Alexandr Andoni|Machine Learning|作者说明了在稳健和保证的前提下学习哈希数据点的问题。他们将稳健性定义为哈希函数处理有噪声或不完整数据的能力，并将保证性定义为哈希函数高效且可扩展的能力。|作者提出了一种新的学习哈希数据点的算法。他们的算法基于学习一组哈希函数，这些函数共同优化以最小化碰撞的风险。作者展示了他们的算法可以使用半监督学习方法高效地学习。|open source|





----------------------------------------------
- [XAI for Transformers: Better Explanations through Conservative Propagation（基于保守传播的Transformer的XAI：通过保守传播实现更好的解释）](https://proceedings.mlr.press/v162/ali22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Ameen Ali（以色列特拉维夫大学计算机科学学院）
  - 问题：Transformer模型的可解释性，<font color="#dd000">常规的XAI方法无法解决注意力头和 LayerNorm 的问题</font><br />
  - 方法：将XAI方法应用的Transformer模型。具体而言，作者提出一种叫做保守传播（Conservative Propagation，CP）的方法来解释Transformer模型的预测。CP方法基于层级相关传播（Layer-wise Relevance Propagation，LRP）框架。
  - 通过论文题目可以了解到什么信息？
    - XAI for Transformers：XAI代表可解释人工智能（Explainable Artificial Intelligence），是一种关注解释模型决策和预测的研究领域。**这篇论文聚焦于在Transformer模型中应用XAI技术**。Transformer是一种广泛应用于自然语言处理和其他序列任务的深度学习模型。论文可能介绍了如何使用XAI方法来提高Transformer模型的解释能力。
    - Better Explanations through Conservative Propagation：这个论文提出了一种名为"Conservative Propagation"的方法，旨在通过这种方法来提供更好的解释能力。具体而言，论文可能探讨如何利用"Conservative Propagation"技术在Transformer模型中生成解释，以提高解释的准确性、一致性和可理解性。
    - Transformer模型和其应用：论文可能会介绍Transformer模型的基本原理和结构，以及它在自然语言处理和其他序列任务中的应用。可能会涉及到Transformer模型的关键概念、自注意力机制、编码器-解码器结构等。
    - 可解释人工智能（XAI）方法：在论文中，可能会涉及到一些XAI方法的原理和应用。这可能包括局部解释方法、全局解释方法、特征重要性分析、模型可视化等。论文可能会探讨如何将这些XAI方法与Transformer模型结合起来，以提供更好的解释能力。
    - 综上所述，通过这个论文题目，可以了解到XAI方法在Transformer模型中的应用，特别是通过"Conservative Propagation"技术提供更好的解释能力。同时，可能会获得关于Transformer模型、XAI方法和可解释人工智能的相关背景知识。然而，具体的内容和深度将需要进一步阅读论文才能确定。
  - 先修知识
    - Transformer
      - Transformer是一种基于注意力机制的深度学习模型，由Vaswani等人在2017年提出，并在自然语言处理（NLP）任务中取得了巨大成功。它在处理序列数据，特别是文本数据的任务上表现出色。
      - **传统的循环神经网络（RNN）在处理长序列时存在梯度消失和梯度爆炸的问题，并且计算效率较低**。Transformer通过引入**自注意力机制**来解决这些问题，并将序列中的所有位置进行**并行计算**。
      - Transformer模型由**编码器（Encoder）和解码器（Decoder）组成，其中编码器负责将输入序列进行编码表示，解码器负责生成输出序列。**编码器和解码器均由多个相同的层（Layer）堆叠而成。
      - 自注意力机制是Transformer的关键组成部分。**它通过计算输入序列中不同位置之间的注意力权重，来建立每个位置与其他位置的依赖关系。**自注意力机制允许模型在编码和解码过程中**动态地**关注输入序列中的不同部分，从而捕捉到更丰富的上下文信息。
      - Transformer模型还引入了**残差连接（Residual Connection）和层归一化（Layer Normalization）**等技术，以促进模型的训练和优化过程。
      - 由于Transformer模型的出色表现和**并行计算能力**，它被广泛应用于机器翻译、文本生成、语言理解、文本分类、问答系统等各种自然语言处理任务，并在这些任务中取得了非常显著的成果。
    - XAI（Explainable Artificial Intelligence，可解释人工智能）
      - XAI（Explainable Artificial Intelligence，可解释人工智能）是一系列方法和技术，旨在使人工智能系统的决策和行为更具解释性和可理解性。XAI的目标是提供对人类用户解释其决策依据的能力，以增强人工智能系统的可信度、透明度和可接受性。
      - 以下是几种常见的XAI方法：
        - 特征重要性分析：这种方法通过分析模型对输入特征的重要性来解释模型的决策。例如，使用特征重要性方法（如基于树的模型中的特征重要性评估或基于梯度的方法），可以确定哪些输入特征对于模型输出的影响最大。
        - 局部可解释性方法：这些方法旨在解释模型对于特定实例的决策。通过观察模型在邻近样本上的行为，可以提供关于模型决策的局部解释。局部可解释性方法包括局部线性近似（LIME）、SHAP（Shapley Additive Explanations）等。
        - 规则提取和决策树：该方法将模型的决策转化为一系列规则或决策树的形式，使其更易理解和解释。这些规则或决策树可以直观地表示模型的决策过程。
        - 可视化方法：可视化方法通过可视化模型的内部状态、决策过程或决策依据，提供对模型行为的直观理解。例如，通过热力图、激活图、注意力图等方式，可视化模型对不同特征的关注程度。
        - 基于原型的解释：这种方法通过寻找代表性的实例或原型，解释模型对这些实例的决策依据。通过展示原型和相似样本之间的关系，可以帮助用户理解模型的决策依据。
      - 需要注意的是，XAI方法并不是单一的方法，而是涵盖了多个技术和方法。选择适合的XAI方法取决于具体的应用场景、模型类型和解释需求。研究人员和开发者们一直在努力推动XAI的发展，并提出了许多新颖的方法来提高解释性能和用户满意度。
    - 层级相关传播（Layer-wise Relevance Propagation，LRP）
      - 层级相关传播（Layer-wise Relevance Propagation，LRP）是一种用于解释深度神经网络（DNN）决策的框架。**它旨在通过将输入的重要性（或相关性）在网络的每一层传播，揭示网络决策的依据。**
      - LRP的**基本思想是将网络的输出反向传播到输入层，将重要性从输出传递回输入，以识别对于网络决策贡献重要性较大的输入特征**。它通过计算每个输入特征的重要性分数，可以帮助我们理解网络对输入的关注和决策过程。
      - 下面是LRP框架的基本步骤：
        - 定义初始重要性：首先，为网络的输出类别设置初始重要性分数。通常情况下，将目标类别设置为1，其他类别设置为0。
        - 反向传播：从输出层开始，将重要性分数从上一层传播到下一层。在传播过程中，根据层间连接权重、激活函数等规则将重要性分数分配给输入特征。
        - 层间重要性分配规则：LRP使用不同的规则来分配重要性分数。常见的规则包括“按比例分配”（Proportional Rule）、“平方比例分配”（Alpha-Beta Rule）和“ε修正”（Epsilon Rule）等。这些规则定义了如何根据连接权重和激活函数来分配重要性分数。
        - 重要性归一化：在传播到输入层之后，对输入的重要性进行归一化处理，以便在输入特征上得到合理的重要性分数。
      - 通过执行上述步骤，LRP框架可以**为每个输入特征计算相对于网络输出的重要性分数**，从而帮助我们理解网络对于决策的关注和贡献。
      - LRP框架在解释深度神经网络决策方面具有一定的优势，但也存在一些挑战和限制。**设计合适的重要性分配规则是一个关键问题**，不同的规则可能会导致不同的解释结果。<font color="#dd000">此外，对于复杂的网络结构和大规模数据集，LRP的计算成本可能很高。</font><br />
      - 需要注意的是，LRP框架是一个活跃的研究领域，有许多变体和改进的技术被提出来进一步增强解释性能。
  - 这篇文章讲了什么内容？
    - 这篇论文是Ameen Ali等人提出的关于使用保守传播（Conservative Propagation，CP）方法来解释Transformer模型预测的新方法。Transformer是一种神经网络，近年来在各种自然语言处理任务中越来越受欢迎。**但是，Transformer的预测结果往往难以解释，这会影响人们对其预测结果的信任度**。
    - <font color="#dd000">CP方法基于层级相关传播（Layer-wise Relevance Propagation，LRP）框架</font><br />。**LRP是一种将神经网络输出的相关得分向其输入特征传播的方法**。CP将LRP方法扩展到了Transformer模型上，并考虑了Transformer的注意力机制和归一化层等特殊属性。
    - **作者在情感分析和问答等多种自然语言处理任务上评估了CP的性能，并发现CP能够产生比其他方法更准确和更有信息量的解释。即使Transformer的预测结果不正确，CP仍然能够更可靠地解释其预测结果。**
    - 作者得出结论，CP是一种有前途的解释Transformer模型预测的方法。CP可以提高Transformer模型的透明度和可信度，使其在实际应用中更广泛地被采用。
    - 这篇论文的一些关键发现包括：
      - CP是比其他方法更准确和更有信息量的解释Transformer模型预测的方法。
      - CP能够更可靠地解释Transformer模型的预测结果，即使这些预测结果是不正确的。
      - CP可以提高Transformer模型的透明度和可信度。
  - 数据集
    - [Stanford Sentiment Treebank v2 (SST2)Stanford Sentiment Treebank v2 (SST2)](https://www.kaggle.com/datasets/atulanandjha/stanford-sentiment-treebank-v2-sst2)：一个情感分析数据集，包含电影评论，标记为正面或负面情感。具体而言，SST-2数据集包含570,000个训练样本和11,000个测试样本。训练样本是标记为正面或负面情感的电影评论。测试样本用于评估模型性能。
    - [IMDB](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)：具有 50K 电影评论的 IMDB 数据集，用于自然语言处理或文本分析。这是一个用于二元情感分类的数据集，包含比以前的基准数据集多得多的数据。 25,000 条高度极端的电影评论用于训练，25,000 条用于测试。因此，使用分类或深度学习算法预测正面和负面评论的数量。
    - [tweet_eval](https://huggingface.co/datasets/tweet_eval)：对情绪 (59,899)、仇恨检测 (12,970) 和情绪识别 (5,052) 进行推文分类
    - T-Emotions
    - T-Hate
    - T-Sentiment
    - Meld-S
    - Semaine
  - graph Transformers 数据集
    - [silicone](https://huggingface.co/datasets/silicone)：情感检测任务和话语情感分析
    - MNIST
    - [BACE](https://paperswithcode.com/dataset/bace-scaffold)：包含 1,522 种化合物，以及它们的结构和二进制标签，表明一组人类 β-分泌酶 1 (BACE-1) 抑制剂的结合结果
  
  - 一言以蔽之：通常而言，关于Transformers的可解释性的方法都是基于梯度信息。作者认为 Transformer 中的梯度仅在局部反映函数，因此无法可靠地识别输入特征对预测的贡献，主要原因在于Attention Heads 和 LayerNorm 。故而提出一种新的叫做保守传播（Conservative Propagation，CP）的方法来解释Transformer模型预测。哪怕预测的错误的，也能给出合理的解释，<font color="#dd000">具体做法是，定性定量的做实验中，也就是对输入做不同的扰动</font><br />

---------------------------------------------------

- [Neuro-Symbolic Language Modeling with Automaton-augmented Retrieval（使用自动机增强检索的神经符号语言建模）](https://proceedings.mlr.press/v162/alon22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Uri Alon（卡内基梅隆大学的语言技术研究所）
  - 问题：基于检索的语言模型 (R-LM) 通过将标准语言模型 (LM) 与在测试时从外部数据存储中检索的示例相结合来对自然语言文本的概率进行建模。虽然有效，但在实践中使用这些模型的一个主要瓶颈是**计算成本高的数据存储搜索**。
  - 方法：作者提出了 RetoMaton，RetoMaton是一种基于检索的语言模型，使用自动机来近似数据存储的搜索。
  - 从论文标题中可以得到的信息
    - Neuro-Symbolic Language Modeling：这个短语表明，论文介绍了一种将**神经网络和符号自动机结合起来的新的语言建模方法**。神经网络是一种机器学习算法，可以学习表示数据之间复杂关系的模型。**符号自动机是一种数学对象，可以用来表示语言的结构**。
    - Automaton-augmented Retrieval：这个短语表明，论文介绍了一种使用符号自动机来**提高检索准确性和效率的语言建模方法**。检索是从大量文档或数据中找到相关内容的过程。符号自动机可以用来表示语言的结构，从而提高检索的准确性和效率。
    - 总的来说，这篇论文的标题表明，该论文介绍了一种将神经网络和符号自动机结合起来的新的语言建模方法，以提高语言建模的准确性和效率。
  - 先修知识
    - R-LM
      - R-LM是一种基于检索的语言模型，全称为Retrieval-based Language Model，它通过查询一个候选答案集合来生成文本。R-LM通常使用符号自动机来表示文本结构，并使用自动机来指导检索过程，从而提高检索效率。R-LM的优点是可以通过检索来生成答案，避免了生成式语言模型中的搜索问题，同时还可以利用自动机表示文本结构，从而提高模型的效率和准确性。
    - LM
      - LM是一种生成式语言模型，全称为Language Model，它是一种用于生成自然语言文本的模型。LM通常基于神经网络（如循环神经网络或Transformer）来学习语言的概率分布，以便在给定先前的文本序列的情况下，生成下一个单词的概率分布。LM的优点是可以生成非常灵活和多样的语言，因为它是基于生成式的方法，不受预定义答案集合的限制。
    - 总之，R-LM和LM都是用于处理自然语言言的模型，**但R-LM更注重检索和利用自动机表示文本结构，而LM更注重生成自然语言文本的灵活性和多样性。**
    - 困惑度（Perplexity
      - 困惑度（Perplexity）是一种衡量语言模型预测能力的指标，它是对一个给定序列的**预测概率的倒数，即倒数对数似然。困惑度越低，表示模型的预测能力越好**，因为它对于给定的测试数据集中的未知序列，能够给出更准确的预测概率。通常情况下，一个好的语言模型的困惑度应该在一个较小的范围内，比如在自然语言处理领域，一个好的语言模型的困惑度应该在20左右，更低的困惑度表示模型预测能力更好。
  - 这篇论文讲了什么？
    - 该论文提出了一种将神经网络和符号自动机相结合的新的语言建模方法。论文作者认为，他们的方法能够通过利用神经网络和符号自动机各自的优势来提高语言建模的准确性和效率。
    - **神经网络**是一种机器学习算法，可以学习表示复杂数据之间关系的模型。**符号自动机**是一种数学对象，可以用来表示语言的结构。论文作者提出了一种利用符号自动机来提高检索准确性和效率的语言建模方法。
    - 该论文提出的**方法**由两个主要组成部分构成：**神经语言模型（NNLM）和符号自动机**。神经语言模型用于生成序列中下一个记号的概率分布，符号自动机用于指导搜索序列中下一个记号。神经语言模型在大型文本数据集上进行训练，符号自动机是从训练数据中构建的。在推理时，神经语言模型用于生成序列中下一个记号的概率分布，然后使用符号自动机来指导搜索序列中下一个记号。选择具有最高概率的记号。
    - 作者在多项任务中对他们的方法进行了评估，包括语言建模、问答和自然语言推理。他们展示了他们的方法能够在所有任务中提高语言建模的准确性和效率。
    - 综上所述，该论文提出了一种新的语言建模方法，将神经网络和符号自动机相结合，并通过实验验证了该方法的有效性。
  - 数据集
    - [Wikitext-103](https://paperswithcode.com/dataset/wikitext-103)：Wikitext-103是一个包含1.03亿个单词的数据集，从维基百科和其他来源提取而来。它是一个平衡的数据集，包含各种领域的文本。
    - Law-MT：Law-MT是一个包含150万个单词的数据集，由其他语言翻译成英语的法律文件组成。该数据集不平衡，包含一些语言的文档比其他语言更多。
    - 作者使用这些数据集来训练和评估他们提出的**模型RetoMaton**。RetoMaton是一种基于检索的语言模型，使用自动机来近似数据存储的搜索。
    - 论文作者选择使用这些数据集，**因为它们都是大型和多样化的**。他们想要在各种数据上测试他们的模型，以确保它能够很好地推广到新的任务中。
  - 总结
    - 基于检索的语言模型 (R-LM) 应用在无条件语言建模、机器翻译、问答和代码生成等领域。改进了很多的神经网络。
    - 在这些模型中，检索组件首先搜索外部数据存储中的最近邻示例；然后，基本模型在预测期间引用这些示例。
    - 这是一种语言模型 (LM) 和检索相融合的角度
    - **k-最近邻语言模型这种基于检索的模型的一个突出例子是kNN-LM** ，它通过线性插值基LM的输出和非参数最近邻分布来预测令牌。该分布是通过搜索数据存储中的k近邻(kNN)来构造的，并根据它们与当前测试上下文的距离对它们进行加权。值得注意的是，对每个生成的测试标记执行这种 k 最近邻搜索，**引入了严重的推理开销**，因为该搜索明显慢于 LM 的标准“前向传递”。
    - 作者的方法：RETOMATON。也就是说，**在当前时间步骤检索到的邻居也提示了将来时间步骤将要检索的邻居，因此可以节省后续的重复搜索**。具体来说，我们使用完全无监督的方式，在现有数据存储之上构建了一个带权有限自动机（WFA），通过在数据存储条目之间保持指针并将相似条目进行聚类。**这个自动机允许间歇性、不频繁的kNN搜索**，并在其他时间步骤上以更低成本的遍历方式遍历自动机。
  - 实验效果
    - 在Wikitext-103上应用RetoMaton，直接使用原始训练姐，可以节省81%的kNN搜索次数，而不会影响困惑度，或者可以将困惑度降低1.85而不进行任何额外的训练
    - 在一个经过微调的LM之上构建RetoMaton时，可以将困惑度降低超过17%。

-----------------------------------------------------------------------

- [Minimax Classification under Concept Drift with Multidimensional Adaptation and Performance Guarantees（具有多维度适应和性能保证的概念漂移下的极小极大分类）](https://proceedings.mlr.press/v162/alvarez22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Ver ́onica  ́Alvarez（西班牙毕尔巴鄂（Bilbao）的一个研究机构）
  - 问题：**传统的分类算法不适用于处理概念漂移**，因为它们通常假设数据的基本分布随时间保持不变。这个假设在现实世界的应用中经常被违反，因为数据的分布可能因环境变化或用户行为变化而改变
  - 方法：在常见的情况下，时间变化是多维的，即不同的统计特征通常会以不同的方式变化。本文提出了自适应极小极大风险分类器（AMRCs），通过对时变基础分布进行多元和高阶跟踪，考虑多维的时间变化
  - 从论文标题中可以了解到的信息
    - 该论文是关于开发一种新的分类算法，可以在**数据的基本分布随时间变化（概念漂移）**的情况下进行自适应，并提供性能保证。论文的作者声称他们的算法称为自适应极小极大风险分类器（AMRCs），可以通过跟踪时间变化的基本分布的多个统计特征来实现这一目标。
    - Minimax（极小极大）：这指的是一种决策问题类型，目标是**最小化最坏情况下的错误概率**。在分类的上下文中，这意味着目标是开发一种算法，即使数据的基本分布随时间变化，也能正确分类大多数实例。
    - Concept drift（概念漂移）：这指的是数据的基本分布随时间变化的现象。这可能由于环境变化或用户行为变化等各种原因而发生。
    - Multidimensional adaptation（多维度适应）：这指的是算法能够适应基本分布的多个统计特征的能力。在分类的上下文中，这意味着算法应该能够适应数据的均值、方差和其他统计特性的变化。
    - Performance Guarantees（性能保证）：这是对算法错误概率的数学界限。在分类的上下文中，这意味着论文的作者声称他们的算法即使在数据的基本分布随时间变化的情况下也能达到一定的准确性水平。
  - 这篇文章讲了什么内容？
    - 本文介绍了一种名为**自适应极小极大风险分类器（AMRCs）**的新的分类算法，该算法可以适应数据的基本分布随时间变化（概念漂移），同时提供性能保证。
    - 论文的作者认为传统的分类算法不适用于处理概念漂移，因为它们通常假设数据的基本分布随时间保持不变。这个假设在现实世界的应用中经常被违反，因为数据的分布可能因环境变化或用户行为变化而改变。
    - AMRCs通过**跟踪时间变化的基本分布的多个统计特征来解决这个问题**。这使得AMRCs比传统的分类算法更有效地适应数据分布的变化。
    - 除了能够适应概念漂移外，AMRCs还能提供性能保证。这意味着论文的作者可以在数学上证明，即使数据的基本分布随时间变化，AMRCs也能达到一定的准确性水平。
    - 论文的作者在多个基准数据集上评估了AMRCs，并表明它们在准确性和对概念漂移的鲁棒性方面优于传统的分类算法。
    - 以下是论文的一些关键要点：
      - AMRCs是一种新的分类算法，可以适应概念漂移，并提供性能保证。
      - AMRCs跟踪时间变化的基本分布的多个统计特征。
      - AMRCs在准确性和对概念漂移的鲁棒性方面优于传统的分类算法。
      - AMRCs有潜力改进各种现实世界应用中的分类算法的准确性和鲁棒性。
  - 数据集
    - 12个开源 数据集

--------------------------------------------------------------

- [Public Data-Assisted Mirror Descent for Private Model Training（借助公共数据的镜像下降算法进行私有模型训练）](https://proceedings.mlr.press/v162/amid22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Ehsan Amid（MIT，Google实习）
  - 问题：当DP-SGD用于训练大型深度学习模型时，与非私有对应模型相比，准确率显著下降。
  - 方法：使用公共数据生成的损失函数作为镜像映射，私有数据上 DP 梯度作为线性项。简而言之，更好的综合私有数据和公共数据，设计了DP变体。**其效果至少要优于原来的DP-SGD**。
  - 从论文标题中可以了解到的信息
    - 该论文介绍了使用公共数据来改进差分隐私（DP）训练的机器学习模型的隐私和效用。
    - 作者提出了一种名为Public Data-Assisted Mirror Descent（PDA-DPMD）的新算法，利用公共数据训练既具有隐私又准确的模型。
    - 下面是标题中每个术语的更详细解释：
      - Public data 公共数据：公共数据是不敏感的数据，可以在不损害个人隐私的情况下共享。例如，公共数据可以包括政府网站、科学数据库或社交媒体平台的数据。
      - Mirror Descent 镜像下降：Mirror Descent是一种优化算法，可用于训练机器学习模型。Mirror Descent通过迭代地朝向损失函数的最小值移动，同时尽量保持接近起始点。
      - Differential privacy 差分隐私：差分隐私是一种保护数据集中个人隐私的技术。**差分隐私通过向数据中添加噪声来保护隐私，以至于无法确定特定个体的数据是否包含在数据集中。**
      - Private model training 私有模型训练：私有模型训练是在保护用于训练模型的数据隐私的同时进行的机器学习模型训练过程。
  - 先修知识
    - 镜像下降（Mirror Descent）
      - 镜像下降（Mirror Descent）是一种优化算法，**用于解决凸优化问题。它是对经典梯度下降算法的一种变体，它不直接在参数空间中迭代更新，而是在对偶空间中进行迭代。**
      - 在镜像下降算法中，我们考虑到凸优化问题的目标函数和约束条件的对偶形式。对偶问题中的每个约束条件都对应一个对偶变量，这些对偶变量以某种方式与原始问题的参数相关联。算法的主要思想是使用对偶变量来表示参数空间中的更新方向，并根据此更新方向迭代地更新参数。
      - 在每个迭代步骤中，镜像下降算法首先计算目标函数的梯度，然后计算对偶变量的梯度。通过将这两个梯度结合起来，算法确定了参数空间中的更新方向。然后，算法根据步长参数来更新参数，并确保更新后的参数在凸集中。这个步骤称为投影操作，用于维持参数的合法性。
      - 相比传统的梯度下降算法，镜像下降算法具有一些优势。首先，镜像下降算法可以应用于凸优化问题的对偶形式，这使得算法更适用于某些特定的优化任务。其次，镜像下降算法对约束的处理更加灵活，可以处理一些非凸约束问题。此外，镜像下降算法还可以适应非欧几里德空间中的优化问题，如流形上的优化。
      - 总而言之，镜像下降算法是一种基于对偶空间的优化算法，通过结合目标函数和约束条件的梯度来更新参数。它在一些特定的优化问题和约束条件下具有优势，并且可以适应非欧几里德空间的情况。
  - 这篇论文讲了什么内容？
    - 《Public Data-Assisted Mirror Descent for Private Model Training》是Amid等人于2022年发表的一篇论文，提出了一种新的算法来训练差分隐私（DP）模型。该算法称为PDA-DPMD（Public Data-Assisted Differentially Private Mirror Descent），利用**公共数据和私有数据的组合**来训练既具有隐私性又准确的模型。
    - 论文的作者认为，利用公共数据可以改善DP模型训练中的隐私/效用权衡。他们展示了对于从非各向同性亚高斯分布中绘制的特征向量的线性回归，当公共数据样本数量足够大时，他们的算法PDA-DPMD提供的总体风险保证比DP下已知的最佳保证渐近地更好（没有访问公共数据）。
    - 论文作者还展示了他们的算法具有自然的“噪声稳定性”属性，可以控制由于为确保DP而添加的噪声引起的方差。他们通过展示四个基准数据集（StackOverflow，WikiText-2，CIFAR-10和EMNIST）上的隐私/效用权衡来展示他们算法的有效性。他们表明，他们的算法不仅显著改进了传统的DP-SGD（没有访问公共数据），而且据他们所知，是首个在已经用公共数据进行预训练的模型上改进DP-SGD的算法。
    - 总之，论文作者提出了一种新的算法，利用公共数据和私有数据的组合来训练既具有隐私性又准确的模型。作者还为其算法提供了理论保证，并在多个基准数据集上展示了其有效性。
  - 数据集
    - Stack Overflow：一个编程问题和答案的数据集。
    - WikiText-2：来自维基百科文章的文本数据集。
    - CIFAR-10：一个物体图像数据集。
    - EMNIST：一个手写数字数据集。

-----------------------------------------------------------------
- [Online Algorithms with Multiple Predictions（具有多个预测的在线算法）](https://proceedings.mlr.press/v162/anand22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Keerti Anand（美国北卡罗来纳州杜克大学的计算机科学系）
  - 问题：在线算法是一种在不了解未来情况下做出决策的算法类型。这使得它们非常适用于环境不断变化的问题，比如股市或交通路由等领域。而传统的在线算法通常使用单个预测来做出决策。然而，在许多情况下，我们可以从不同的来源获取多个预测，比如机器学习模型或人工专家。
  - 方法：该论文研究了如何利用多个预测来提高在线算法的性能。作者们提出了一种名为"多重预测在线算法"（Multiple Prediction Online Algorithm，简称MPOA）的新算法。MPOA算法利用这些预测的组合来做出决策。简言之，**为具有多个预测的在线覆盖问题提供了一个通用的算法框架**
  - 从论文标题中可以了解到的信息
    - 该论文研究了一种可以利用多个预测来做出更好决策的在线算法。
  - 先修知识
    - 多个预测 (Multiple Predictions)。
      - **多个预测（Multiple Predictions）是指从不同的来源或方法中获得的多个预测结果**。在研究论文中，多个预测可以来自不同的机器学习模型、不同的数据源，或者是由不同的专家提供的预测。通过使用多个预测，可以获得多个视角和信息来源的综合，从而提高决策的准确性和可靠性。这种方法可以在在线算法中使用，使算法能够更好地适应不断变化的环境和数据。通过整合多个预测，可以更好地预测未来情况，并做出更好的决策。
    - 在线集合覆盖（Online Set Cover）
      - 在线集合覆盖（Online Set Cover）是一种经典的优化问题，涉及到在动态的情况下，从一个集合系统中选择一些集合，以覆盖所有的元素，同时尽量减少所选集合的数量。该问题通常用于描述实际应用中的资源分配、任务调度、广告投放等场景。<font color="#dd000">类似于最小碰集</font><br />
      - 在在线集合覆盖问题中，集合系统一开始是未知的，集合逐渐以逐个元素的方式揭示。在每个时刻，算法必须决定是否选择某个新揭示的集合以覆盖尚未覆盖的元素。算法的目标是在尽可能早地覆盖所有元素的同时，选择尽量少的集合。
      - 具体来说，在线集合覆盖问题可以定义如下：
        - 输入：一组元素（即全集），以及一系列集合的序列，每个集合包含一些元素。
        - 输出：选择一些集合，以覆盖所有的元素。
        - 目标：尽可能减少所选集合的数量。
        - 算法在每个时刻都要根据当前已知的信息进行决策，通常使用贪心策略来选择下一个集合。一种常见的贪心算法是选择能够覆盖最多尚未被覆盖元素的集合。这种策略被称为最大覆盖（Maximum Coverage）。其他变体的贪心策略也可以用于解决在线集合覆盖问题。
      - 在线集合覆盖是一个具有挑战性的问题，**因为算法必须在只知道部分信息的情况下做出决策，并且需要在有限的时间内找到一个近似最优解。**研究人员一直致力于设计有效的在线算法，并对问题的性质和界限进行深入研究，以提供更好的解决方案。
  - 这篇论文讲了什么内容？
    - 本文讨论了一种适用于具有多重预测的在线覆盖问题的通用算法框架。该框架能够获得一个在线解，<font color="#dd000">其竞争力能够与从预测中获得的最佳解的性能相媲美</font><br />。该算法结合了对在线算法的经典基于潜力的分析中预测的使用。
    - 作者将他们的算法框架应用于解决经典问题，如在线集合覆盖、（加权）缓存和多重预测设置中的在线设施定位。他们的算法还可以进行健壮性处理，即算法可以同时具有与最佳预测和最佳在线算法（无预测）性能相竞争的特性。
    - 以下是论文的一些关键要点：
      - 具有多重预测的在线算法是一个新兴的研究领域。
      - 作者的算法框架是解决具有多重预测的在线覆盖问题的一种通用方法。
      - 该框架能够与从预测中获得的最佳解的性能相竞争。
      - 该框架可以应用于解决经典问题，如在线集合覆盖、（加权）缓存和在线设施定位。
      - 该框架还可以进行健壮性处理，即算法可以同时具有与最佳预测和最佳在线算法（无预测）性能相竞争的特性。
    - 作者的算法框架是一种通用方法，适用于各种问题。该框架能够与从预测中获得的最佳解的性能相竞争，并且还可以进行健壮性处理。这使得该框架成为解决各种设置中的在线问题的一种有前景的工具。
  - 数据集
    - <font color="#dd000">纯数学理论，无实验</font><br />

  - 注释
    - 竞争力能够与从预测中获得的最佳解的性能相媲美
      - 这句话的意思是说，论文中提出的算法框架在解决在线覆盖问题时能够达到与从预测中获得的最佳解相当的竞争力。
      - 在问题求解过程中，通过使用预测模型或者其他方法，我们可以获得对问题的预测或估计。这些预测可能是关于未来事件、系统状态或者其他相关信息的。论文中的算法框架利用这些预测来指导在线覆盖问题的解决过程。
      - **竞争力是衡量算法性能的指标**，它表示算法的解与最佳解之间的性能比较。这句话中所指的竞争力就是指论文中的算法框架能够在在线覆盖问题中达到与从预测中获得的最佳解相当的性能水平。换句话说，算法的解决方案与预测中的最佳解相比，具有接近甚至相等的效果。
      - 这句话强调了论文中算法框架的竞争力，即其能够在实践中取得良好的效果，与使用预测所获得的最佳解相当甚至更好。这表明论文中的算法框架在解决在线覆盖问题时具有实用性和可行性。

--------------------------------------------------------------
- [Learning to Hash Robustly, Guaranteed（学习哈希：鲁棒性保证）](https://proceedings.mlr.press/v162/andoni22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Alexandr Andoni（加州大学圣地亚哥分校计算机科学与工程系）
  - 问题：作者说明了在稳健和保证的前提下学习哈希数据点的问题。他们将稳健性定义为哈希函数处理有噪声或不完整数据的能力，并将保证性定义为哈希函数高效且可扩展的能力。
  - 方法：作者提出了一种新的学习哈希数据点的算法。他们的算法基于学习一组哈希函数，这些函数共同优化以最小化碰撞的风险。作者展示了他们的算法可以使用半监督学习方法高效地学习。
  - 从论文标题中可以了解到的信息
    - Learning to hash 学习哈希：该论文涉及学习如何对数据点进行哈希。哈希是一种将数据点转换为较小表示的技术，然后可以用于各种任务，如搜索、聚类和降维。
    - Robustly 稳健性：该论文侧重于以稳健的方式学习哈希数据点。稳健性意味着哈希函数应能处理有噪声或不完整数据。
    - Guaranteed 保证性：该论文还承诺生成的哈希函数将是高效且可扩展的。高效性意味着哈希函数应能够快速为大量数据点生成哈希。可扩展性意味着哈希函数能够处理大型数据集，而不会变得过于缓慢或昂贵。
  - 先修知识
    - 学习哈希（Learning to Hash）
      - 学习哈希（Learning to Hash）指的是通过机器学习的方法，将原始数据映射为二进制码（hash code），以便于高效地存储、检索和处理数据。**学习哈希的目标是将原始数据的相似性在哈希码空间中保持**，即相似的数据在哈希码空间中距离较近，不相似的数据在哈希码空间中距离较远。**通过学习哈希，可以在保证数据隐私和安全的前提下，加速大规模数据的相似性搜索、聚类、分类等任务**。学习哈希有许多应用，例如图像检索、文本检索、视频检索等领域。
  - 这篇文章讲了什么内容？
    - 本文讨论了一种既稳健又保证的学习哈希数据点的新方法。作者提出了一种新的算法，可以学习哈希数据点，**以最小化碰撞的风险，并确保生成的哈希函数高效且可扩展**。作者对多种数据集进行了算法评估，并表明它在准确性和速度方面优于现有方法。
  - 数据集
    - MNIST：MNIST数据集是一个手写数字数据集。它包含了70,000张训练图像和10,000张测试图像。
    - ImageNet：ImageNet数据集是一个图像数据集。它包含了1.2百万张训练图像和50,000张验证图像。


---------------------------------------------
#### 9. July 11, 2023(week 9)

|Title|Publication|Year|Authors|Area|Problem|Main Method|Datasets|
| :---:| :---:| :---:| :---:|:---:|:---:|:---:|:---:|
|[Set Based Stochastic Subsampling](https://proceedings.mlr.press/v162/andreis22a.html)|ICML|2022|Bruno Andreis|Machine Learning|常规的随机子采样方法将数据维度降低，甚至将多通道的图像先变成单通道，之后变成向量，损失了太多的信息，对结果造成太大的影响|**第一个阶段：摒弃一部分样本，构成候选集（粗粒度）；第二个阶段：通过条件概率和自注意力机制考虑候选集中的样本的相对重要性，从候选集中选择较小的子集（细粒度）**|open source|
|[Towards Understanding Sharpness-Aware Minimization](https://proceedings.mlr.press/v162/andriushchenko22a.html)|ICML|2022|Maksym Andriushchenko|Machine Learning|SAM为何有效？|隐式偏差|open source|
|[fair and fast k-center clustering for data summarization](https://proceedings.mlr.press/v162/angelidakis22a.html)|ICML|2022|Haris Angelidakis|Machine Learning|聚类算法中的两个关键性问题：（1）“人口群体”的不公平代表性；（2）失真的数据概括|K-Center（过于繁琐，没有细看）|open source|
|[Interactive Correlation Clustering with Existential Cluster Constraints](https://proceedings.mlr.press/v162/angell22a.html)|ICML|2022|Rico Angell|Machine Learning|||open source|
|[Image-to-Image Regression with Distribution-Free Uncertainty Quantification and Applications in Imaging](https://proceedings.mlr.press/v162/angelopoulos22a.html)|ICML|2022|Anastasios N Angelopoulos|Machine Learning|图像到图像回归 (Image-to-Image Regression) 不提供任何统计信息，也就是新的发现未必可靠|本文开发了一种方法，以赋予任何图像到图像回归模型具有像素的不确定性区间。在特定像素，不确定性区间是保证以高概率包含该像素的真实值的一系列值。|open source|
|[AdaGrad Avoids Saddle Points](https://proceedings.mlr.press/v162/antonakopoulos22a.html)|ICML|2022|Kimon Antonakopoulos|Machine Learning|优化中的鞍点问题|AdaGrad可以自动避免|open source|
|[UnderGrad: A Universal Black-Box Optimization Method with Almost Dimension-Free Convergence Rate Guarantees](https://proceedings.mlr.press/v162/antonakopoulos22b.html)|ICML|2022|**Kimon Antonakopoulos**|Machine Learning|**维度过高的时候，很多优化算法不收敛，或者收敛速度没有保证**|**设计一种通用性很高的无维度限制的，且收敛速度有保证的黑盒优化算法**|open source|


--------------------------------------------------------------
- [Set Based Stochastic Subsampling（基于集合的随机子采样方法）](https://proceedings.mlr.press/v162/andreis22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Bruno Andreis（韩国科学技术院（KAIST）人工智能研究生院（Graduate School of AI）
  - 问题：常规的随机子采样方法将数据维度降低，甚至将多通道的图像先变成单通道，之后变成向量，损失了太多的信息，对结果造成太大的影响
  - 方法：**第一个阶段：摒弃一部分样本，构成候选集（粗粒度）；第二个阶段：通过条件概率和自注意力机制考虑候选集中的样本的相对重要性，从候选集中选择较小的子集（细粒度）**
  - 从论文标题中可以了解到的信息
    - 主题：论文的主题是 "Set Based Stochastic Subsampling"，意味着该论文将探讨一种**基于集合的随机子采样方法**。
    - 方法：论文将介绍一种用于随机子采样的方法，该方法可能是基于集合的。这种方法可能是一种统计学或机器学习中的采样技术，**用于从一个集合中随机选择子集**。
    - 概率性：标题中的 "Stochastic" 表示这种子采样方法是随机的，即在选择子集时可能具有一定的概率性。
    - 集合：标题中的 "Set Based" 暗示该子采样方法可能与**集合操作和特征选择**相关。这可能意味着论文讨论的是从给定集合中选择子集的方法，或者在集合上执行随机采样的相关技术。
  - 先修知识
    - 随机子采样是一种**从给定数据集或总体中随机选择子集的采样方法**。在统计学和机器学习中，随机子采样常用于以下情况：
      - **数据集降维**：当数据集非常庞大时，为了减少计算和存储的负担，可以使用随机子采样来选择一个较小的代表性子集，以代替整个数据集进行分析和建模。
      - **模型训练**：在训练机器学习模型时，如果数据集非常庞大，可能会导致训练时间过长或内存不足的问题。在这种情况下，可以使用随机子采样从数据集中选择一个随机样本子集，用于模型的训练和调优。
      - **蒙特卡洛模拟**：在蒙特卡洛模拟中，随机子采样可用于从总体中选择一部分样本，以近似估计总体的某些属性或概率分布。
    - 随机子采样的关键特点是**随机性**，即每个样本都有被选择的概率，并且**每次采样都是独立进行的**。通过随机性，我们可以期望采样的子集能够代表整个数据集或总体的特征，从而进行有效的分析、建模或估计。
  - 这篇文章讲了什么内容？
    - 这篇文章提出了一个两阶段的端到端神经子采样模型，与任意下游任务网络进行联合优化。该论文的结构如下：
      - 引言：论文首先介绍了基于集合的随机子采样问题。他们认为现有的集合子采样方法要么效率低下，要么不能捕捉集合中元素之间的复杂交互。
      - 方法：接着，论文介绍了他们提出的方法。该方法包括两个阶段：
        - 第一阶段**使用条件独立的伯努利随机变量**，通过使用集合编码函数捕捉粗粒度全局信息，高效地对候选元素进行子采样。
        - 第二阶段使用**条件依赖**的分类随机变量，**利用集合注意力网络对候选集合进行自回归子采样，以建模成对的相互作用**。
      - 实验：接着，论文在多个任务上对他们的方法进行了评估，包括图像分类、图像重构、函数重构和少样本分类。他们表明，在低子采样率下，他们的方法优于相关的基准方法。此外，他们还表明，他们的方法可用于提高非参数模型（如神经过程）的可扩展性。
    - 这篇论文写作精细，实验结果有说服力。所提出的方法是一种有前景的基于集合的随机子采样方法，可以用于改善各种机器学习任务的性能。
    - 以下是论文的一些主要贡献：
      - 论文提出了一个两阶段的端到端神经子采样模型，**与任意下游任务网络进行联合优化**。
      - 论文表明，在**低子采样率下**，他们的方法优于相关的基准方法。
      - 论文表明，他们的方法可用于提高**非参数模型（如神经过程）**的可扩展性。
  - 数据集

 
--------------------------------------------------
- [Towards Understanding Sharpness-Aware Minimization（对于锐度感知最小化的理解）](https://proceedings.mlr.press/v162/andriushchenko22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Maksym Andriushchenko（洛桑联邦理工）
  - 问题：SAM为何有效？
  - 方法：隐式偏差
  - 从论文标题中可以了解到的信息
    - 主题：论文的主题是 "Sharpness-Aware Minimization"，意味着该论文旨在**研究和理解与最小化损失函数的尖锐度有关的方法**。
    - 方法：论文将介绍一种名为 "Sharpness-Aware Minimization" 的方法。这种方法可能是一种优化算法或技术，**用于在训练神经网络或优化模型时考虑尖锐度的影响**。
    - 尖锐度：标题中的 "Sharpness" 暗示该论文将关注尖锐度的概念。在机器学习中，**尖锐度通常指的是损失函数的曲率或梯度的属性**。这可能与模型的收敛性、泛化能力或优化过程中的问题有关。
    - 探索：标题中的 "Towards Understanding" 表明该论文将探索和理解尖锐度感知最小化的方法。这表明该论文可能会提供对现有优化算法的改进或对尖锐度概念的新见解。
  - 先修知识
    - Sharpness-Aware Minimization（SAM）是一种训练方法，它通过**同时最小化损失值和损失锐度**来提高模型的泛化能力。SAM通过寻找在具有均匀低损失值的邻域中的参数（而不是仅具有低损失值的参数）来实现。
    - Sharpness-Aware是指在训练过程中，SAM会尝试在最小化损失值的同时，最小化损失函数的锐度，以此来提高模型的泛化能力。
  - 这篇文章讲了什么内容？
    - 这篇文章研究了用于训练深度神经网络的**尖锐度感知最小化（Sharpness-Aware Minimization，SAM）**方法。SAM是一种近期的训练方法，已被证明在各种任务上改善了泛化性能。**该论文旨在通过对其内在偏差进行理论分析，更好地理解SAM方法成功的原因**。
    - 论文首先回顾了SAM方法。**SAM通过最小化模型预测的最坏尖锐度来工作。尖锐度是衡量模型对权重的微小扰动有多敏感的指标**。通过最小化尖锐度，SAM鼓励模型学习更具鲁棒性的预测结果，**从而减少过拟合训练数据的可能性**。
    - 接下来，论文提出了对SAM的内在偏差进行理论分析的结果。作者证明了对于某类问题，SAM总是选择一个具有比标准梯度下降更好的泛化特性的解决方案。使用SAM中的m-尖锐度可以放大这种效果，而m-尖锐度已被证明对泛化性能至关重要。
    - 论文还提供了支持理论发现的实证结果。作者展示了用SAM对标准模型进行微调可以显著提高泛化性能。他们还展示了SAM在噪声标签设置下的有效性，即标签受到噪声污染。
    - 以下是论文的一些**主要贡献**：
      - 论文对SAM的内在偏差提供了理论洞见。
      - 论文表明SAM可以显著提高泛化性能。
      - 论文表明SAM在噪声标签设置下是有效的。
  - 数据集


--------------------------------------------------
- [Fair and Fast k-Center Clustering for Data Summarization（公平快速的数据概括k中心聚类）](https://proceedings.mlr.press/v162/andriushchenko22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Haris Angelidakis（苏黎世联邦理工数学系）
  - 问题：聚类算法中的两个关键性问题：（1）“人口群体”的不公平代表性；（2）失真的数据概括
  - 方法：K-Center（过于繁琐，没有细看）
  - 从论文标题中可以了解到的信息
    - 主题：该论文的主题是关于数据概括的聚类方法，旨在实现公平和快速的聚类算法。
    - 公平性：论文关注解决聚类算法在数据概括中可能出现的公平性问题，特别是避免对不同人群的数据选择造成不公平的情况。
    - 快速性：除了公平性，论文还关注聚类算法的效率，追求快速的运行时间。
    - **k-Center聚类**：论文所介绍的算法基于k-Center聚类问题，**这是一种常见的聚类方法，通过选择k个中心点将数据划分成不同的簇**。
    - **数据概括**：该论文的研究目标是数据概括，**即从原始数据中生成代表性的概括或摘要**，以便更有效地分析和处理数据。
  - 这篇文章讲了什么内容？
    - 本文针对许多聚类方法在数据概括时面临的两个关键问题进行了探讨：
      - **不公平的代表性**：当聚类算法在选择数据点时不成比例地选取某一人群而忽略其他人群时，就会出现这种情况。
      - **失真的概括**：当聚类算法产生代表原始数据相差巨大的子集概括时，就会出现这种情况。
    - 作者提出了一种新的聚类算法，同时解决了这两个问题。他们的算法**基于k中心聚类问题，但引入了公平约束，以确保所选中心在不同人群之间均匀分布**。该算法还被设计为高效，其运行时间与数据集大小和k呈线性关系。
    - 作者在多种合成和真实数据集上评估了他们的算法。结果显示，该算法能够产生公平且代表性强的概括，并且具有高效性。
    - 以下是该论文的一些主要贡献：
      - 作者提出了一种新的聚类算法，解决了数据概括中的公平性和代表性问题。
      - 该算法高效，其运行时间与数据集大小和k呈线性关系。
      - 作者在多种合成和真实数据集上评估了算法，结果表明该算法能够产生公平且代表性强的概括。
  - 一言以蔽之
    - 给定一个大型数据集，**文档摘要的目标是提取代表整个数据集的一小部分样本**。对较小的数据集进行进一步分析要容易得多。当用较小的子集表示大型数据集面临的一个关键挑战是**正确处理公平考虑**。作者专注于获得底层数据的公平表示的两个中心方面，即：
      - **敏感属性正确地反映在摘要中**
      - **摘要中的不同数据点不应该代表不同大小的原始数据的子集**，从而导致摘要失真
  - 数据集

--------------------------------------------------
- [Interactive Correlation Clustering with Existential Cluster Constraints（具有存在性簇约束的交互式相关聚类）](https://proceedings.mlr.press/v162/angell22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Rico Angell（马萨诸塞大学阿默斯特分校（University of Massachusetts Amherst）的信息与计算机科学学院（Manning College of Information and Computer Sciences））
  - 问题：
  - 方法：
  - 从论文标题中可以了解到的信息
    - 主题：该论文的主题是关于交互式相关聚类的研究，特别是在存在性簇约束下的情况。
    - 相关聚类：论文关注的是相关聚类，这是一种聚类方法，旨在将具有相似属性或关系的数据点划分为相同的簇。
    - 存在性簇约束：论文中介绍了存在性簇约束，这可能是一种特定的限制或要求，要求某些簇在聚类中存在或被排除。
    - 交互式：论文所提出的方法是交互式的，可能涉及用户与算法之间的迭代交互，以逐步调整聚类结果。
    - 总之，根据论文题目，可以了解到该论文研究了一种交互式相关聚类方法，特别考虑了存在性簇约束。这种方法可能允许用户通过与算法的交互来调整聚类结果，并满足特定的簇约束要求。
  - 这篇文章讲了什么内容？
    - 本文提出了一种新的交互式聚类方法，允许用户以**存在性簇约束**的形式提供反馈。**这些约束指定了包含特定特征子集的簇的存在或不存在**。
    - 作者认为，与成对点约束相比，存在性簇约束更高效，因为它们可以更简洁地表达用户意图。他们还认为，存在性簇约束更自然，**用户可以不需要了解原始数据。**
    - 作者提出了一种适用于存在性簇约束的聚类算法。该算法首先通过解决聚类问题的半定规划（SDP）松弛问题来获得解。然后，利用SDP松弛的解构造一个DAG形状的分层聚类。最后，利用动态规划算法从分层聚类中提取最优平面聚类。
    - 作者在多种合成和真实数据集上评估了他们的算法。结果显示，相比先前的方法，**该算法能够在较少的用户交互下产生高质量的聚类。**
    - 以下是该论文的一些主要贡献：
      - 作者提出了一种使用存在性簇约束的交互式聚类方法。
      - 作者展示了存在性簇约束相比成对点约束更高效的优势。
      - 作者提出了一种适用于存在性簇约束的聚类算法。
      - 作者在多个数据集上评估了算法，并展示了在较少用户交互下能够产生高质量聚类的能力。
    - 使用存在性簇约束进行交互式聚类有以下一些优点：
      - 可以更简洁地表达用户的偏好。
      - 更符合用户的自然表达方式。
      - 可以在较少用户交互的情况下产生高质量的聚类。


--------------------------------------------------
- [Image-to-Image Regression with Distribution-Free Uncertainty Quantification and Applications in Imaging（基于无分布不确定性量化的图像到图像回归及在成像中的应用）](https://proceedings.mlr.press/v162/angelopoulos22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Anastasios N Angelopoulos（加州大学伯克利分校（University of California, Berkeley）的电气工程与计算机科学系（Department of Electrical Engineering and Computer Science））
  - 问题：图像到图像回归 (Image-to-Image Regression) 不提供任何统计信息，也就是新的发现未必可靠
  - 方法：本文开发了一种方法，以赋予任何图像到图像回归模型具有像素的不确定性区间。在特定像素，不确定性区间是保证以高概率包含该像素的真实值的一系列值。
  - 从论文标题中可以了解到的信息
    - 主题：该论文的主题是关于图像到图像回归的研究，特别是在成像领域中应用无分布不确定性量化的方法。
    - 图像到图像回归：论文关注的是从输入图像到输出图像的回归问题，即通过学习输入图像与目标输出图像之间的映射关系来预测输出图像。
    - 无分布不确定性量化：论文中提出了一种无需假设数据分布的不确定性量化方法。这种方法用于评估模型在图像到图像回归任务中的预测不确定性，提供关于预测结果的置信度度量。
    - 成像应用：论文介绍了在成像领域中应用图像到图像回归的方法和无分布不确定性量化的方法。这可能涉及诸如图像重建、图像增强或图像合成等任务。
    - 总之，通过论文题目，我们可以了解到该论文研究了一种基于无分布不确定性量化的图像到图像回归方法，并探索了其在成像领域中的应用。这种方法可以用于预测图像输出并提供与预测结果相关的不确定性度量。
  - 先修知识
    - 图像到图像回归 (Image-to-Image Regression) 
      - 图像到图像回归 (Image-to-Image Regression) 是一种机器学习任务，**旨在将输入图像转换为输出图像**。与图像分类不同，图像到图像回归的目标不是将图像分为不同的类别，**而是生成与输入图像相关的另一幅图像**。
      - **图像到图像回归任务通常涉及到将输入图像进行某种形式的变换或转换**，例如图像去噪、图像修复、图像增强、图像风格转换、图像超分辨率等。这些任务可以被广泛应用于计算机视觉领域，如图像处理、医学影像分析、自动驾驶、机器人视觉等。
      - 为了解决图像到图像回归任务，通常使用深度学习模型，如卷积神经网络 (CNN)、生成对抗网络 (GAN)、变分自编码器 (VAE) 等。这些模型可以从大量的训练数据中学习输入和输出之间的映射，并用于生成新的输出图像。
  - 这篇文章讲了什么内容？
    - 这篇文章提出了一种提供不确定性量化的图像到图像回归的新方法。作者提出了一种方法，可以为任何图像到图像回归模型赋予每像素的不确定性区间。在特定像素处，不确定性区间是一个范围，高概率保证包含该像素的真实值。
    - **作者的方法是无分布的，这意味着它不对数据的分布做任何假设**。这使得他们的方法更通用，适用于更广泛的问题。
    - 作者在多种成像任务上评估了他们的方法，包括MRI重建、光流估计和深度估计。结果显示，他们的方法能够提供准确的不确定性量化，可以用于提高图像到图像回归模型的稳健性。
    - 以下是该论文的一些主要贡献：
      - 作者提出了一种提供不确定性量化的图像到图像回归的新方法。
      - 作者的方法是无分布的，这使得它更通用，适用于更广泛的问题。
      - 作者在多种成像任务上评估了他们的方法，结果表明它能够提供准确的不确定性量化。
    - 在图像到图像回归中使用不确定性量化的一些好处包括：
      - 可以提高模型对噪声和异常值的稳健性。
      - 可以用于识别模型在图像中信心较低的区域。
      - 可以生成更有信息量的错误消息。
  - 数据集

--------------------------------------------------
- [AdaGrad Avoids Saddle Points（AdaGrad优化算法自动避免鞍点）](https://proceedings.mlr.press/v162/antonakopoulos22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Kimon Antonakopoulos（洛桑联邦理工）
  - 问题：优化中的鞍点问题
  - 方法：AdaGrad可以自动避免
  - 从论文标题中可以了解到的信息
    - 论文研究的是优化算法AdaGrad在避免梯度下降过程中出现鞍点问题（saddle points）方面的表现。
    - AdaGrad是一种常见的优化算法，用于在深度学习中更新神经网络参数。
    - **鞍点问题是深度学习中常见的问题之一，当神经网络的损失函数存在多个局部极小值和局部最大值时，梯度下降算法可能会被卡在鞍点处，导致训练不收敛或收敛很慢**。
    - 论文内容可能涉及到AdaGrad算法的工作原理、鞍点问题的本质，以及如何使用AdaGrad算法避免鞍点问题等方面的内容。
  - 这篇文章讲了什么内容？
    - 这篇文章研究了针对非凸优化问题的AdaGrad算法的收敛性质。
    - **论文的主要贡献在于展示了AdaGrad算法几乎可以从任何初始条件避免鞍点**。这是一个重要的结果，因为鞍点是非凸优化中常见的问题，可能会导致算法无法收敛到全局最小值。
    - 论文的主要技术如下：
      - 他们证明了AdaGrad的自适应步长矩阵Γt会收敛到对称正定矩阵。
      - 他们利用这一点展示了梯度范数平方和是有限的。
      - 然后，他们使用稳定流形技术展示了AdaGrad的诱导轨迹几乎可以从任何初始条件避免鞍点。
      - 论文的结果是有前途的，因为它们表明AdaGrad算法比以前认为的更可靠用于非凸优化。然而，论文也有一些限制。例如，它只考虑了具有标量预处理的AdaGrad算法。有趣的是，看看结果是否推广到其他类型的AdaGrad算法，例如带有对角线或完全矩阵预处理的AdaGrad。
    - 以下是论文的几个关键要点：
      - AdaGrad几乎可以从任何初始条件避免鞍点。
      - 鞍点是非凸优化中常见的问题。
      - AdaGrad的步长矩阵收敛到对称正定矩阵。
      - 梯度范数平方和是有限的。
      - 可以使用稳定流形技术展示AdaGrad的诱导轨迹避免鞍点。
    - 总的来说，论文 "AdaGrad Avoids Saddle Points" 对于非凸优化领域是一项有价值的贡献。**它提供了理论证据，表明AdaGrad是一种可靠的算法，可以避免鞍点，这在非凸优化中可能是一个重大问题**。
  - 数据集

--------------------------------------------------
- [UnderGrad: A Universal Black-Box Optimization Method with Almost Dimension-Free Convergence Rate Guarantees（UnderGrad：一种具有几乎无维度收敛率保证的通用黑盒优化方法）](https://proceedings.mlr.press/v162/antonakopoulos22b.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Kimon Antonakopoulos（洛桑联邦理工）
  - 问题：**维度过高的时候，很多优化算法不收敛，或者收敛速度没有保证**
  - 方法：**设计一种通用性很高的无维度限制的，且收敛速度有保证的黑盒优化算法**
  - 从论文标题中可以了解到的信息
    - 论文介绍了一个名为 "UnderGrad" 的优化方法。
    - 这个方法是一种通用的黑盒优化方法，可以用于解决各种类型的优化问题。
    - 这个方法具有“几乎无维度”的收敛速度保证，这意味着它可以在高维空间中表现得很好，而不会受到“维度灾难”的影响。
    - 文章的主要贡献在于提出了这个方法，并证明了其在理论上的优越性能。
  - 这篇文章讲了什么内容？
    - 这篇文章研究了一种名为 UnderGrad 的新型通用梯度方法的收敛性质。UnderGrad 旨在在高维设置下高效且可扩展，并实现几乎无维度的收敛速度保证。
    - 论文的主要贡献在于展示 UnderGrad 在具有完美梯度预测器的 Lipschitz 平滑问题中实现了 $O(1/T^{2/3})$ 的收敛速率，并在具有随机梯度预测器的问题中实现了 $O(1/T^{1/3})$ 的收敛速率。这些速率几乎无维度，这意味着它们不依赖于问题的维度 d。
    - 论文的主要技术如下：
      - 他们为 UnderGrad 开发了一个原始-对偶更新方案，受变分不等式的对偶探索方法的启发。
      - 他们展示了 UnderGrad 收敛到优化问题的 KKT 点。
      - 他们使用了一个集中不等式来限制梯度估计中的误差。
      - 然后，他们利用这些结果推导了收敛速率保证。
    - 论文的结果是有前途的，因为它们表明 UnderGrad 比以前认为的更高效、可扩展，并具有几乎无维度的收敛速度保证。然而，这篇论文也有一些限制。例如，它只考虑了问题的目标函数是凸函数的情况。有趣的是，看看这些结果是否推广到非凸问题。
    - 以下是论文的几个关键要点：
      - UnderGrad 是一种新的通用梯度方法，实现了几乎无维度的收敛速度保证。
      - UnderGrad 旨在在高维设置下高效且可扩展。
      - UnderGrad 收敛到优化问题的 KKT 点。
      - 在具有完美梯度预测器的 Lipschitz 平滑问题中，UnderGrad 的收敛速率为 $O(1/T^{2/3})$，在具有随机梯度预测器的问题中为 $O(1/T^{1/3})$。
  - 数据集


---------------------------------------

#### Neural Network未读
[Robust Training of Neural Networks Using Scale Invariant Architectures](https://proceedings.mlr.press/v162/li22b.html)
[Finding Global Homophily in Graph Neural Networks When Meeting Heterophily](https://proceedings.mlr.press/v162/li22ad.html)
[Constrained Gradient Descent: A Powerful and Principled Evasion Attack Against Neural Networks](https://proceedings.mlr.press/v162/lin22e.html)
[Deep Neural Network Fusion via Graph Matching with Applications to Model Ensemble and Federated Learning](https://proceedings.mlr.press/v162/liu22k.html)
[Local Augmentation for Graph Neural Networks](https://proceedings.mlr.press/v162/liu22s.html)
[Feature Learning and Signal Propagation in Deep Neural Networks](https://proceedings.mlr.press/v162/lou22a.html)
[Interpretable Neural Networks with Frank-Wolfe: Sparse Relevance Maps and Relevance Orderings](https://proceedings.mlr.press/v162/macdonald22a.html)
[Architecture Agnostic Federated Learning for Neural Networks](https://proceedings.mlr.press/v162/makhija22a.html)
[A Dynamical System Perspective for Lipschitz Neural Networks](https://proceedings.mlr.press/v162/meunier22a.html)
[Modeling Structure with Undirected Neural Networks](https://proceedings.mlr.press/v162/mihaylova22a.html)
[Wide Neural Networks Forget Less Catastrophically](https://proceedings.mlr.press/v162/mirzadeh22a.html)
[Bounding the Width of Neural Networks via Coupled Initialization A Worst Case Analysis](https://proceedings.mlr.press/v162/munteanu22a.html)
[AutoSNN: Towards Energy-Efficient Spiking Neural Networks](https://proceedings.mlr.press/v162/na22a.html)
[Implicit Bias of the Step Size in Linear Diagonal Neural Networks](https://proceedings.mlr.press/v162/nacson22a.html)
[Measuring Representational Robustness of Neural Networks Through Shared Invariances](https://proceedings.mlr.press/v162/nanda22a.html)
[Fast Aquatic Swimmer Optimization with Differentiable Projective Dynamics and Neural Network Hydrodynamic Models](https://proceedings.mlr.press/v162/nava22a.html)
[Variational Inference for Infinitely Deep Neural Networks](https://proceedings.mlr.press/v162/nazaret22a.html)
[A Unified Weight Initialization Paradigm for Tensorial Convolutional Neural Networks](https://proceedings.mlr.press/v162/pan22b.html)
[A Theoretical Comparison of Graph Neural Network Extensions](https://proceedings.mlr.press/v162/papp22a.html)
[POET: Training Neural Networks on Tiny Devices with Integrated Rematerialization and Paging](https://proceedings.mlr.press/v162/patil22b.html)
[Neural Network Pruning Denoises the Features and Makes Local Connectivity Emerge in Visual Tasks](https://proceedings.mlr.press/v162/pellegrini22a.html)
[A Differential Entropy Estimator for Training Neural Networks](https://proceedings.mlr.press/v162/pichler22a.html)
[Implicit Regularization in Hierarchical Tensor Factorization and Deep Convolutional Neural Networks](https://proceedings.mlr.press/v162/razin22a.html)
[Structure Preserving Neural Networks: A Case Study in the Entropy Closure of the Boltzmann Equation](https://proceedings.mlr.press/v162/schotthofer22a.html)
[DNS: Determinantal Point Process Based Neural Network Sampler for Ensemble Reinforcement Learning](https://proceedings.mlr.press/v162/sheikh22a.html)
[Coin Flipping Neural Networks](https://proceedings.mlr.press/v162/sieradzki22a.html)
[Rethinking Graph Neural Networks for Anomaly Detection](https://proceedings.mlr.press/v162/tang22b.html)
[Tackling covariate shift with node-based Bayesian neural networks](https://proceedings.mlr.press/v162/trinh22a.html)
[What Can Linear Interpolation of Neural Network Loss Landscapes Tell Us?](https://proceedings.mlr.press/v162/vlaar22a.html)
[Multirate Training of Neural Networks](https://proceedings.mlr.press/v162/vlaar22b.html)
[DRAGONN: Distributed Randomized Approximate Gradients of Neural Networks](https://proceedings.mlr.press/v162/wang22aj.html)
[How Powerful are Spectral Graph Neural Networks](https://proceedings.mlr.press/v162/wang22am.html)
[Mitigating Neural Network Overconfidence with Logit Normalization](https://proceedings.mlr.press/v162/wei22d.html)
[Characterizing and Overcoming the Greedy Nature of Learning in Multi-modal Deep Neural Networks](https://proceedings.mlr.press/v162/wu22d.html)
[DAVINZ: Data Valuation using Deep Neural Networks at Initialization](https://proceedings.mlr.press/v162/wu22j.html)
[Injecting Logical Constraints into Neural Networks via Straight-Through Estimators](https://proceedings.mlr.press/v162/yang22h.html)
[Locally Sparse Neural Networks for Tabular Biomedical Data](https://proceedings.mlr.press/v162/yang22i.html)
[Informed Learning by Wide Neural Networks: Convergence, Generalization and Sampling Complexity](https://proceedings.mlr.press/v162/yang22l.html)
[A New Perspective on the Effects of Spectrum in Graph Neural Networks](https://proceedings.mlr.press/v162/yang22n.html)
[Estimating Instance-dependent Bayes-label Transition Matrix using a Deep Neural Network](https://proceedings.mlr.press/v162/yang22p.html)
[Feature Space Particle Inference for Neural Network Ensembles](https://proceedings.mlr.press/v162/yashima22a.html)
[ShiftAddNAS: Hardware-Inspired Search for More Accurate and Efficient Neural Networks](https://proceedings.mlr.press/v162/you22a.html)
[Molecular Representation Learning via Heterogeneous Motif Graph Neural Networks](https://proceedings.mlr.press/v162/yu22a.html)
[The Combinatorial Brain Surgeon: Pruning Weights That Cancel One Another in Neural Networks](https://proceedings.mlr.press/v162/yu22f.html)
[Neural Network Weights Do Not Converge to Stationary Points: An Invariant Measure Perspective](https://proceedings.mlr.press/v162/zhang22q.html)
[Learning Efficient and Robust Ordinary Differential Equations via Invertible Neural Networks](https://proceedings.mlr.press/v162/zhi22a.html)


#### 待看
[Batched Dueling Bandits](https://proceedings.mlr.press/v162/agarwal22a.html)

#### 不会

|[Bregman Neural Networks](https://proceedings.mlr.press/v162/frecon22a.html)|ICML|2022|Jordan Frecon|Machine Learning|TODO|TODO|TODO|

- [Bregman Neural Networks](https://proceedings.mlr.press/v162/frecon22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Jordan Frecon (Normandie Univ 诺曼底大学)
  - 问题：
  - 方法：
  - 从论文题目**Bregman Neural Networks**可以了解到什么信息？
    - 论文探讨了一种基于Bregman距离的神经网络模型。
  - 先修知识
    - 什么是Bregman距离？
      - Bregman距离是一种基于Bregman散度（Bregman Divergence）的距离度量方法，它是由以色列数学家Simeon Reich在2009年引入的。
      - 在数学中，Bregman距离是一种非对称的距离度量，它衡量的是一个向量与另一个向量之间的距离，但不满足对称性，即Bregman距离(A,B)≠Bregman距离(B,A)。Bregman距离的计算方法是通过一个Bregman散度函数来计算的，这个函数通常具有凸性和微分性质。
      - 在机器学习中，Bregman距离通常用于矩阵分解、聚类、降维等任务中，也可以作为正则化项用于最优化问题中，例如LASSO和稀疏编码。此外，Bregman距离还被用于设计新的距离学习算法和度量学习方法。
  - 文章内容
  - 数据集



表示学习的双层优化：本文提出了一个框架来学习从原始输入到线性可分特征的表示映射以进行预测。 该框架基于双层优化，其中低层问题通过最小化逐层目标找到表示，而上层问题优化目标的参数。

Bregman 神经网络：论文表明，通过在分层目标中选择不同的距离和正则化器，该框架可以恢复标准的前馈神经网络或产生新的 Bregman 神经网络。

- 这篇文章讲了什么？
这篇文章介绍了一种基于双层优化的框架，用于学习多层深度数据表示。文章提出了一种新的神经网络架构，称为Bregman神经网络，它使用Bregman距离来定义激活函数的逆。作者通过数值实验表明，Bregman变体具有更好的学习性能和更强的预测性能。文章还介绍了一些相关工作，如元学习和超参数优化等。文章中提到的方法可以用于各种应用，如医学成像、自动驾驶等。文章中提到的方法可以用于各种应用，如医学成像、自动驾驶等。

- 这篇文章解决了什么问题？采用的什么方法？
这篇文章是关于Bregman神经网络的。作者提出了一种基于双层优化的框架，用于学习多层深度数据表示。文章中提到，通过选择保真度项作为两个连续层之间的二次距离，双层问题可以简化为前馈神经网络的训练。文章还介绍了一种新型神经网络结构——Bregman前馈层，它还涉及激活函数的逆，类似于ResNets中使用的跳跃连接。数值实验表明，所提出的Bregman变体具有更好的学习性能和更强的预测性能。

文章中提出的框架可以用于学习多层深度数据表示，其中下层问题通过逐步最小化由预定正则化器、保真度项和依赖于前一层找到的表示的线性函数组成的逐层目标来找到表示。上层问题则通过优化线性函数来产生线性可分离的最终表示。

这篇文章是关于Bregman神经网络的。作者提出了一个基于双层优化的框架，用于学习多层深度数据表示。文章中，作者提出了一种新的神经网络架构，称为Bregman前馈层，它还涉及激活函数的逆。这种设置提供了神经网络的新视角，允许我们将激活算子解释为Bregman投影，而不是Bregman近似算子。在第5节中，作者在合成和真实数据集上评估了这种新类型层的实际效果，并扩展了多层感知器和残差网络。文章中提出的框架可以通过选择保真度项作为两个连续层之间的二次距离来简化为前馈神经网络的训练。文章中还介绍了一种新型的神经网络架构，称为Bregman前馈层，它还涉及激活函数的逆。这种设置提供了神经网络的新视角，允许我们将激活算子解释为Bregman投影，而不是Bregman近似算子。文章中还介绍了一种新型的神经网络架构，称为Bregman前馈层，它还涉及激活函数的逆。这种设置提供了神经网络的新视角，允许我们将激活算子解释为Bregman投影，而不是Bregman近似算子。

----------------------------------------
|[Convergence of Policy Gradient for Entropy Regularized MDPs with Neural Network Approximation in the Mean-Field Regime](https://proceedings.mlr.press/v162/leahy22a.html)|ICML|2022|Bekzhan Kerimkulov|Machine Learning|||open source|


- [Convergence of Policy Gradient for Entropy Regularized MDPs with Neural Network Approximation in the Mean-Field Regime（平均场Regime中神经网络逼近熵正则化MDP策略梯度的收敛性）](https://proceedings.mlr.press/v162/leahy22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Bekzhan Kerimkulov（爱丁堡大学数学学院）
  - 问题：
  - 方法：
  - 从这个论文的题目可以得到以下信息：
    - 该论文的主题是关于强化学习（reinforcement learning）的，研究的内容是关于策略梯度（policy gradient）的收敛性（convergence）问题，涉及熵正则化的马尔可夫决策过程（entropy regularized Markov decision processes）和神经网络的逼近（neural network approximation）。
    - 在强化学习中，策略梯度是一种常用的策略优化方法。熵正则化的马尔可夫决策过程是一种在强化学习中广泛使用的模型，它可以通过引入熵正则化项来促进策略的探索性行为。
    - 该论文可能会介绍一种新的方法，该方法可以证明在神经网络逼近下，熵正则化的马尔可夫决策过程中的策略梯度方法具有收敛性，并且在一些特定的情况下具有优越的性能。这种方法可能会涉及到策略梯度、马尔可夫决策过程、熵正则化和神经网络逼近等方面的知识。
    - 该论文可能会对强化学习中策略梯度方法的理论进行探讨，并提出了一些新的思路和方法，以提高强化学习算法的收敛性和性能。

  - 先修知识
  - 这篇文章讲了什么？
    - 这篇文章是关于无限时域、连续状态和动作空间以及熵正则化马尔可夫决策过程（MDPs）的策略梯度全局收敛性的研究。作者考虑了一个softmax策略，其中包含一个（单隐藏层）神经网络逼近，处于均场极限状态下。

  - 这篇文章的创新点是什么？
    - 这篇文章的创新点是研究了无限时域、连续状态和动作空间以及熵正则化马尔可夫决策过程（MDPs）的策略梯度全局收敛性。作者考虑了一个softmax策略，其中包含一个（单隐藏层）神经网络逼近，处于均场极限状态下。
    - 这篇文章的创新点是研究了策略梯度全局收敛性，这是一个重要的问题，因为它可以帮助我们理解强化学习算法的收敛性质。

  - 这篇文章解决了什么问题？采用的什么方法？
    - 这篇文章的方法是研究了无限时域、连续状态和动作空间以及熵正则化马尔可夫决策过程（MDPs）的策略梯度全局收敛性。作者考虑了一个softmax策略，其中包含一个（单隐藏层）神经网络逼近，处于均场极限状态下。
    - 这篇文章解决的问题是策略梯度全局收敛性，这是一个重要的问题，因为它可以帮助我们理解强化学习算法的收敛性质。




------------------------------------
|[On the Convergence of the Shapley Value in Parametric Bayesian Learning Games](https://proceedings.mlr.press/v162/agussurja22a.html)|ICML|2022|Lucas Agussurja|Machine Learning|||open source|

- [On the Convergence of the Shapley Value in Parametric Bayesian Learning Games（关于参数贝叶斯学习对策中Shapley值的收敛）](https://proceedings.mlr.press/v162/agussurja22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Lucas Agussurja（英国牛津大学工程科学系）
  - 问题：
  - 方法：

  - 贝叶斯学习博弈是指一种博弈论模型，其中每个玩家都有一个概率分布，表示他对其他玩家策略的信念。在这个模型中，玩家的目标是通过博弈过程来更新自己的信念，并最终选择最优的策略。
  - Shapley值是一种用于评估博弈中参与者贡献的方法，它可以用来刻画每个参与者对于博弈结果的影响。在这篇论文中，作者研究了在贝叶斯学习博弈中，Shapley值的收敛性问题。具体来说，作者考虑了一个参数化的贝叶斯学习博弈模型，其中每个玩家的策略由一个参数向量表示。作者证明了在这个模型中，如果每个玩家的策略空间是紧致的（即有限且闭合），并且玩家的信念是连续的，那么Shapley值是收敛的，并且收敛到一个唯一的极限值。
  - 该论文的主要贡献在于研究了在参数化的贝叶斯学习博弈中Shapley值的收敛性问题，并给出了收敛性的证明。这个结果对于理解博弈论中Shapley值的性质和应用具有重要的意义，可以帮助更好地评估参与者的贡献，并优化博弈的结果。
  - 总的来说，"On the Convergence of the Shapley Value in Parametric Bayesian Learning Games"这篇论文主要探讨了在贝叶斯学习博弈中Shapley值的收敛性问题，提供了一些有用的结论和证明，对于博弈论中Shapley值的理解和应用具有重要的意义。












|[Hierarchical Shrinkage: Improving the accuracy and interpretability of tree-based models](https://proceedings.mlr.press/v162/agarwal22b.html)|ICML|2022|Abhineet Agarwal|Machine Learning|||open source|

- [Hierarchical Shrinkage: Improving the accuracy and interpretability of tree-based models（分层收缩：提高基于树的模型的准确性和可解释性）](https://proceedings.mlr.press/v162/agarwal22b.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Abhineet Agarwal（加州大学伯克利分校统计系）
  - 问题：
  - 方法：
  - 文章讲了什么？



----------------------------------------------
--------------------------------------------
- [Optimistic Linear Support and Successor Features as a Basis for Optimal Policy Transfer（作为最优策略转移基础的乐观线性支持和后续特征）](https://proceedings.mlr.press/v162/alegre22a.html)
  - 文章发布在ICML
  - 时间为2022年
  - 作者：Lucas N. Alegre（巴西里约格兰德杜若斯州波尔图阿莱格里的联邦大学信息学院）
  - 问题：
  - 方法：
  - 这篇文章主要讲了什么内容？
    - 这篇文章提出了一种新的算法，可以在多个任务之间进行最优策略转移。这个算法叫做Optimistic Linear Support (OLS)。OLS算法通过学习不同的线性偏好来构建一个CCS（Cone of Credible Sets），并且可以在这个集合中找到至少一个对应的最优策略。
  - 这篇文章的创新点是什么？
    - 这篇文章的创新点是提出了一种新的算法，可以在多个任务之间进行最优策略转移。这个算法叫做Optimistic Linear Support (OLS)。OLS算法通过学习不同的线性偏好来构建一个CCS（Cone of Credible Sets），并且可以在这个集合中找到至少一个对应的最优策略。
  - 这篇文章解决了什么问题？采用的什么方法？
     - 这篇文章解决的问题是如何在多个任务之间进行最优策略转移。文章提出了一种新的算法，叫做Optimistic Linear Support (OLS)，它通过学习不同的线性偏好来构建一个CCS（Cone of Credible Sets），并且可以在这个集合中找到至少一个对应的最优策略。
  - 先修知识：
    - Optimistic Linear Support（OLS）
      - OLS是一种基于置信上限的强化学习算法。在强化学习中，通常使用值函数来评估状态或状态-动作对的价值。OLS通过引入一个置信上限来估计值函数，从而对价值进行乐观估计。这个置信上限用于表示对未知价值的乐观估计，以鼓励探索未知状态和动作。OLS算法通过不断更新值函数的估计值，并基于乐观估计选择动作，以最大化奖励或收益
    - Successor Features（SF）
      - SF是一种基于状态转移的表示方法，用于将MDP中的状态映射到特征空间。SF通过表示每个状态的"继承特征"，即描述从一个状态转移到其他状态的可能性。通过学习和使用SF，智能体可以更有效地表示和推断状态之间的关系，并进行策略优化。SF具有一些优势，例如对状态转移的建模能力强、泛化性好、高效学习等。
> OLS和SF都是用于强化学习中的策略优化的技术。OLS通过乐观估计值函数来促进探索，而SF则通过表示状态之间的转移特征来改进状态表示和策略优化。这些方法在强化学习中有广泛的应用，并在不同的问题领域中取得了一定的成功。


    - 可信集锥 CCS（Cone of Credible Sets）
      - CCS（Cone of Credible Sets）是一种统计学方法，用于确定参数估计的可信区间。它是由统计学家Adrian Raftery于1995年提出的。
      - 传统的**参数估计方法通常使用点估计**，即给出一个单一的估计值。然而，这种方法无法提供关于估计值的不确定性的信息。**CCS是一种贝叶斯统计方法，旨在通过提供参数的可信区间来解决这个问题**。
      - CCS基于贝叶斯定理，并使用MCMC（Markov Chain Monte Carlo）方法来从参数的后验分布中抽取样本。通过抽取的样本，可以形成一个参数空间的锥形区域，称为Cone of Credible Sets。这个锥形区域表示了参数估计的不确定性范围，其中包含了真实参数的可能值。
      - CCS的优点是能够提供参数估计的可信区间，反映了参数估计的不确定性。这对于统计推断和决策分析非常有用，因为它可以帮助研究人员更准确地理解参数估计的可靠性和置信度。
    - 最优策略转移
      - 最优策略转移是指在一个决策问题中，通过选择最佳策略，从一个状态转移到另一个状态以**最大化预期收益或最小化预期成本**的过程。
      - **最优策略转移通常应用于强化学习和动态规划等领域**。在强化学习中，一个智能体需要学习在给定环境中作出最佳决策的策略。最优策略转移就是在给定环境状态下，智能体选择能够最大化预期累积奖励的动作。这个过程涉及评估每个可能动作的价值，并选择具有最高价值的动作。
      - 动态规划中的最优策略转移是通过迭代计算来确定在给定状态下应采取的最佳决策。该过程通常涉及构建一个值函数或者策略函数，用于评估每个状态的价值或决策。然后，通过比较不同策略的预期收益或成本，选择具有最优价值的策略。
      - 最优策略转移的目标是通过选择最佳策略来实现最优的结果。这在许多领域中都是重要的，如机器人导航、金融投资决策、游戏策略等。通过使用最优策略转移方法，可以使决策过程更加智能化和优化。